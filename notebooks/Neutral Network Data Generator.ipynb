{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1227 images belonging to 7 classes.\n",
      "Found 335 images belonging to 7 classes.\n",
      "Found 331 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Image Data Generator w/ no augmentation\n",
    "#Scaling for pixels\n",
    "piece_train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255)\n",
    "piece_test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255)\n",
    "piece_valid_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255)\n",
    "\n",
    "\n",
    "#Flow data from directory\n",
    "\n",
    "piece_train_iter = piece_train_datagen.flow_from_directory(\n",
    "    directory = 'data/piece_data/train',\n",
    "    target_size = (135,135),\n",
    "    color_mode = 'grayscale',\n",
    "    class_mode = 'categorical',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "piece_test_iter = piece_test_datagen.flow_from_directory(\n",
    "    directory = 'data/piece_data/test',\n",
    "    target_size = (135,135),\n",
    "    color_mode = 'grayscale',\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "piece_valid_iter = piece_valid_datagen.flow_from_directory(\n",
    "    directory = 'data/piece_data/valid',\n",
    "    target_size = (135,135),\n",
    "    color_mode = 'grayscale',\n",
    "    class_mode = 'categorical',\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 135, 135, 16)      416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 67, 67, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 67, 67, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 67, 67, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 33, 33, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 33, 33, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 33, 33, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       32896     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 128)       65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 64)          32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 64)          16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              133120    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 14343     \n",
      "=================================================================\n",
      "Total params: 4,506,439\n",
      "Trainable params: 4,505,703\n",
      "Non-trainable params: 736\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define NN architecture\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "piece_model = Sequential()\n",
    "piece_model.add(Conv2D(filters=16, kernel_size=5, padding='same', activation='relu', \n",
    "                        input_shape=(135, 135, 1)))\n",
    "piece_model.add(MaxPooling2D(pool_size=2))\n",
    "piece_model.add(BatchNormalization())\n",
    "piece_model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "piece_model.add(MaxPooling2D(pool_size=2))\n",
    "piece_model.add(BatchNormalization())\n",
    "piece_model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "piece_model.add(MaxPooling2D(pool_size=2))\n",
    "piece_model.add(BatchNormalization())\n",
    "piece_model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
    "piece_model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
    "piece_model.add(MaxPooling2D(pool_size=2))\n",
    "piece_model.add(BatchNormalization())\n",
    "piece_model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "piece_model.add(MaxPooling2D(pool_size=2))\n",
    "piece_model.add(BatchNormalization())\n",
    "piece_model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "piece_model.add(MaxPooling2D(pool_size=2))\n",
    "piece_model.add(BatchNormalization())\n",
    "piece_model.add(Dropout(0.3))\n",
    "piece_model.add(GlobalAveragePooling2D())\n",
    "piece_model.add(Dense(2048, activation='relu'))\n",
    "piece_model.add(Dense(2048, activation='relu'))\n",
    "piece_model.add(Dropout(0.4))\n",
    "piece_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "piece_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "from keras.optimizers import RMSprop\n",
    "piece_model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.00001), \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "STEP_SIZE_TRAIN = piece_train_iter.n/piece_train_iter.batch_size\n",
    "STEP_SIZE_VALID = piece_valid_iter.n/piece_valid_iter.batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "Epoch 00000: val_loss improved from inf to 1.94296, saving model to piece_model.weights.best.hdf5\n",
      "6s - loss: 1.8641 - acc: 0.2871 - val_loss: 1.9430 - val_acc: 0.1511\n",
      "Epoch 2/1500\n",
      "Epoch 00001: val_loss did not improve\n",
      "2s - loss: 1.7899 - acc: 0.3083 - val_loss: 1.9829 - val_acc: 0.1329\n",
      "Epoch 3/1500\n",
      "Epoch 00002: val_loss did not improve\n",
      "2s - loss: 1.7301 - acc: 0.3298 - val_loss: 2.0310 - val_acc: 0.1571\n",
      "Epoch 4/1500\n",
      "Epoch 00003: val_loss did not improve\n",
      "2s - loss: 1.6780 - acc: 0.3589 - val_loss: 2.1937 - val_acc: 0.1480\n",
      "Epoch 5/1500\n",
      "Epoch 00004: val_loss did not improve\n",
      "2s - loss: 1.6336 - acc: 0.3593 - val_loss: 2.3701 - val_acc: 0.1480\n",
      "Epoch 6/1500\n",
      "Epoch 00005: val_loss did not improve\n",
      "2s - loss: 1.5999 - acc: 0.3677 - val_loss: 2.5419 - val_acc: 0.1480\n",
      "Epoch 7/1500\n",
      "Epoch 00006: val_loss did not improve\n",
      "2s - loss: 1.5600 - acc: 0.4024 - val_loss: 2.6844 - val_acc: 0.1450\n",
      "Epoch 8/1500\n",
      "Epoch 00007: val_loss did not improve\n",
      "2s - loss: 1.5336 - acc: 0.4166 - val_loss: 2.6709 - val_acc: 0.1480\n",
      "Epoch 9/1500\n",
      "Epoch 00008: val_loss did not improve\n",
      "2s - loss: 1.4958 - acc: 0.4345 - val_loss: 2.5691 - val_acc: 0.1662\n",
      "Epoch 10/1500\n",
      "Epoch 00009: val_loss did not improve\n",
      "2s - loss: 1.4743 - acc: 0.4484 - val_loss: 2.5588 - val_acc: 0.1541\n",
      "Epoch 11/1500\n",
      "Epoch 00010: val_loss did not improve\n",
      "2s - loss: 1.4511 - acc: 0.4642 - val_loss: 2.3784 - val_acc: 0.1571\n",
      "Epoch 12/1500\n",
      "Epoch 00011: val_loss did not improve\n",
      "2s - loss: 1.4325 - acc: 0.4547 - val_loss: 2.2251 - val_acc: 0.1752\n",
      "Epoch 13/1500\n",
      "Epoch 00012: val_loss did not improve\n",
      "2s - loss: 1.4055 - acc: 0.4742 - val_loss: 2.0430 - val_acc: 0.2115\n",
      "Epoch 14/1500\n",
      "Epoch 00013: val_loss improved from 1.94296 to 1.86238, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.3919 - acc: 0.4907 - val_loss: 1.8624 - val_acc: 0.2508\n",
      "Epoch 15/1500\n",
      "Epoch 00014: val_loss improved from 1.86238 to 1.75381, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.3738 - acc: 0.4814 - val_loss: 1.7538 - val_acc: 0.2477\n",
      "Epoch 16/1500\n",
      "Epoch 00015: val_loss improved from 1.75381 to 1.69623, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.3531 - acc: 0.4918 - val_loss: 1.6962 - val_acc: 0.2840\n",
      "Epoch 17/1500\n",
      "Epoch 00016: val_loss improved from 1.69623 to 1.66334, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.3311 - acc: 0.5117 - val_loss: 1.6633 - val_acc: 0.2991\n",
      "Epoch 18/1500\n",
      "Epoch 00017: val_loss improved from 1.66334 to 1.58763, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.3252 - acc: 0.5036 - val_loss: 1.5876 - val_acc: 0.3323\n",
      "Epoch 19/1500\n",
      "Epoch 00018: val_loss improved from 1.58763 to 1.53410, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.3070 - acc: 0.5068 - val_loss: 1.5341 - val_acc: 0.3474\n",
      "Epoch 20/1500\n",
      "Epoch 00019: val_loss improved from 1.53410 to 1.51486, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.2941 - acc: 0.5080 - val_loss: 1.5149 - val_acc: 0.3625\n",
      "Epoch 21/1500\n",
      "Epoch 00020: val_loss did not improve\n",
      "2s - loss: 1.2693 - acc: 0.5227 - val_loss: 1.5306 - val_acc: 0.3595\n",
      "Epoch 22/1500\n",
      "Epoch 00021: val_loss improved from 1.51486 to 1.50905, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.2443 - acc: 0.5531 - val_loss: 1.5091 - val_acc: 0.3656\n",
      "Epoch 23/1500\n",
      "Epoch 00022: val_loss improved from 1.50905 to 1.48476, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.2340 - acc: 0.5470 - val_loss: 1.4848 - val_acc: 0.3837\n",
      "Epoch 24/1500\n",
      "Epoch 00023: val_loss improved from 1.48476 to 1.46800, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.2079 - acc: 0.5530 - val_loss: 1.4680 - val_acc: 0.3927\n",
      "Epoch 25/1500\n",
      "Epoch 00024: val_loss did not improve\n",
      "2s - loss: 1.1989 - acc: 0.5555 - val_loss: 1.4873 - val_acc: 0.3716\n",
      "Epoch 26/1500\n",
      "Epoch 00025: val_loss improved from 1.46800 to 1.42723, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.1844 - acc: 0.5862 - val_loss: 1.4272 - val_acc: 0.4169\n",
      "Epoch 27/1500\n",
      "Epoch 00026: val_loss improved from 1.42723 to 1.41609, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.1662 - acc: 0.5693 - val_loss: 1.4161 - val_acc: 0.4199\n",
      "Epoch 28/1500\n",
      "Epoch 00027: val_loss did not improve\n",
      "2s - loss: 1.1404 - acc: 0.5830 - val_loss: 1.4748 - val_acc: 0.4048\n",
      "Epoch 29/1500\n",
      "Epoch 00028: val_loss did not improve\n",
      "2s - loss: 1.1389 - acc: 0.5885 - val_loss: 1.4205 - val_acc: 0.4139\n",
      "Epoch 30/1500\n",
      "Epoch 00029: val_loss improved from 1.41609 to 1.40394, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.1175 - acc: 0.5910 - val_loss: 1.4039 - val_acc: 0.4320\n",
      "Epoch 31/1500\n",
      "Epoch 00030: val_loss did not improve\n",
      "2s - loss: 1.1052 - acc: 0.5999 - val_loss: 1.4159 - val_acc: 0.4320\n",
      "Epoch 32/1500\n",
      "Epoch 00031: val_loss improved from 1.40394 to 1.36765, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.0990 - acc: 0.5886 - val_loss: 1.3676 - val_acc: 0.4532\n",
      "Epoch 33/1500\n",
      "Epoch 00032: val_loss did not improve\n",
      "2s - loss: 1.0894 - acc: 0.5989 - val_loss: 1.3745 - val_acc: 0.4532\n",
      "Epoch 34/1500\n",
      "Epoch 00033: val_loss did not improve\n",
      "2s - loss: 1.0409 - acc: 0.6325 - val_loss: 1.4479 - val_acc: 0.4592\n",
      "Epoch 35/1500\n",
      "Epoch 00034: val_loss improved from 1.36765 to 1.36585, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.0543 - acc: 0.6151 - val_loss: 1.3659 - val_acc: 0.4713\n",
      "Epoch 36/1500\n",
      "Epoch 00035: val_loss improved from 1.36585 to 1.34542, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 1.0290 - acc: 0.6378 - val_loss: 1.3454 - val_acc: 0.4804\n",
      "Epoch 37/1500\n",
      "Epoch 00036: val_loss did not improve\n",
      "2s - loss: 1.0068 - acc: 0.6519 - val_loss: 1.3759 - val_acc: 0.4804\n",
      "Epoch 38/1500\n",
      "Epoch 00037: val_loss did not improve\n",
      "2s - loss: 0.9838 - acc: 0.6646 - val_loss: 1.3686 - val_acc: 0.4804\n",
      "Epoch 39/1500\n",
      "Epoch 00038: val_loss did not improve\n",
      "2s - loss: 0.9846 - acc: 0.6541 - val_loss: 1.3521 - val_acc: 0.4713\n",
      "Epoch 40/1500\n",
      "Epoch 00039: val_loss did not improve\n",
      "2s - loss: 0.9713 - acc: 0.6664 - val_loss: 1.3967 - val_acc: 0.4683\n",
      "Epoch 41/1500\n",
      "Epoch 00040: val_loss did not improve\n",
      "2s - loss: 0.9619 - acc: 0.6596 - val_loss: 1.3542 - val_acc: 0.4743\n",
      "Epoch 42/1500\n",
      "Epoch 00041: val_loss improved from 1.34542 to 1.30843, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 0.9525 - acc: 0.6651 - val_loss: 1.3084 - val_acc: 0.5287\n",
      "Epoch 43/1500\n",
      "Epoch 00042: val_loss improved from 1.30843 to 1.30320, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 0.9267 - acc: 0.6829 - val_loss: 1.3032 - val_acc: 0.5166\n",
      "Epoch 44/1500\n",
      "Epoch 00043: val_loss improved from 1.30320 to 1.28519, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 0.8996 - acc: 0.6771 - val_loss: 1.2852 - val_acc: 0.5257\n",
      "Epoch 45/1500\n",
      "Epoch 00044: val_loss did not improve\n",
      "2s - loss: 0.9095 - acc: 0.6717 - val_loss: 1.2920 - val_acc: 0.5287\n",
      "Epoch 46/1500\n",
      "Epoch 00045: val_loss did not improve\n",
      "2s - loss: 0.8992 - acc: 0.6861 - val_loss: 1.3621 - val_acc: 0.4773\n",
      "Epoch 47/1500\n",
      "Epoch 00046: val_loss did not improve\n",
      "2s - loss: 0.9082 - acc: 0.6807 - val_loss: 1.3483 - val_acc: 0.4985\n",
      "Epoch 48/1500\n",
      "Epoch 00047: val_loss improved from 1.28519 to 1.27398, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 0.8584 - acc: 0.6954 - val_loss: 1.2740 - val_acc: 0.5317\n",
      "Epoch 49/1500\n",
      "Epoch 00048: val_loss did not improve\n",
      "2s - loss: 0.8315 - acc: 0.7158 - val_loss: 1.2944 - val_acc: 0.5227\n",
      "Epoch 50/1500\n",
      "Epoch 00049: val_loss did not improve\n",
      "2s - loss: 0.8652 - acc: 0.7061 - val_loss: 1.3039 - val_acc: 0.4924\n",
      "Epoch 51/1500\n",
      "Epoch 00050: val_loss did not improve\n",
      "2s - loss: 0.8091 - acc: 0.7253 - val_loss: 1.3539 - val_acc: 0.5045\n",
      "Epoch 52/1500\n",
      "Epoch 00051: val_loss did not improve\n",
      "2s - loss: 0.8247 - acc: 0.7095 - val_loss: 1.2856 - val_acc: 0.5196\n",
      "Epoch 53/1500\n",
      "Epoch 00052: val_loss did not improve\n",
      "2s - loss: 0.7989 - acc: 0.7287 - val_loss: 1.3429 - val_acc: 0.4804\n",
      "Epoch 54/1500\n",
      "Epoch 00053: val_loss did not improve\n",
      "2s - loss: 0.7901 - acc: 0.7327 - val_loss: 1.3357 - val_acc: 0.5015\n",
      "Epoch 55/1500\n",
      "Epoch 00054: val_loss improved from 1.27398 to 1.25400, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 0.7661 - acc: 0.7387 - val_loss: 1.2540 - val_acc: 0.5529\n",
      "Epoch 56/1500\n",
      "Epoch 00055: val_loss did not improve\n",
      "2s - loss: 0.7630 - acc: 0.7445 - val_loss: 1.3327 - val_acc: 0.5015\n",
      "Epoch 57/1500\n",
      "Epoch 00056: val_loss did not improve\n",
      "2s - loss: 0.7598 - acc: 0.7392 - val_loss: 1.3134 - val_acc: 0.5136\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00057: val_loss did not improve\n",
      "2s - loss: 0.7864 - acc: 0.7406 - val_loss: 1.3194 - val_acc: 0.5136\n",
      "Epoch 59/1500\n",
      "Epoch 00058: val_loss did not improve\n",
      "2s - loss: 0.7322 - acc: 0.7590 - val_loss: 1.2739 - val_acc: 0.5257\n",
      "Epoch 60/1500\n",
      "Epoch 00059: val_loss did not improve\n",
      "2s - loss: 0.7229 - acc: 0.7452 - val_loss: 1.2565 - val_acc: 0.5317\n",
      "Epoch 61/1500\n",
      "Epoch 00060: val_loss did not improve\n",
      "2s - loss: 0.7029 - acc: 0.7510 - val_loss: 1.3013 - val_acc: 0.5378\n",
      "Epoch 62/1500\n",
      "Epoch 00061: val_loss did not improve\n",
      "2s - loss: 0.6950 - acc: 0.7656 - val_loss: 1.3481 - val_acc: 0.5166\n",
      "Epoch 63/1500\n",
      "Epoch 00062: val_loss did not improve\n",
      "2s - loss: 0.6850 - acc: 0.7653 - val_loss: 1.3231 - val_acc: 0.5257\n",
      "Epoch 64/1500\n",
      "Epoch 00063: val_loss did not improve\n",
      "2s - loss: 0.6645 - acc: 0.7657 - val_loss: 1.3223 - val_acc: 0.5408\n",
      "Epoch 65/1500\n",
      "Epoch 00064: val_loss improved from 1.25400 to 1.23023, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 0.6787 - acc: 0.7655 - val_loss: 1.2302 - val_acc: 0.5529\n",
      "Epoch 66/1500\n",
      "Epoch 00065: val_loss did not improve\n",
      "2s - loss: 0.6540 - acc: 0.7744 - val_loss: 1.3594 - val_acc: 0.4955\n",
      "Epoch 67/1500\n",
      "Epoch 00066: val_loss did not improve\n",
      "2s - loss: 0.6465 - acc: 0.7831 - val_loss: 1.4453 - val_acc: 0.4834\n",
      "Epoch 68/1500\n",
      "Epoch 00067: val_loss did not improve\n",
      "2s - loss: 0.6237 - acc: 0.7936 - val_loss: 1.2765 - val_acc: 0.5740\n",
      "Epoch 69/1500\n",
      "Epoch 00068: val_loss did not improve\n",
      "2s - loss: 0.6273 - acc: 0.7920 - val_loss: 1.3094 - val_acc: 0.5529\n",
      "Epoch 70/1500\n",
      "Epoch 00069: val_loss did not improve\n",
      "2s - loss: 0.6448 - acc: 0.7804 - val_loss: 1.3426 - val_acc: 0.5076\n",
      "Epoch 71/1500\n",
      "Epoch 00070: val_loss improved from 1.23023 to 1.22664, saving model to piece_model.weights.best.hdf5\n",
      "2s - loss: 0.6165 - acc: 0.7943 - val_loss: 1.2266 - val_acc: 0.5770\n",
      "Epoch 72/1500\n",
      "Epoch 00071: val_loss did not improve\n",
      "2s - loss: 0.5842 - acc: 0.8084 - val_loss: 1.3062 - val_acc: 0.5529\n",
      "Epoch 73/1500\n",
      "Epoch 00072: val_loss did not improve\n",
      "2s - loss: 0.5984 - acc: 0.7903 - val_loss: 1.2599 - val_acc: 0.5317\n",
      "Epoch 74/1500\n",
      "Epoch 00073: val_loss did not improve\n",
      "2s - loss: 0.5668 - acc: 0.8134 - val_loss: 1.3092 - val_acc: 0.5559\n",
      "Epoch 75/1500\n",
      "Epoch 00074: val_loss did not improve\n",
      "2s - loss: 0.6032 - acc: 0.7956 - val_loss: 1.2451 - val_acc: 0.5619\n",
      "Epoch 76/1500\n",
      "Epoch 00075: val_loss did not improve\n",
      "2s - loss: 0.5906 - acc: 0.8037 - val_loss: 1.3570 - val_acc: 0.5287\n",
      "Epoch 77/1500\n",
      "Epoch 00076: val_loss did not improve\n",
      "2s - loss: 0.5632 - acc: 0.8181 - val_loss: 1.2354 - val_acc: 0.5710\n",
      "Epoch 78/1500\n",
      "Epoch 00077: val_loss did not improve\n",
      "2s - loss: 0.5511 - acc: 0.8225 - val_loss: 1.2968 - val_acc: 0.5559\n",
      "Epoch 79/1500\n",
      "Epoch 00078: val_loss did not improve\n",
      "2s - loss: 0.5357 - acc: 0.8327 - val_loss: 1.2836 - val_acc: 0.5619\n",
      "Epoch 80/1500\n",
      "Epoch 00079: val_loss did not improve\n",
      "2s - loss: 0.5387 - acc: 0.8202 - val_loss: 1.2920 - val_acc: 0.5559\n",
      "Epoch 81/1500\n",
      "Epoch 00080: val_loss did not improve\n",
      "2s - loss: 0.4994 - acc: 0.8391 - val_loss: 1.2630 - val_acc: 0.5831\n",
      "Epoch 82/1500\n",
      "Epoch 00081: val_loss did not improve\n",
      "2s - loss: 0.5028 - acc: 0.8321 - val_loss: 1.3224 - val_acc: 0.5408\n",
      "Epoch 83/1500\n",
      "Epoch 00082: val_loss did not improve\n",
      "2s - loss: 0.5442 - acc: 0.8242 - val_loss: 1.3118 - val_acc: 0.5650\n",
      "Epoch 84/1500\n",
      "Epoch 00083: val_loss did not improve\n",
      "2s - loss: 0.5132 - acc: 0.8431 - val_loss: 1.2910 - val_acc: 0.5710\n",
      "Epoch 85/1500\n",
      "Epoch 00084: val_loss did not improve\n",
      "2s - loss: 0.4551 - acc: 0.8590 - val_loss: 1.3634 - val_acc: 0.5498\n",
      "Epoch 86/1500\n",
      "Epoch 00085: val_loss did not improve\n",
      "2s - loss: 0.5432 - acc: 0.8099 - val_loss: 1.3453 - val_acc: 0.5347\n",
      "Epoch 87/1500\n",
      "Epoch 00086: val_loss did not improve\n",
      "2s - loss: 0.4727 - acc: 0.8474 - val_loss: 1.3348 - val_acc: 0.5317\n",
      "Epoch 88/1500\n",
      "Epoch 00087: val_loss did not improve\n",
      "2s - loss: 0.4600 - acc: 0.8602 - val_loss: 1.3301 - val_acc: 0.5680\n",
      "Epoch 89/1500\n",
      "Epoch 00088: val_loss did not improve\n",
      "2s - loss: 0.4695 - acc: 0.8382 - val_loss: 1.2749 - val_acc: 0.5619\n",
      "Epoch 90/1500\n",
      "Epoch 00089: val_loss did not improve\n",
      "2s - loss: 0.4409 - acc: 0.8433 - val_loss: 1.4335 - val_acc: 0.5317\n",
      "Epoch 91/1500\n",
      "Epoch 00090: val_loss did not improve\n",
      "2s - loss: 0.4207 - acc: 0.8630 - val_loss: 1.3540 - val_acc: 0.5378\n",
      "Epoch 92/1500\n",
      "Epoch 00091: val_loss did not improve\n",
      "2s - loss: 0.4371 - acc: 0.8615 - val_loss: 1.4282 - val_acc: 0.5438\n",
      "Epoch 93/1500\n",
      "Epoch 00092: val_loss did not improve\n",
      "2s - loss: 0.4486 - acc: 0.8622 - val_loss: 1.3425 - val_acc: 0.5801\n",
      "Epoch 94/1500\n",
      "Epoch 00093: val_loss did not improve\n",
      "2s - loss: 0.4009 - acc: 0.8836 - val_loss: 1.3826 - val_acc: 0.5680\n",
      "Epoch 95/1500\n",
      "Epoch 00094: val_loss did not improve\n",
      "2s - loss: 0.4179 - acc: 0.8696 - val_loss: 1.2932 - val_acc: 0.5589\n",
      "Epoch 96/1500\n",
      "Epoch 00095: val_loss did not improve\n",
      "2s - loss: 0.3841 - acc: 0.8880 - val_loss: 1.3519 - val_acc: 0.5650\n",
      "Epoch 97/1500\n",
      "Epoch 00096: val_loss did not improve\n",
      "2s - loss: 0.4209 - acc: 0.8587 - val_loss: 1.3535 - val_acc: 0.5710\n",
      "Epoch 98/1500\n",
      "Epoch 00097: val_loss did not improve\n",
      "2s - loss: 0.4147 - acc: 0.8719 - val_loss: 1.3459 - val_acc: 0.5589\n",
      "Epoch 99/1500\n",
      "Epoch 00098: val_loss did not improve\n",
      "2s - loss: 0.4067 - acc: 0.8615 - val_loss: 1.3388 - val_acc: 0.5770\n",
      "Epoch 100/1500\n",
      "Epoch 00099: val_loss did not improve\n",
      "2s - loss: 0.4073 - acc: 0.8683 - val_loss: 1.4302 - val_acc: 0.5347\n",
      "Epoch 101/1500\n",
      "Epoch 00100: val_loss did not improve\n",
      "2s - loss: 0.3788 - acc: 0.8767 - val_loss: 1.3943 - val_acc: 0.5559\n",
      "Epoch 102/1500\n",
      "Epoch 00101: val_loss did not improve\n",
      "2s - loss: 0.3914 - acc: 0.8683 - val_loss: 1.4382 - val_acc: 0.5378\n",
      "Epoch 103/1500\n",
      "Epoch 00102: val_loss did not improve\n",
      "2s - loss: 0.3679 - acc: 0.8809 - val_loss: 1.4296 - val_acc: 0.5257\n",
      "Epoch 104/1500\n",
      "Epoch 00103: val_loss did not improve\n",
      "2s - loss: 0.4107 - acc: 0.8634 - val_loss: 1.2815 - val_acc: 0.5861\n",
      "Epoch 105/1500\n",
      "Epoch 00104: val_loss did not improve\n",
      "2s - loss: 0.3671 - acc: 0.8769 - val_loss: 1.4809 - val_acc: 0.5287\n",
      "Epoch 106/1500\n",
      "Epoch 00105: val_loss did not improve\n",
      "2s - loss: 0.3268 - acc: 0.9007 - val_loss: 1.4156 - val_acc: 0.5831\n",
      "Epoch 107/1500\n",
      "Epoch 00106: val_loss did not improve\n",
      "2s - loss: 0.3631 - acc: 0.8723 - val_loss: 1.4305 - val_acc: 0.5650\n",
      "Epoch 108/1500\n",
      "Epoch 00107: val_loss did not improve\n",
      "2s - loss: 0.3484 - acc: 0.8816 - val_loss: 1.3672 - val_acc: 0.5831\n",
      "Epoch 109/1500\n",
      "Epoch 00108: val_loss did not improve\n",
      "2s - loss: 0.3249 - acc: 0.8968 - val_loss: 1.4003 - val_acc: 0.5861\n",
      "Epoch 110/1500\n",
      "Epoch 00109: val_loss did not improve\n",
      "2s - loss: 0.3174 - acc: 0.8952 - val_loss: 1.3673 - val_acc: 0.5680\n",
      "Epoch 111/1500\n",
      "Epoch 00110: val_loss did not improve\n",
      "2s - loss: 0.3012 - acc: 0.9064 - val_loss: 1.4285 - val_acc: 0.5498\n",
      "Epoch 112/1500\n",
      "Epoch 00111: val_loss did not improve\n",
      "2s - loss: 0.3233 - acc: 0.8967 - val_loss: 1.4852 - val_acc: 0.5468\n",
      "Epoch 113/1500\n",
      "Epoch 00112: val_loss did not improve\n",
      "2s - loss: 0.3122 - acc: 0.9064 - val_loss: 1.4753 - val_acc: 0.5680\n",
      "Epoch 114/1500\n",
      "Epoch 00113: val_loss did not improve\n",
      "2s - loss: 0.3191 - acc: 0.8977 - val_loss: 1.3746 - val_acc: 0.5529\n",
      "Epoch 115/1500\n",
      "Epoch 00114: val_loss did not improve\n",
      "2s - loss: 0.3296 - acc: 0.8856 - val_loss: 1.4744 - val_acc: 0.5740\n",
      "Epoch 116/1500\n",
      "Epoch 00115: val_loss did not improve\n",
      "2s - loss: 0.2955 - acc: 0.9062 - val_loss: 1.5267 - val_acc: 0.5408\n",
      "Epoch 117/1500\n",
      "Epoch 00116: val_loss did not improve\n",
      "2s - loss: 0.2710 - acc: 0.9130 - val_loss: 1.5246 - val_acc: 0.5468\n",
      "Epoch 118/1500\n",
      "Epoch 00117: val_loss did not improve\n",
      "2s - loss: 0.2890 - acc: 0.9059 - val_loss: 1.4230 - val_acc: 0.5650\n",
      "Epoch 119/1500\n",
      "Epoch 00118: val_loss did not improve\n",
      "2s - loss: 0.3166 - acc: 0.9065 - val_loss: 1.6395 - val_acc: 0.5468\n",
      "Epoch 120/1500\n",
      "Epoch 00119: val_loss did not improve\n",
      "2s - loss: 0.3216 - acc: 0.8898 - val_loss: 1.4614 - val_acc: 0.5650\n",
      "Epoch 121/1500\n",
      "Epoch 00120: val_loss did not improve\n",
      "2s - loss: 0.2722 - acc: 0.9135 - val_loss: 1.4279 - val_acc: 0.5952\n",
      "Epoch 122/1500\n",
      "Epoch 00121: val_loss did not improve\n",
      "2s - loss: 0.2765 - acc: 0.9234 - val_loss: 1.5093 - val_acc: 0.5801\n",
      "Epoch 123/1500\n",
      "Epoch 00122: val_loss did not improve\n",
      "2s - loss: 0.2908 - acc: 0.9065 - val_loss: 1.4882 - val_acc: 0.5438\n",
      "Epoch 124/1500\n",
      "Epoch 00123: val_loss did not improve\n",
      "2s - loss: 0.2634 - acc: 0.9151 - val_loss: 1.6003 - val_acc: 0.5317\n",
      "Epoch 125/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00124: val_loss did not improve\n",
      "2s - loss: 0.2456 - acc: 0.9199 - val_loss: 1.4008 - val_acc: 0.5952\n",
      "Epoch 126/1500\n",
      "Epoch 00125: val_loss did not improve\n",
      "2s - loss: 0.2461 - acc: 0.9256 - val_loss: 1.4746 - val_acc: 0.5801\n",
      "Epoch 127/1500\n",
      "Epoch 00126: val_loss did not improve\n",
      "2s - loss: 0.2439 - acc: 0.9183 - val_loss: 1.6021 - val_acc: 0.5136\n",
      "Epoch 128/1500\n",
      "Epoch 00127: val_loss did not improve\n",
      "2s - loss: 0.2382 - acc: 0.9232 - val_loss: 1.5227 - val_acc: 0.5650\n",
      "Epoch 129/1500\n",
      "Epoch 00128: val_loss did not improve\n",
      "2s - loss: 0.2523 - acc: 0.9256 - val_loss: 1.5838 - val_acc: 0.5831\n",
      "Epoch 130/1500\n",
      "Epoch 00129: val_loss did not improve\n",
      "2s - loss: 0.2280 - acc: 0.9271 - val_loss: 1.4674 - val_acc: 0.5921\n",
      "Epoch 131/1500\n",
      "Epoch 00130: val_loss did not improve\n",
      "2s - loss: 0.2535 - acc: 0.9175 - val_loss: 1.3543 - val_acc: 0.5891\n",
      "Epoch 132/1500\n",
      "Epoch 00131: val_loss did not improve\n",
      "2s - loss: 0.2465 - acc: 0.9182 - val_loss: 1.6017 - val_acc: 0.5589\n",
      "Epoch 133/1500\n",
      "Epoch 00132: val_loss did not improve\n",
      "2s - loss: 0.2141 - acc: 0.9329 - val_loss: 1.5267 - val_acc: 0.6073\n",
      "Epoch 134/1500\n",
      "Epoch 00133: val_loss did not improve\n",
      "2s - loss: 0.2536 - acc: 0.9240 - val_loss: 1.5381 - val_acc: 0.5801\n",
      "Epoch 135/1500\n",
      "Epoch 00134: val_loss did not improve\n",
      "2s - loss: 0.2412 - acc: 0.9256 - val_loss: 1.5261 - val_acc: 0.5680\n",
      "Epoch 136/1500\n",
      "Epoch 00135: val_loss did not improve\n",
      "2s - loss: 0.2265 - acc: 0.9272 - val_loss: 1.5181 - val_acc: 0.5559\n",
      "Epoch 137/1500\n",
      "Epoch 00136: val_loss did not improve\n",
      "2s - loss: 0.1927 - acc: 0.9447 - val_loss: 1.5889 - val_acc: 0.5650\n",
      "Epoch 138/1500\n",
      "Epoch 00137: val_loss did not improve\n",
      "2s - loss: 0.1998 - acc: 0.9497 - val_loss: 1.4504 - val_acc: 0.5770\n",
      "Epoch 139/1500\n",
      "Epoch 00138: val_loss did not improve\n",
      "2s - loss: 0.2364 - acc: 0.9232 - val_loss: 1.6086 - val_acc: 0.5801\n",
      "Epoch 140/1500\n",
      "Epoch 00139: val_loss did not improve\n",
      "2s - loss: 0.2055 - acc: 0.9375 - val_loss: 1.6341 - val_acc: 0.5378\n",
      "Epoch 141/1500\n",
      "Epoch 00140: val_loss did not improve\n",
      "2s - loss: 0.2309 - acc: 0.9241 - val_loss: 1.5755 - val_acc: 0.5770\n",
      "Epoch 142/1500\n",
      "Epoch 00141: val_loss did not improve\n",
      "2s - loss: 0.2240 - acc: 0.9254 - val_loss: 1.5089 - val_acc: 0.5740\n",
      "Epoch 143/1500\n",
      "Epoch 00142: val_loss did not improve\n",
      "2s - loss: 0.2037 - acc: 0.9400 - val_loss: 1.5898 - val_acc: 0.5770\n",
      "Epoch 144/1500\n",
      "Epoch 00143: val_loss did not improve\n",
      "2s - loss: 0.2064 - acc: 0.9304 - val_loss: 1.4872 - val_acc: 0.6133\n",
      "Epoch 145/1500\n",
      "Epoch 00144: val_loss did not improve\n",
      "2s - loss: 0.2086 - acc: 0.9241 - val_loss: 1.6516 - val_acc: 0.5498\n",
      "Epoch 146/1500\n",
      "Epoch 00145: val_loss did not improve\n",
      "2s - loss: 0.2109 - acc: 0.9319 - val_loss: 1.4713 - val_acc: 0.5982\n",
      "Epoch 147/1500\n",
      "Epoch 00146: val_loss did not improve\n",
      "2s - loss: 0.2018 - acc: 0.9352 - val_loss: 1.6234 - val_acc: 0.6042\n",
      "Epoch 148/1500\n",
      "Epoch 00147: val_loss did not improve\n",
      "2s - loss: 0.1879 - acc: 0.9408 - val_loss: 1.6732 - val_acc: 0.5650\n",
      "Epoch 149/1500\n",
      "Epoch 00148: val_loss did not improve\n",
      "2s - loss: 0.1852 - acc: 0.9368 - val_loss: 1.6105 - val_acc: 0.5740\n",
      "Epoch 150/1500\n",
      "Epoch 00149: val_loss did not improve\n",
      "2s - loss: 0.1733 - acc: 0.9458 - val_loss: 1.5851 - val_acc: 0.5982\n",
      "Epoch 151/1500\n",
      "Epoch 00150: val_loss did not improve\n",
      "2s - loss: 0.2099 - acc: 0.9329 - val_loss: 1.5683 - val_acc: 0.5801\n",
      "Epoch 152/1500\n",
      "Epoch 00151: val_loss did not improve\n",
      "2s - loss: 0.1867 - acc: 0.9424 - val_loss: 1.4900 - val_acc: 0.6163\n",
      "Epoch 153/1500\n",
      "Epoch 00152: val_loss did not improve\n",
      "2s - loss: 0.1904 - acc: 0.9368 - val_loss: 1.6079 - val_acc: 0.5831\n",
      "Epoch 154/1500\n",
      "Epoch 00153: val_loss did not improve\n",
      "2s - loss: 0.1526 - acc: 0.9576 - val_loss: 1.6991 - val_acc: 0.5801\n",
      "Epoch 155/1500\n",
      "Epoch 00154: val_loss did not improve\n",
      "2s - loss: 0.1640 - acc: 0.9575 - val_loss: 1.6562 - val_acc: 0.5952\n",
      "Epoch 156/1500\n",
      "Epoch 00155: val_loss did not improve\n",
      "2s - loss: 0.1549 - acc: 0.9463 - val_loss: 1.5267 - val_acc: 0.5891\n",
      "Epoch 157/1500\n",
      "Epoch 00156: val_loss did not improve\n",
      "2s - loss: 0.1923 - acc: 0.9442 - val_loss: 1.6949 - val_acc: 0.5740\n",
      "Epoch 158/1500\n",
      "Epoch 00157: val_loss did not improve\n",
      "2s - loss: 0.1690 - acc: 0.9447 - val_loss: 1.5246 - val_acc: 0.6224\n",
      "Epoch 159/1500\n",
      "Epoch 00158: val_loss did not improve\n",
      "2s - loss: 0.1466 - acc: 0.9552 - val_loss: 1.6349 - val_acc: 0.6073\n",
      "Epoch 160/1500\n",
      "Epoch 00159: val_loss did not improve\n",
      "2s - loss: 0.1665 - acc: 0.9439 - val_loss: 1.6210 - val_acc: 0.5831\n",
      "Epoch 161/1500\n",
      "Epoch 00160: val_loss did not improve\n",
      "2s - loss: 0.1322 - acc: 0.9591 - val_loss: 1.6954 - val_acc: 0.5891\n",
      "Epoch 162/1500\n",
      "Epoch 00161: val_loss did not improve\n",
      "2s - loss: 0.1594 - acc: 0.9463 - val_loss: 1.6067 - val_acc: 0.6284\n",
      "Epoch 163/1500\n",
      "Epoch 00162: val_loss did not improve\n",
      "2s - loss: 0.1208 - acc: 0.9687 - val_loss: 1.8074 - val_acc: 0.5770\n",
      "Epoch 164/1500\n",
      "Epoch 00163: val_loss did not improve\n",
      "2s - loss: 0.1390 - acc: 0.9640 - val_loss: 1.7867 - val_acc: 0.5710\n",
      "Epoch 165/1500\n",
      "Epoch 00164: val_loss did not improve\n",
      "2s - loss: 0.1742 - acc: 0.9451 - val_loss: 1.7172 - val_acc: 0.5770\n",
      "Epoch 166/1500\n",
      "Epoch 00165: val_loss did not improve\n",
      "2s - loss: 0.1383 - acc: 0.9583 - val_loss: 1.8656 - val_acc: 0.5650\n",
      "Epoch 167/1500\n",
      "Epoch 00166: val_loss did not improve\n",
      "2s - loss: 0.1739 - acc: 0.9498 - val_loss: 1.6427 - val_acc: 0.5921\n",
      "Epoch 168/1500\n",
      "Epoch 00167: val_loss did not improve\n",
      "2s - loss: 0.1460 - acc: 0.9617 - val_loss: 1.8285 - val_acc: 0.5680\n",
      "Epoch 169/1500\n",
      "Epoch 00168: val_loss did not improve\n",
      "2s - loss: 0.1294 - acc: 0.9619 - val_loss: 1.6663 - val_acc: 0.5952\n",
      "Epoch 170/1500\n",
      "Epoch 00169: val_loss did not improve\n",
      "2s - loss: 0.1101 - acc: 0.9687 - val_loss: 1.6341 - val_acc: 0.5982\n",
      "Epoch 171/1500\n",
      "Epoch 00170: val_loss did not improve\n",
      "2s - loss: 0.1049 - acc: 0.9751 - val_loss: 1.5903 - val_acc: 0.5982\n",
      "Epoch 172/1500\n",
      "Epoch 00171: val_loss did not improve\n",
      "2s - loss: 0.1346 - acc: 0.9592 - val_loss: 1.6756 - val_acc: 0.5801\n",
      "Epoch 173/1500\n",
      "Epoch 00172: val_loss did not improve\n",
      "2s - loss: 0.1378 - acc: 0.9543 - val_loss: 1.7576 - val_acc: 0.5619\n",
      "Epoch 174/1500\n",
      "Epoch 00173: val_loss did not improve\n",
      "2s - loss: 0.1739 - acc: 0.9481 - val_loss: 1.6671 - val_acc: 0.6012\n",
      "Epoch 175/1500\n",
      "Epoch 00174: val_loss did not improve\n",
      "2s - loss: 0.1305 - acc: 0.9585 - val_loss: 1.6727 - val_acc: 0.5770\n",
      "Epoch 176/1500\n",
      "Epoch 00175: val_loss did not improve\n",
      "2s - loss: 0.1654 - acc: 0.9477 - val_loss: 1.8081 - val_acc: 0.5861\n",
      "Epoch 177/1500\n",
      "Epoch 00176: val_loss did not improve\n",
      "2s - loss: 0.1352 - acc: 0.9551 - val_loss: 1.5558 - val_acc: 0.6284\n",
      "Epoch 178/1500\n",
      "Epoch 00177: val_loss did not improve\n",
      "2s - loss: 0.1534 - acc: 0.9434 - val_loss: 1.5192 - val_acc: 0.6224\n",
      "Epoch 179/1500\n",
      "Epoch 00178: val_loss did not improve\n",
      "2s - loss: 0.1347 - acc: 0.9544 - val_loss: 1.7711 - val_acc: 0.5740\n",
      "Epoch 180/1500\n",
      "Epoch 00179: val_loss did not improve\n",
      "2s - loss: 0.1341 - acc: 0.9560 - val_loss: 1.7635 - val_acc: 0.5921\n",
      "Epoch 181/1500\n",
      "Epoch 00180: val_loss did not improve\n",
      "2s - loss: 0.1175 - acc: 0.9639 - val_loss: 1.8467 - val_acc: 0.5801\n",
      "Epoch 182/1500\n",
      "Epoch 00181: val_loss did not improve\n",
      "2s - loss: 0.1130 - acc: 0.9680 - val_loss: 1.7338 - val_acc: 0.6224\n",
      "Epoch 183/1500\n",
      "Epoch 00182: val_loss did not improve\n",
      "2s - loss: 0.1028 - acc: 0.9672 - val_loss: 1.8344 - val_acc: 0.5770\n",
      "Epoch 184/1500\n",
      "Epoch 00183: val_loss did not improve\n",
      "2s - loss: 0.1166 - acc: 0.9599 - val_loss: 1.6634 - val_acc: 0.6042\n",
      "Epoch 185/1500\n",
      "Epoch 00184: val_loss did not improve\n",
      "2s - loss: 0.1558 - acc: 0.9467 - val_loss: 1.8023 - val_acc: 0.5891\n",
      "Epoch 186/1500\n",
      "Epoch 00185: val_loss did not improve\n",
      "2s - loss: 0.1166 - acc: 0.9655 - val_loss: 1.7930 - val_acc: 0.5921\n",
      "Epoch 187/1500\n",
      "Epoch 00186: val_loss did not improve\n",
      "2s - loss: 0.1097 - acc: 0.9672 - val_loss: 1.9647 - val_acc: 0.5559\n",
      "Epoch 188/1500\n",
      "Epoch 00187: val_loss did not improve\n",
      "2s - loss: 0.1182 - acc: 0.9599 - val_loss: 1.6445 - val_acc: 0.6103\n",
      "Epoch 189/1500\n",
      "Epoch 00188: val_loss did not improve\n",
      "2s - loss: 0.0970 - acc: 0.9680 - val_loss: 1.8333 - val_acc: 0.5801\n",
      "Epoch 190/1500\n",
      "Epoch 00189: val_loss did not improve\n",
      "2s - loss: 0.1147 - acc: 0.9650 - val_loss: 1.6953 - val_acc: 0.6193\n",
      "Epoch 191/1500\n",
      "Epoch 00190: val_loss did not improve\n",
      "2s - loss: 0.1058 - acc: 0.9648 - val_loss: 1.8150 - val_acc: 0.6012\n",
      "Epoch 192/1500\n",
      "Epoch 00191: val_loss did not improve\n",
      "2s - loss: 0.1073 - acc: 0.9607 - val_loss: 1.6945 - val_acc: 0.6073\n",
      "Epoch 193/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00192: val_loss did not improve\n",
      "2s - loss: 0.1060 - acc: 0.9687 - val_loss: 1.7060 - val_acc: 0.6012\n",
      "Epoch 194/1500\n",
      "Epoch 00193: val_loss did not improve\n",
      "2s - loss: 0.1206 - acc: 0.9584 - val_loss: 1.7885 - val_acc: 0.5861\n",
      "Epoch 195/1500\n",
      "Epoch 00194: val_loss did not improve\n",
      "2s - loss: 0.1003 - acc: 0.9674 - val_loss: 1.8715 - val_acc: 0.5921\n",
      "Epoch 196/1500\n",
      "Epoch 00195: val_loss did not improve\n",
      "2s - loss: 0.0954 - acc: 0.9666 - val_loss: 1.8968 - val_acc: 0.5740\n",
      "Epoch 197/1500\n",
      "Epoch 00196: val_loss did not improve\n",
      "2s - loss: 0.1080 - acc: 0.9643 - val_loss: 1.8849 - val_acc: 0.5861\n",
      "Epoch 198/1500\n",
      "Epoch 00197: val_loss did not improve\n",
      "2s - loss: 0.1285 - acc: 0.9566 - val_loss: 1.9430 - val_acc: 0.5619\n",
      "Epoch 199/1500\n",
      "Epoch 00198: val_loss did not improve\n",
      "2s - loss: 0.1102 - acc: 0.9671 - val_loss: 1.8498 - val_acc: 0.6012\n",
      "Epoch 200/1500\n",
      "Epoch 00199: val_loss did not improve\n",
      "2s - loss: 0.1189 - acc: 0.9691 - val_loss: 1.9704 - val_acc: 0.5680\n",
      "Epoch 201/1500\n",
      "Epoch 00200: val_loss did not improve\n",
      "2s - loss: 0.1028 - acc: 0.9703 - val_loss: 1.8080 - val_acc: 0.6073\n",
      "Epoch 202/1500\n",
      "Epoch 00201: val_loss did not improve\n",
      "2s - loss: 0.1162 - acc: 0.9591 - val_loss: 1.8470 - val_acc: 0.5891\n",
      "Epoch 203/1500\n",
      "Epoch 00202: val_loss did not improve\n",
      "2s - loss: 0.0805 - acc: 0.9768 - val_loss: 1.8877 - val_acc: 0.5801\n",
      "Epoch 204/1500\n",
      "Epoch 00203: val_loss did not improve\n",
      "2s - loss: 0.0836 - acc: 0.9751 - val_loss: 1.8562 - val_acc: 0.6042\n",
      "Epoch 205/1500\n",
      "Epoch 00204: val_loss did not improve\n",
      "2s - loss: 0.0790 - acc: 0.9840 - val_loss: 1.8615 - val_acc: 0.5952\n",
      "Epoch 206/1500\n",
      "Epoch 00205: val_loss did not improve\n",
      "2s - loss: 0.0887 - acc: 0.9680 - val_loss: 1.7943 - val_acc: 0.5589\n",
      "Epoch 207/1500\n",
      "Epoch 00206: val_loss did not improve\n",
      "2s - loss: 0.0905 - acc: 0.9760 - val_loss: 1.6093 - val_acc: 0.6284\n",
      "Epoch 208/1500\n",
      "Epoch 00207: val_loss did not improve\n",
      "2s - loss: 0.1082 - acc: 0.9714 - val_loss: 1.8755 - val_acc: 0.5801\n",
      "Epoch 209/1500\n",
      "Epoch 00208: val_loss did not improve\n",
      "2s - loss: 0.0791 - acc: 0.9760 - val_loss: 1.5594 - val_acc: 0.6163\n",
      "Epoch 210/1500\n",
      "Epoch 00209: val_loss did not improve\n",
      "2s - loss: 0.0869 - acc: 0.9735 - val_loss: 1.8528 - val_acc: 0.6042\n",
      "Epoch 211/1500\n",
      "Epoch 00210: val_loss did not improve\n",
      "2s - loss: 0.0753 - acc: 0.9754 - val_loss: 1.7934 - val_acc: 0.6073\n",
      "Epoch 212/1500\n",
      "Epoch 00211: val_loss did not improve\n",
      "2s - loss: 0.0948 - acc: 0.9745 - val_loss: 2.1632 - val_acc: 0.5378\n",
      "Epoch 213/1500\n",
      "Epoch 00212: val_loss did not improve\n",
      "2s - loss: 0.0863 - acc: 0.9658 - val_loss: 1.8515 - val_acc: 0.5801\n",
      "Epoch 214/1500\n",
      "Epoch 00213: val_loss did not improve\n",
      "2s - loss: 0.0711 - acc: 0.9751 - val_loss: 1.8712 - val_acc: 0.5770\n",
      "Epoch 215/1500\n",
      "Epoch 00214: val_loss did not improve\n",
      "2s - loss: 0.1040 - acc: 0.9705 - val_loss: 1.9768 - val_acc: 0.5891\n",
      "Epoch 216/1500\n",
      "Epoch 00215: val_loss did not improve\n",
      "2s - loss: 0.0767 - acc: 0.9719 - val_loss: 1.9755 - val_acc: 0.5921\n",
      "Epoch 217/1500\n",
      "Epoch 00216: val_loss did not improve\n",
      "2s - loss: 0.0912 - acc: 0.9713 - val_loss: 1.8600 - val_acc: 0.5952\n",
      "Epoch 218/1500\n",
      "Epoch 00217: val_loss did not improve\n",
      "2s - loss: 0.0795 - acc: 0.9761 - val_loss: 1.9733 - val_acc: 0.5921\n",
      "Epoch 219/1500\n",
      "Epoch 00218: val_loss did not improve\n",
      "2s - loss: 0.0762 - acc: 0.9761 - val_loss: 1.9491 - val_acc: 0.5861\n",
      "Epoch 220/1500\n",
      "Epoch 00219: val_loss did not improve\n",
      "2s - loss: 0.0799 - acc: 0.9760 - val_loss: 1.9096 - val_acc: 0.6042\n",
      "Epoch 221/1500\n",
      "Epoch 00220: val_loss did not improve\n",
      "2s - loss: 0.0678 - acc: 0.9762 - val_loss: 1.6340 - val_acc: 0.6163\n",
      "Epoch 222/1500\n",
      "Epoch 00221: val_loss did not improve\n",
      "2s - loss: 0.0739 - acc: 0.9793 - val_loss: 1.9019 - val_acc: 0.6073\n",
      "Epoch 223/1500\n",
      "Epoch 00222: val_loss did not improve\n",
      "2s - loss: 0.0897 - acc: 0.9697 - val_loss: 1.9243 - val_acc: 0.6133\n",
      "Epoch 224/1500\n",
      "Epoch 00223: val_loss did not improve\n",
      "2s - loss: 0.1039 - acc: 0.9639 - val_loss: 1.8105 - val_acc: 0.6405\n",
      "Epoch 225/1500\n",
      "Epoch 00224: val_loss did not improve\n",
      "2s - loss: 0.0748 - acc: 0.9760 - val_loss: 2.0782 - val_acc: 0.6042\n",
      "Epoch 226/1500\n",
      "Epoch 00225: val_loss did not improve\n",
      "2s - loss: 0.0616 - acc: 0.9808 - val_loss: 1.9525 - val_acc: 0.5921\n",
      "Epoch 227/1500\n",
      "Epoch 00226: val_loss did not improve\n",
      "2s - loss: 0.0808 - acc: 0.9745 - val_loss: 1.9603 - val_acc: 0.5801\n",
      "Epoch 228/1500\n",
      "Epoch 00227: val_loss did not improve\n",
      "2s - loss: 0.0759 - acc: 0.9769 - val_loss: 1.9305 - val_acc: 0.5861\n",
      "Epoch 229/1500\n",
      "Epoch 00228: val_loss did not improve\n",
      "2s - loss: 0.0792 - acc: 0.9768 - val_loss: 1.8798 - val_acc: 0.5891\n",
      "Epoch 230/1500\n",
      "Epoch 00229: val_loss did not improve\n",
      "2s - loss: 0.0778 - acc: 0.9735 - val_loss: 1.9245 - val_acc: 0.5680\n",
      "Epoch 231/1500\n",
      "Epoch 00230: val_loss did not improve\n",
      "2s - loss: 0.0619 - acc: 0.9809 - val_loss: 2.0213 - val_acc: 0.5831\n",
      "Epoch 232/1500\n",
      "Epoch 00231: val_loss did not improve\n",
      "2s - loss: 0.0727 - acc: 0.9769 - val_loss: 2.0263 - val_acc: 0.6073\n",
      "Epoch 233/1500\n",
      "Epoch 00232: val_loss did not improve\n",
      "2s - loss: 0.0985 - acc: 0.9683 - val_loss: 2.0048 - val_acc: 0.5770\n",
      "Epoch 234/1500\n",
      "Epoch 00233: val_loss did not improve\n",
      "2s - loss: 0.0799 - acc: 0.9760 - val_loss: 1.8894 - val_acc: 0.5891\n",
      "Epoch 235/1500\n",
      "Epoch 00234: val_loss did not improve\n",
      "2s - loss: 0.0838 - acc: 0.9730 - val_loss: 2.0392 - val_acc: 0.5861\n",
      "Epoch 236/1500\n",
      "Epoch 00235: val_loss did not improve\n",
      "2s - loss: 0.0654 - acc: 0.9785 - val_loss: 2.1155 - val_acc: 0.5589\n",
      "Epoch 237/1500\n",
      "Epoch 00236: val_loss did not improve\n",
      "2s - loss: 0.0722 - acc: 0.9816 - val_loss: 1.8290 - val_acc: 0.6012\n",
      "Epoch 238/1500\n",
      "Epoch 00237: val_loss did not improve\n",
      "2s - loss: 0.0839 - acc: 0.9679 - val_loss: 2.0254 - val_acc: 0.6073\n",
      "Epoch 239/1500\n",
      "Epoch 00238: val_loss did not improve\n",
      "2s - loss: 0.0824 - acc: 0.9747 - val_loss: 1.9052 - val_acc: 0.6284\n",
      "Epoch 240/1500\n",
      "Epoch 00239: val_loss did not improve\n",
      "2s - loss: 0.0760 - acc: 0.9808 - val_loss: 1.9277 - val_acc: 0.5740\n",
      "Epoch 241/1500\n",
      "Epoch 00240: val_loss did not improve\n",
      "2s - loss: 0.0562 - acc: 0.9850 - val_loss: 1.8033 - val_acc: 0.6073\n",
      "Epoch 242/1500\n",
      "Epoch 00241: val_loss did not improve\n",
      "2s - loss: 0.0492 - acc: 0.9865 - val_loss: 2.0507 - val_acc: 0.5921\n",
      "Epoch 243/1500\n",
      "Epoch 00242: val_loss did not improve\n",
      "2s - loss: 0.0591 - acc: 0.9832 - val_loss: 1.9958 - val_acc: 0.5952\n",
      "Epoch 244/1500\n",
      "Epoch 00243: val_loss did not improve\n",
      "2s - loss: 0.0505 - acc: 0.9856 - val_loss: 2.0115 - val_acc: 0.5740\n",
      "Epoch 245/1500\n",
      "Epoch 00244: val_loss did not improve\n",
      "2s - loss: 0.0501 - acc: 0.9888 - val_loss: 2.0211 - val_acc: 0.6073\n",
      "Epoch 246/1500\n",
      "Epoch 00245: val_loss did not improve\n",
      "2s - loss: 0.0736 - acc: 0.9788 - val_loss: 2.0054 - val_acc: 0.6163\n",
      "Epoch 247/1500\n",
      "Epoch 00246: val_loss did not improve\n",
      "2s - loss: 0.0520 - acc: 0.9857 - val_loss: 2.0722 - val_acc: 0.6042\n",
      "Epoch 248/1500\n",
      "Epoch 00247: val_loss did not improve\n",
      "2s - loss: 0.0585 - acc: 0.9841 - val_loss: 2.1341 - val_acc: 0.5952\n",
      "Epoch 249/1500\n",
      "Epoch 00248: val_loss did not improve\n",
      "2s - loss: 0.0591 - acc: 0.9832 - val_loss: 2.0268 - val_acc: 0.5861\n",
      "Epoch 250/1500\n",
      "Epoch 00249: val_loss did not improve\n",
      "2s - loss: 0.0788 - acc: 0.9755 - val_loss: 1.9251 - val_acc: 0.6405\n",
      "Epoch 251/1500\n",
      "Epoch 00250: val_loss did not improve\n",
      "2s - loss: 0.0455 - acc: 0.9872 - val_loss: 2.0030 - val_acc: 0.6042\n",
      "Epoch 252/1500\n",
      "Epoch 00251: val_loss did not improve\n",
      "2s - loss: 0.0685 - acc: 0.9747 - val_loss: 1.9182 - val_acc: 0.5982\n",
      "Epoch 253/1500\n",
      "Epoch 00252: val_loss did not improve\n",
      "2s - loss: 0.0476 - acc: 0.9856 - val_loss: 2.1055 - val_acc: 0.5710\n",
      "Epoch 254/1500\n",
      "Epoch 00253: val_loss did not improve\n",
      "2s - loss: 0.0411 - acc: 0.9858 - val_loss: 2.1857 - val_acc: 0.5861\n",
      "Epoch 255/1500\n",
      "Epoch 00254: val_loss did not improve\n",
      "2s - loss: 0.0677 - acc: 0.9746 - val_loss: 2.1075 - val_acc: 0.5559\n",
      "Epoch 256/1500\n",
      "Epoch 00255: val_loss did not improve\n",
      "2s - loss: 0.0825 - acc: 0.9697 - val_loss: 2.0640 - val_acc: 0.5710\n",
      "Epoch 257/1500\n",
      "Epoch 00256: val_loss did not improve\n",
      "2s - loss: 0.0481 - acc: 0.9864 - val_loss: 2.2559 - val_acc: 0.5650\n",
      "Epoch 258/1500\n",
      "Epoch 00257: val_loss did not improve\n",
      "2s - loss: 0.0702 - acc: 0.9769 - val_loss: 1.9884 - val_acc: 0.6224\n",
      "Epoch 259/1500\n",
      "Epoch 00258: val_loss did not improve\n",
      "2s - loss: 0.0556 - acc: 0.9794 - val_loss: 2.0576 - val_acc: 0.5921\n",
      "Epoch 260/1500\n",
      "Epoch 00259: val_loss did not improve\n",
      "2s - loss: 0.0667 - acc: 0.9833 - val_loss: 2.1574 - val_acc: 0.6073\n",
      "Epoch 261/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00260: val_loss did not improve\n",
      "2s - loss: 0.0547 - acc: 0.9849 - val_loss: 2.0597 - val_acc: 0.6073\n",
      "Epoch 262/1500\n",
      "Epoch 00261: val_loss did not improve\n",
      "2s - loss: 0.0577 - acc: 0.9818 - val_loss: 2.0099 - val_acc: 0.5921\n",
      "Epoch 263/1500\n",
      "Epoch 00262: val_loss did not improve\n",
      "2s - loss: 0.0687 - acc: 0.9778 - val_loss: 2.0164 - val_acc: 0.6073\n",
      "Epoch 264/1500\n",
      "Epoch 00263: val_loss did not improve\n",
      "2s - loss: 0.0653 - acc: 0.9818 - val_loss: 2.2022 - val_acc: 0.5982\n",
      "Epoch 265/1500\n",
      "Epoch 00264: val_loss did not improve\n",
      "2s - loss: 0.0543 - acc: 0.9833 - val_loss: 2.0340 - val_acc: 0.6224\n",
      "Epoch 266/1500\n",
      "Epoch 00265: val_loss did not improve\n",
      "2s - loss: 0.0375 - acc: 0.9904 - val_loss: 2.0876 - val_acc: 0.6103\n",
      "Epoch 267/1500\n",
      "Epoch 00266: val_loss did not improve\n",
      "2s - loss: 0.0438 - acc: 0.9850 - val_loss: 1.9844 - val_acc: 0.6314\n",
      "Epoch 268/1500\n",
      "Epoch 00267: val_loss did not improve\n",
      "2s - loss: 0.0884 - acc: 0.9787 - val_loss: 1.9348 - val_acc: 0.6163\n",
      "Epoch 269/1500\n",
      "Epoch 00268: val_loss did not improve\n",
      "2s - loss: 0.0565 - acc: 0.9795 - val_loss: 2.0832 - val_acc: 0.5952\n",
      "Epoch 270/1500\n",
      "Epoch 00269: val_loss did not improve\n",
      "2s - loss: 0.0567 - acc: 0.9833 - val_loss: 2.0673 - val_acc: 0.6254\n",
      "Epoch 271/1500\n",
      "Epoch 00270: val_loss did not improve\n",
      "2s - loss: 0.0491 - acc: 0.9857 - val_loss: 2.1971 - val_acc: 0.6042\n",
      "Epoch 272/1500\n",
      "Epoch 00271: val_loss did not improve\n",
      "2s - loss: 0.0683 - acc: 0.9786 - val_loss: 2.4144 - val_acc: 0.5619\n",
      "Epoch 273/1500\n",
      "Epoch 00272: val_loss did not improve\n",
      "2s - loss: 0.0775 - acc: 0.9772 - val_loss: 2.1364 - val_acc: 0.5891\n",
      "Epoch 274/1500\n",
      "Epoch 00273: val_loss did not improve\n",
      "2s - loss: 0.0479 - acc: 0.9857 - val_loss: 2.4065 - val_acc: 0.5710\n",
      "Epoch 275/1500\n",
      "Epoch 00274: val_loss did not improve\n",
      "2s - loss: 0.0583 - acc: 0.9824 - val_loss: 2.2051 - val_acc: 0.6073\n",
      "Epoch 276/1500\n",
      "Epoch 00275: val_loss did not improve\n",
      "2s - loss: 0.0560 - acc: 0.9825 - val_loss: 2.1274 - val_acc: 0.6012\n",
      "Epoch 277/1500\n",
      "Epoch 00276: val_loss did not improve\n",
      "2s - loss: 0.0461 - acc: 0.9881 - val_loss: 2.1468 - val_acc: 0.5770\n",
      "Epoch 278/1500\n",
      "Epoch 00277: val_loss did not improve\n",
      "2s - loss: 0.0393 - acc: 0.9905 - val_loss: 2.1899 - val_acc: 0.5770\n",
      "Epoch 279/1500\n",
      "Epoch 00278: val_loss did not improve\n",
      "2s - loss: 0.0592 - acc: 0.9810 - val_loss: 2.4437 - val_acc: 0.5891\n",
      "Epoch 280/1500\n",
      "Epoch 00279: val_loss did not improve\n",
      "2s - loss: 0.0359 - acc: 0.9896 - val_loss: 2.1404 - val_acc: 0.6073\n",
      "Epoch 281/1500\n",
      "Epoch 00280: val_loss did not improve\n",
      "2s - loss: 0.0537 - acc: 0.9867 - val_loss: 2.1228 - val_acc: 0.5921\n",
      "Epoch 282/1500\n",
      "Epoch 00281: val_loss did not improve\n",
      "2s - loss: 0.0413 - acc: 0.9881 - val_loss: 2.1621 - val_acc: 0.5680\n",
      "Epoch 283/1500\n",
      "Epoch 00282: val_loss did not improve\n",
      "2s - loss: 0.0856 - acc: 0.9771 - val_loss: 2.1717 - val_acc: 0.6224\n",
      "Epoch 284/1500\n",
      "Epoch 00283: val_loss did not improve\n",
      "2s - loss: 0.0486 - acc: 0.9816 - val_loss: 2.0959 - val_acc: 0.5891\n",
      "Epoch 285/1500\n",
      "Epoch 00284: val_loss did not improve\n",
      "2s - loss: 0.0430 - acc: 0.9872 - val_loss: 2.1314 - val_acc: 0.5861\n",
      "Epoch 286/1500\n",
      "Epoch 00285: val_loss did not improve\n",
      "2s - loss: 0.0461 - acc: 0.9888 - val_loss: 2.0363 - val_acc: 0.6042\n",
      "Epoch 287/1500\n",
      "Epoch 00286: val_loss did not improve\n",
      "2s - loss: 0.0522 - acc: 0.9849 - val_loss: 2.1667 - val_acc: 0.5861\n",
      "Epoch 288/1500\n",
      "Epoch 00287: val_loss did not improve\n",
      "2s - loss: 0.0652 - acc: 0.9816 - val_loss: 2.2931 - val_acc: 0.5710\n",
      "Epoch 289/1500\n",
      "Epoch 00288: val_loss did not improve\n",
      "2s - loss: 0.0487 - acc: 0.9848 - val_loss: 2.2873 - val_acc: 0.5831\n",
      "Epoch 290/1500\n",
      "Epoch 00289: val_loss did not improve\n",
      "2s - loss: 0.0426 - acc: 0.9848 - val_loss: 2.3589 - val_acc: 0.5861\n",
      "Epoch 291/1500\n",
      "Epoch 00290: val_loss did not improve\n",
      "2s - loss: 0.0540 - acc: 0.9825 - val_loss: 2.3142 - val_acc: 0.5891\n",
      "Epoch 292/1500\n",
      "Epoch 00291: val_loss did not improve\n",
      "2s - loss: 0.0654 - acc: 0.9777 - val_loss: 2.1752 - val_acc: 0.6224\n",
      "Epoch 293/1500\n",
      "Epoch 00292: val_loss did not improve\n",
      "2s - loss: 0.0551 - acc: 0.9841 - val_loss: 2.4116 - val_acc: 0.5529\n",
      "Epoch 294/1500\n",
      "Epoch 00293: val_loss did not improve\n",
      "2s - loss: 0.0729 - acc: 0.9764 - val_loss: 2.4599 - val_acc: 0.5861\n",
      "Epoch 295/1500\n",
      "Epoch 00294: val_loss did not improve\n",
      "2s - loss: 0.0409 - acc: 0.9866 - val_loss: 2.2140 - val_acc: 0.5982\n",
      "Epoch 296/1500\n",
      "Epoch 00295: val_loss did not improve\n",
      "2s - loss: 0.0581 - acc: 0.9858 - val_loss: 2.2418 - val_acc: 0.5891\n",
      "Epoch 297/1500\n",
      "Epoch 00296: val_loss did not improve\n",
      "2s - loss: 0.0383 - acc: 0.9864 - val_loss: 2.1375 - val_acc: 0.6042\n",
      "Epoch 298/1500\n",
      "Epoch 00297: val_loss did not improve\n",
      "2s - loss: 0.0778 - acc: 0.9717 - val_loss: 2.4277 - val_acc: 0.5680\n",
      "Epoch 299/1500\n",
      "Epoch 00298: val_loss did not improve\n",
      "2s - loss: 0.0521 - acc: 0.9840 - val_loss: 2.2014 - val_acc: 0.6012\n",
      "Epoch 300/1500\n",
      "Epoch 00299: val_loss did not improve\n",
      "2s - loss: 0.0381 - acc: 0.9856 - val_loss: 2.0717 - val_acc: 0.6224\n",
      "Epoch 301/1500\n",
      "Epoch 00300: val_loss did not improve\n",
      "2s - loss: 0.0594 - acc: 0.9785 - val_loss: 2.3758 - val_acc: 0.5680\n",
      "Epoch 302/1500\n",
      "Epoch 00301: val_loss did not improve\n",
      "2s - loss: 0.0356 - acc: 0.9912 - val_loss: 2.2708 - val_acc: 0.5861\n",
      "Epoch 303/1500\n",
      "Epoch 00302: val_loss did not improve\n",
      "2s - loss: 0.0488 - acc: 0.9793 - val_loss: 2.3149 - val_acc: 0.5982\n",
      "Epoch 304/1500\n",
      "Epoch 00303: val_loss did not improve\n",
      "2s - loss: 0.0420 - acc: 0.9833 - val_loss: 2.1958 - val_acc: 0.5921\n",
      "Epoch 305/1500\n",
      "Epoch 00304: val_loss did not improve\n",
      "2s - loss: 0.0407 - acc: 0.9888 - val_loss: 2.3048 - val_acc: 0.6012\n",
      "Epoch 306/1500\n",
      "Epoch 00305: val_loss did not improve\n",
      "2s - loss: 0.0406 - acc: 0.9880 - val_loss: 2.4466 - val_acc: 0.5801\n",
      "Epoch 307/1500\n",
      "Epoch 00306: val_loss did not improve\n",
      "2s - loss: 0.0355 - acc: 0.9904 - val_loss: 2.2721 - val_acc: 0.5861\n",
      "Epoch 308/1500\n",
      "Epoch 00307: val_loss did not improve\n",
      "2s - loss: 0.0452 - acc: 0.9833 - val_loss: 2.3335 - val_acc: 0.6073\n",
      "Epoch 309/1500\n",
      "Epoch 00308: val_loss did not improve\n",
      "2s - loss: 0.0472 - acc: 0.9816 - val_loss: 2.3054 - val_acc: 0.5952\n",
      "Epoch 310/1500\n",
      "Epoch 00309: val_loss did not improve\n",
      "2s - loss: 0.0435 - acc: 0.9824 - val_loss: 2.3488 - val_acc: 0.5801\n",
      "Epoch 311/1500\n",
      "Epoch 00310: val_loss did not improve\n",
      "2s - loss: 0.0499 - acc: 0.9866 - val_loss: 2.2489 - val_acc: 0.5891\n",
      "Epoch 312/1500\n",
      "Epoch 00311: val_loss did not improve\n",
      "2s - loss: 0.0341 - acc: 0.9889 - val_loss: 2.3678 - val_acc: 0.5589\n",
      "Epoch 313/1500\n",
      "Epoch 00312: val_loss did not improve\n",
      "2s - loss: 0.0493 - acc: 0.9801 - val_loss: 2.4916 - val_acc: 0.5559\n",
      "Epoch 314/1500\n",
      "Epoch 00313: val_loss did not improve\n",
      "2s - loss: 0.0337 - acc: 0.9872 - val_loss: 2.1422 - val_acc: 0.6103\n",
      "Epoch 315/1500\n",
      "Epoch 00314: val_loss did not improve\n",
      "2s - loss: 0.0399 - acc: 0.9872 - val_loss: 2.1334 - val_acc: 0.5921\n",
      "Epoch 316/1500\n",
      "Epoch 00315: val_loss did not improve\n",
      "2s - loss: 0.0385 - acc: 0.9888 - val_loss: 2.3910 - val_acc: 0.5680\n",
      "Epoch 317/1500\n",
      "Epoch 00316: val_loss did not improve\n",
      "2s - loss: 0.0496 - acc: 0.9819 - val_loss: 2.1941 - val_acc: 0.6133\n",
      "Epoch 318/1500\n",
      "Epoch 00317: val_loss did not improve\n",
      "2s - loss: 0.0552 - acc: 0.9842 - val_loss: 2.1889 - val_acc: 0.5740\n",
      "Epoch 319/1500\n",
      "Epoch 00318: val_loss did not improve\n",
      "2s - loss: 0.0297 - acc: 0.9912 - val_loss: 2.4013 - val_acc: 0.5770\n",
      "Epoch 320/1500\n",
      "Epoch 00319: val_loss did not improve\n",
      "2s - loss: 0.0613 - acc: 0.9771 - val_loss: 2.3444 - val_acc: 0.6042\n",
      "Epoch 321/1500\n",
      "Epoch 00320: val_loss did not improve\n",
      "2s - loss: 0.0324 - acc: 0.9864 - val_loss: 2.2633 - val_acc: 0.5740\n",
      "Epoch 322/1500\n",
      "Epoch 00321: val_loss did not improve\n",
      "2s - loss: 0.0395 - acc: 0.9888 - val_loss: 2.1416 - val_acc: 0.6103\n",
      "Epoch 323/1500\n",
      "Epoch 00322: val_loss did not improve\n",
      "2s - loss: 0.0428 - acc: 0.9897 - val_loss: 2.2713 - val_acc: 0.5619\n",
      "Epoch 324/1500\n",
      "Epoch 00323: val_loss did not improve\n",
      "2s - loss: 0.0399 - acc: 0.9850 - val_loss: 2.0286 - val_acc: 0.6254\n",
      "Epoch 325/1500\n",
      "Epoch 00324: val_loss did not improve\n",
      "2s - loss: 0.0394 - acc: 0.9865 - val_loss: 2.2055 - val_acc: 0.6073\n",
      "Epoch 326/1500\n",
      "Epoch 00325: val_loss did not improve\n",
      "2s - loss: 0.0337 - acc: 0.9904 - val_loss: 2.3209 - val_acc: 0.5740\n",
      "Epoch 327/1500\n",
      "Epoch 00326: val_loss did not improve\n",
      "2s - loss: 0.0853 - acc: 0.9787 - val_loss: 2.4718 - val_acc: 0.6012\n",
      "Epoch 328/1500\n",
      "Epoch 00327: val_loss did not improve\n",
      "2s - loss: 0.0516 - acc: 0.9827 - val_loss: 2.2632 - val_acc: 0.6103\n",
      "Epoch 329/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00328: val_loss did not improve\n",
      "2s - loss: 0.0379 - acc: 0.9840 - val_loss: 2.2702 - val_acc: 0.5861\n",
      "Epoch 330/1500\n",
      "Epoch 00329: val_loss did not improve\n",
      "2s - loss: 0.0442 - acc: 0.9856 - val_loss: 2.1975 - val_acc: 0.6103\n",
      "Epoch 331/1500\n",
      "Epoch 00330: val_loss did not improve\n",
      "2s - loss: 0.0568 - acc: 0.9780 - val_loss: 2.2528 - val_acc: 0.5952\n",
      "Epoch 332/1500\n",
      "Epoch 00331: val_loss did not improve\n",
      "2s - loss: 0.0584 - acc: 0.9788 - val_loss: 2.3007 - val_acc: 0.5740\n",
      "Epoch 333/1500\n",
      "Epoch 00332: val_loss did not improve\n",
      "2s - loss: 0.0434 - acc: 0.9865 - val_loss: 2.2190 - val_acc: 0.5952\n",
      "Epoch 334/1500\n",
      "Epoch 00333: val_loss did not improve\n",
      "2s - loss: 0.0309 - acc: 0.9889 - val_loss: 2.2887 - val_acc: 0.6012\n",
      "Epoch 335/1500\n",
      "Epoch 00334: val_loss did not improve\n",
      "2s - loss: 0.0293 - acc: 0.9912 - val_loss: 2.2138 - val_acc: 0.6073\n",
      "Epoch 336/1500\n",
      "Epoch 00335: val_loss did not improve\n",
      "2s - loss: 0.0399 - acc: 0.9896 - val_loss: 2.4628 - val_acc: 0.5650\n",
      "Epoch 337/1500\n",
      "Epoch 00336: val_loss did not improve\n",
      "2s - loss: 0.0327 - acc: 0.9873 - val_loss: 2.1583 - val_acc: 0.5952\n",
      "Epoch 338/1500\n",
      "Epoch 00337: val_loss did not improve\n",
      "2s - loss: 0.0516 - acc: 0.9808 - val_loss: 2.4294 - val_acc: 0.5680\n",
      "Epoch 339/1500\n",
      "Epoch 00338: val_loss did not improve\n",
      "2s - loss: 0.0510 - acc: 0.9882 - val_loss: 2.3185 - val_acc: 0.6042\n",
      "Epoch 340/1500\n",
      "Epoch 00339: val_loss did not improve\n",
      "2s - loss: 0.0370 - acc: 0.9883 - val_loss: 2.6492 - val_acc: 0.5227\n",
      "Epoch 341/1500\n",
      "Epoch 00340: val_loss did not improve\n",
      "2s - loss: 0.0410 - acc: 0.9880 - val_loss: 2.3864 - val_acc: 0.5861\n",
      "Epoch 342/1500\n",
      "Epoch 00341: val_loss did not improve\n",
      "2s - loss: 0.0331 - acc: 0.9889 - val_loss: 2.2966 - val_acc: 0.6073\n",
      "Epoch 343/1500\n",
      "Epoch 00342: val_loss did not improve\n",
      "2s - loss: 0.0826 - acc: 0.9750 - val_loss: 2.3453 - val_acc: 0.5740\n",
      "Epoch 344/1500\n",
      "Epoch 00343: val_loss did not improve\n",
      "2s - loss: 0.0454 - acc: 0.9882 - val_loss: 2.3329 - val_acc: 0.6103\n",
      "Epoch 345/1500\n",
      "Epoch 00344: val_loss did not improve\n",
      "2s - loss: 0.0296 - acc: 0.9920 - val_loss: 2.3099 - val_acc: 0.5891\n",
      "Epoch 346/1500\n",
      "Epoch 00345: val_loss did not improve\n",
      "2s - loss: 0.0488 - acc: 0.9866 - val_loss: 2.3183 - val_acc: 0.5861\n",
      "Epoch 347/1500\n",
      "Epoch 00346: val_loss did not improve\n",
      "2s - loss: 0.0279 - acc: 0.9888 - val_loss: 2.5099 - val_acc: 0.5801\n",
      "Epoch 348/1500\n",
      "Epoch 00347: val_loss did not improve\n",
      "2s - loss: 0.0373 - acc: 0.9889 - val_loss: 2.4440 - val_acc: 0.5982\n",
      "Epoch 349/1500\n",
      "Epoch 00348: val_loss did not improve\n",
      "2s - loss: 0.0228 - acc: 0.9944 - val_loss: 2.4044 - val_acc: 0.5921\n",
      "Epoch 350/1500\n",
      "Epoch 00349: val_loss did not improve\n",
      "2s - loss: 0.0352 - acc: 0.9888 - val_loss: 2.2548 - val_acc: 0.5770\n",
      "Epoch 351/1500\n",
      "Epoch 00350: val_loss did not improve\n",
      "2s - loss: 0.0416 - acc: 0.9825 - val_loss: 2.4162 - val_acc: 0.5619\n",
      "Epoch 352/1500\n",
      "Epoch 00351: val_loss did not improve\n",
      "2s - loss: 0.0179 - acc: 0.9968 - val_loss: 2.1985 - val_acc: 0.5710\n",
      "Epoch 353/1500\n",
      "Epoch 00352: val_loss did not improve\n",
      "2s - loss: 0.0521 - acc: 0.9851 - val_loss: 2.2943 - val_acc: 0.5619\n",
      "Epoch 354/1500\n",
      "Epoch 00353: val_loss did not improve\n",
      "2s - loss: 0.0551 - acc: 0.9809 - val_loss: 2.2427 - val_acc: 0.6042\n",
      "Epoch 355/1500\n",
      "Epoch 00354: val_loss did not improve\n",
      "2s - loss: 0.0245 - acc: 0.9905 - val_loss: 2.4798 - val_acc: 0.5891\n",
      "Epoch 356/1500\n",
      "Epoch 00355: val_loss did not improve\n",
      "2s - loss: 0.0437 - acc: 0.9840 - val_loss: 2.4331 - val_acc: 0.5891\n",
      "Epoch 357/1500\n",
      "Epoch 00356: val_loss did not improve\n",
      "2s - loss: 0.0270 - acc: 0.9912 - val_loss: 2.2356 - val_acc: 0.6042\n",
      "Epoch 358/1500\n",
      "Epoch 00357: val_loss did not improve\n",
      "2s - loss: 0.0372 - acc: 0.9889 - val_loss: 2.5662 - val_acc: 0.5770\n",
      "Epoch 359/1500\n",
      "Epoch 00358: val_loss did not improve\n",
      "2s - loss: 0.0173 - acc: 0.9960 - val_loss: 2.3229 - val_acc: 0.6163\n",
      "Epoch 360/1500\n",
      "Epoch 00359: val_loss did not improve\n",
      "2s - loss: 0.0376 - acc: 0.9865 - val_loss: 2.1878 - val_acc: 0.5891\n",
      "Epoch 361/1500\n",
      "Epoch 00360: val_loss did not improve\n",
      "2s - loss: 0.0181 - acc: 0.9952 - val_loss: 2.4050 - val_acc: 0.5952\n",
      "Epoch 362/1500\n",
      "Epoch 00361: val_loss did not improve\n",
      "2s - loss: 0.0335 - acc: 0.9866 - val_loss: 2.2859 - val_acc: 0.6163\n",
      "Epoch 363/1500\n",
      "Epoch 00362: val_loss did not improve\n",
      "2s - loss: 0.0327 - acc: 0.9896 - val_loss: 2.2035 - val_acc: 0.6193\n",
      "Epoch 364/1500\n",
      "Epoch 00363: val_loss did not improve\n",
      "2s - loss: 0.0302 - acc: 0.9904 - val_loss: 2.2276 - val_acc: 0.6254\n",
      "Epoch 365/1500\n",
      "Epoch 00364: val_loss did not improve\n",
      "2s - loss: 0.0208 - acc: 0.9952 - val_loss: 2.2486 - val_acc: 0.6133\n",
      "Epoch 366/1500\n",
      "Epoch 00365: val_loss did not improve\n",
      "2s - loss: 0.0431 - acc: 0.9841 - val_loss: 2.4982 - val_acc: 0.5801\n",
      "Epoch 367/1500\n",
      "Epoch 00366: val_loss did not improve\n",
      "2s - loss: 0.0306 - acc: 0.9896 - val_loss: 2.4178 - val_acc: 0.6012\n",
      "Epoch 368/1500\n",
      "Epoch 00367: val_loss did not improve\n",
      "2s - loss: 0.0343 - acc: 0.9896 - val_loss: 2.6359 - val_acc: 0.5680\n",
      "Epoch 369/1500\n",
      "Epoch 00368: val_loss did not improve\n",
      "2s - loss: 0.0346 - acc: 0.9873 - val_loss: 2.5663 - val_acc: 0.5831\n",
      "Epoch 370/1500\n",
      "Epoch 00369: val_loss did not improve\n",
      "2s - loss: 0.0455 - acc: 0.9834 - val_loss: 2.5286 - val_acc: 0.5921\n",
      "Epoch 371/1500\n",
      "Epoch 00370: val_loss did not improve\n",
      "2s - loss: 0.0392 - acc: 0.9873 - val_loss: 2.3000 - val_acc: 0.6284\n",
      "Epoch 372/1500\n",
      "Epoch 00371: val_loss did not improve\n",
      "2s - loss: 0.0481 - acc: 0.9811 - val_loss: 2.1885 - val_acc: 0.6163\n",
      "Epoch 373/1500\n",
      "Epoch 00372: val_loss did not improve\n",
      "2s - loss: 0.0327 - acc: 0.9904 - val_loss: 2.3965 - val_acc: 0.5921\n",
      "Epoch 374/1500\n",
      "Epoch 00373: val_loss did not improve\n",
      "2s - loss: 0.0342 - acc: 0.9912 - val_loss: 2.5511 - val_acc: 0.5770\n",
      "Epoch 375/1500\n",
      "Epoch 00374: val_loss did not improve\n",
      "2s - loss: 0.0337 - acc: 0.9856 - val_loss: 2.4564 - val_acc: 0.6133\n",
      "Epoch 376/1500\n",
      "Epoch 00375: val_loss did not improve\n",
      "2s - loss: 0.0317 - acc: 0.9912 - val_loss: 2.4334 - val_acc: 0.5982\n",
      "Epoch 377/1500\n",
      "Epoch 00376: val_loss did not improve\n",
      "2s - loss: 0.0750 - acc: 0.9748 - val_loss: 2.4260 - val_acc: 0.6284\n",
      "Epoch 378/1500\n",
      "Epoch 00377: val_loss did not improve\n",
      "2s - loss: 0.0297 - acc: 0.9929 - val_loss: 2.4019 - val_acc: 0.5831\n",
      "Epoch 379/1500\n",
      "Epoch 00378: val_loss did not improve\n",
      "2s - loss: 0.0189 - acc: 0.9944 - val_loss: 2.1685 - val_acc: 0.6254\n",
      "Epoch 380/1500\n",
      "Epoch 00379: val_loss did not improve\n",
      "2s - loss: 0.0628 - acc: 0.9803 - val_loss: 2.2026 - val_acc: 0.6103\n",
      "Epoch 381/1500\n",
      "Epoch 00380: val_loss did not improve\n",
      "2s - loss: 0.0205 - acc: 0.9944 - val_loss: 2.3547 - val_acc: 0.5952\n",
      "Epoch 382/1500\n",
      "Epoch 00381: val_loss did not improve\n",
      "2s - loss: 0.0361 - acc: 0.9857 - val_loss: 2.5532 - val_acc: 0.5801\n",
      "Epoch 383/1500\n",
      "Epoch 00382: val_loss did not improve\n",
      "2s - loss: 0.0385 - acc: 0.9888 - val_loss: 2.1347 - val_acc: 0.6375\n",
      "Epoch 384/1500\n",
      "Epoch 00383: val_loss did not improve\n",
      "2s - loss: 0.0263 - acc: 0.9920 - val_loss: 2.5208 - val_acc: 0.5982\n",
      "Epoch 385/1500\n",
      "Epoch 00384: val_loss did not improve\n",
      "2s - loss: 0.0338 - acc: 0.9888 - val_loss: 2.2430 - val_acc: 0.6163\n",
      "Epoch 386/1500\n",
      "Epoch 00385: val_loss did not improve\n",
      "2s - loss: 0.0331 - acc: 0.9896 - val_loss: 2.4793 - val_acc: 0.5861\n",
      "Epoch 387/1500\n",
      "Epoch 00386: val_loss did not improve\n",
      "2s - loss: 0.0310 - acc: 0.9905 - val_loss: 2.3513 - val_acc: 0.6314\n",
      "Epoch 388/1500\n",
      "Epoch 00387: val_loss did not improve\n",
      "2s - loss: 0.0314 - acc: 0.9905 - val_loss: 2.4705 - val_acc: 0.5831\n",
      "Epoch 389/1500\n",
      "Epoch 00388: val_loss did not improve\n",
      "2s - loss: 0.0274 - acc: 0.9921 - val_loss: 2.8581 - val_acc: 0.5740\n",
      "Epoch 390/1500\n",
      "Epoch 00389: val_loss did not improve\n",
      "2s - loss: 0.0161 - acc: 0.9976 - val_loss: 2.2691 - val_acc: 0.6193\n",
      "Epoch 391/1500\n",
      "Epoch 00390: val_loss did not improve\n",
      "2s - loss: 0.0476 - acc: 0.9883 - val_loss: 2.4559 - val_acc: 0.5952\n",
      "Epoch 392/1500\n",
      "Epoch 00391: val_loss did not improve\n",
      "2s - loss: 0.0462 - acc: 0.9851 - val_loss: 2.3897 - val_acc: 0.6103\n",
      "Epoch 393/1500\n",
      "Epoch 00392: val_loss did not improve\n",
      "2s - loss: 0.0231 - acc: 0.9896 - val_loss: 2.5383 - val_acc: 0.5891\n",
      "Epoch 394/1500\n",
      "Epoch 00393: val_loss did not improve\n",
      "2s - loss: 0.0216 - acc: 0.9905 - val_loss: 2.5757 - val_acc: 0.5861\n",
      "Epoch 395/1500\n",
      "Epoch 00394: val_loss did not improve\n",
      "2s - loss: 0.0171 - acc: 0.9968 - val_loss: 2.7254 - val_acc: 0.5498\n",
      "Epoch 396/1500\n",
      "Epoch 00395: val_loss did not improve\n",
      "2s - loss: 0.0210 - acc: 0.9936 - val_loss: 2.5499 - val_acc: 0.5770\n",
      "Epoch 397/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00396: val_loss did not improve\n",
      "2s - loss: 0.0276 - acc: 0.9904 - val_loss: 2.4522 - val_acc: 0.5710\n",
      "Epoch 398/1500\n",
      "Epoch 00397: val_loss did not improve\n",
      "2s - loss: 0.0202 - acc: 0.9944 - val_loss: 2.6460 - val_acc: 0.5891\n",
      "Epoch 399/1500\n",
      "Epoch 00398: val_loss did not improve\n",
      "2s - loss: 0.0352 - acc: 0.9873 - val_loss: 2.5379 - val_acc: 0.6224\n",
      "Epoch 400/1500\n",
      "Epoch 00399: val_loss did not improve\n",
      "2s - loss: 0.0455 - acc: 0.9866 - val_loss: 2.4393 - val_acc: 0.5740\n",
      "Epoch 401/1500\n",
      "Epoch 00400: val_loss did not improve\n",
      "2s - loss: 0.0372 - acc: 0.9858 - val_loss: 2.2992 - val_acc: 0.6284\n",
      "Epoch 402/1500\n",
      "Epoch 00401: val_loss did not improve\n",
      "2s - loss: 0.0286 - acc: 0.9945 - val_loss: 2.3290 - val_acc: 0.6133\n",
      "Epoch 403/1500\n",
      "Epoch 00402: val_loss did not improve\n",
      "2s - loss: 0.0246 - acc: 0.9936 - val_loss: 2.3666 - val_acc: 0.6073\n",
      "Epoch 404/1500\n",
      "Epoch 00403: val_loss did not improve\n",
      "2s - loss: 0.0191 - acc: 0.9944 - val_loss: 2.3978 - val_acc: 0.6193\n",
      "Epoch 405/1500\n",
      "Epoch 00404: val_loss did not improve\n",
      "2s - loss: 0.0211 - acc: 0.9912 - val_loss: 2.5595 - val_acc: 0.5952\n",
      "Epoch 406/1500\n",
      "Epoch 00405: val_loss did not improve\n",
      "2s - loss: 0.0260 - acc: 0.9897 - val_loss: 2.4918 - val_acc: 0.6103\n",
      "Epoch 407/1500\n",
      "Epoch 00406: val_loss did not improve\n",
      "2s - loss: 0.0276 - acc: 0.9896 - val_loss: 2.6313 - val_acc: 0.5891\n",
      "Epoch 408/1500\n",
      "Epoch 00407: val_loss did not improve\n",
      "2s - loss: 0.0163 - acc: 0.9920 - val_loss: 2.5370 - val_acc: 0.5891\n",
      "Epoch 409/1500\n",
      "Epoch 00408: val_loss did not improve\n",
      "2s - loss: 0.0478 - acc: 0.9865 - val_loss: 2.6152 - val_acc: 0.5861\n",
      "Epoch 410/1500\n",
      "Epoch 00409: val_loss did not improve\n",
      "2s - loss: 0.0373 - acc: 0.9889 - val_loss: 2.5127 - val_acc: 0.5740\n",
      "Epoch 411/1500\n",
      "Epoch 00410: val_loss did not improve\n",
      "2s - loss: 0.0215 - acc: 0.9904 - val_loss: 2.6052 - val_acc: 0.5680\n",
      "Epoch 412/1500\n",
      "Epoch 00411: val_loss did not improve\n",
      "2s - loss: 0.0349 - acc: 0.9896 - val_loss: 2.4726 - val_acc: 0.5952\n",
      "Epoch 413/1500\n",
      "Epoch 00412: val_loss did not improve\n",
      "2s - loss: 0.0273 - acc: 0.9928 - val_loss: 2.6917 - val_acc: 0.5770\n",
      "Epoch 414/1500\n",
      "Epoch 00413: val_loss did not improve\n",
      "2s - loss: 0.0117 - acc: 0.9976 - val_loss: 2.3551 - val_acc: 0.5921\n",
      "Epoch 415/1500\n",
      "Epoch 00414: val_loss did not improve\n",
      "2s - loss: 0.0688 - acc: 0.9827 - val_loss: 2.4344 - val_acc: 0.5680\n",
      "Epoch 416/1500\n",
      "Epoch 00415: val_loss did not improve\n",
      "2s - loss: 0.0422 - acc: 0.9889 - val_loss: 2.7169 - val_acc: 0.5680\n",
      "Epoch 417/1500\n",
      "Epoch 00416: val_loss did not improve\n",
      "2s - loss: 0.0353 - acc: 0.9889 - val_loss: 2.6929 - val_acc: 0.5801\n",
      "Epoch 418/1500\n",
      "Epoch 00417: val_loss did not improve\n",
      "2s - loss: 0.0145 - acc: 0.9953 - val_loss: 2.4880 - val_acc: 0.6073\n",
      "Epoch 419/1500\n",
      "Epoch 00418: val_loss did not improve\n",
      "2s - loss: 0.0381 - acc: 0.9880 - val_loss: 2.6412 - val_acc: 0.6133\n",
      "Epoch 420/1500\n",
      "Epoch 00419: val_loss did not improve\n",
      "2s - loss: 0.0237 - acc: 0.9936 - val_loss: 2.3396 - val_acc: 0.6163\n",
      "Epoch 421/1500\n",
      "Epoch 00420: val_loss did not improve\n",
      "2s - loss: 0.0169 - acc: 0.9936 - val_loss: 2.5635 - val_acc: 0.5740\n",
      "Epoch 422/1500\n",
      "Epoch 00421: val_loss did not improve\n",
      "2s - loss: 0.0188 - acc: 0.9937 - val_loss: 2.5367 - val_acc: 0.6103\n",
      "Epoch 423/1500\n",
      "Epoch 00422: val_loss did not improve\n",
      "2s - loss: 0.0331 - acc: 0.9881 - val_loss: 2.5485 - val_acc: 0.5861\n",
      "Epoch 424/1500\n",
      "Epoch 00423: val_loss did not improve\n",
      "2s - loss: 0.0358 - acc: 0.9913 - val_loss: 2.6458 - val_acc: 0.5982\n",
      "Epoch 425/1500\n",
      "Epoch 00424: val_loss did not improve\n",
      "2s - loss: 0.0191 - acc: 0.9960 - val_loss: 2.4941 - val_acc: 0.5801\n",
      "Epoch 426/1500\n",
      "Epoch 00425: val_loss did not improve\n",
      "2s - loss: 0.0127 - acc: 0.9960 - val_loss: 2.6422 - val_acc: 0.5831\n",
      "Epoch 427/1500\n",
      "Epoch 00426: val_loss did not improve\n",
      "2s - loss: 0.0302 - acc: 0.9905 - val_loss: 2.4628 - val_acc: 0.5952\n",
      "Epoch 428/1500\n",
      "Epoch 00427: val_loss did not improve\n",
      "2s - loss: 0.0280 - acc: 0.9922 - val_loss: 2.4294 - val_acc: 0.6042\n",
      "Epoch 429/1500\n",
      "Epoch 00428: val_loss did not improve\n",
      "2s - loss: 0.0335 - acc: 0.9922 - val_loss: 2.5793 - val_acc: 0.5770\n",
      "Epoch 430/1500\n",
      "Epoch 00429: val_loss did not improve\n",
      "2s - loss: 0.0366 - acc: 0.9888 - val_loss: 2.3676 - val_acc: 0.6042\n",
      "Epoch 431/1500\n",
      "Epoch 00430: val_loss did not improve\n",
      "2s - loss: 0.0226 - acc: 0.9920 - val_loss: 2.6704 - val_acc: 0.5921\n",
      "Epoch 432/1500\n",
      "Epoch 00431: val_loss did not improve\n",
      "2s - loss: 0.0257 - acc: 0.9906 - val_loss: 2.4534 - val_acc: 0.5740\n",
      "Epoch 433/1500\n",
      "Epoch 00432: val_loss did not improve\n",
      "2s - loss: 0.0316 - acc: 0.9881 - val_loss: 2.5040 - val_acc: 0.5861\n",
      "Epoch 434/1500\n",
      "Epoch 00433: val_loss did not improve\n",
      "2s - loss: 0.0194 - acc: 0.9936 - val_loss: 2.7852 - val_acc: 0.5559\n",
      "Epoch 435/1500\n",
      "Epoch 00434: val_loss did not improve\n",
      "2s - loss: 0.0179 - acc: 0.9945 - val_loss: 2.6204 - val_acc: 0.5861\n",
      "Epoch 436/1500\n",
      "Epoch 00435: val_loss did not improve\n",
      "2s - loss: 0.0210 - acc: 0.9912 - val_loss: 2.4466 - val_acc: 0.5982\n",
      "Epoch 437/1500\n",
      "Epoch 00436: val_loss did not improve\n",
      "2s - loss: 0.0321 - acc: 0.9888 - val_loss: 2.4156 - val_acc: 0.6073\n",
      "Epoch 438/1500\n",
      "Epoch 00437: val_loss did not improve\n",
      "2s - loss: 0.0125 - acc: 0.9960 - val_loss: 2.5198 - val_acc: 0.6042\n",
      "Epoch 439/1500\n",
      "Epoch 00438: val_loss did not improve\n",
      "2s - loss: 0.0175 - acc: 0.9944 - val_loss: 2.7610 - val_acc: 0.5831\n",
      "Epoch 440/1500\n",
      "Epoch 00439: val_loss did not improve\n",
      "2s - loss: 0.0291 - acc: 0.9890 - val_loss: 2.5625 - val_acc: 0.5861\n",
      "Epoch 441/1500\n",
      "Epoch 00440: val_loss did not improve\n",
      "2s - loss: 0.0177 - acc: 0.9952 - val_loss: 2.6967 - val_acc: 0.5831\n",
      "Epoch 442/1500\n",
      "Epoch 00441: val_loss did not improve\n",
      "2s - loss: 0.0282 - acc: 0.9928 - val_loss: 2.2292 - val_acc: 0.6163\n",
      "Epoch 443/1500\n",
      "Epoch 00442: val_loss did not improve\n",
      "2s - loss: 0.0168 - acc: 0.9960 - val_loss: 2.7663 - val_acc: 0.5619\n",
      "Epoch 444/1500\n",
      "Epoch 00443: val_loss did not improve\n",
      "2s - loss: 0.0219 - acc: 0.9912 - val_loss: 2.5068 - val_acc: 0.5861\n",
      "Epoch 445/1500\n",
      "Epoch 00444: val_loss did not improve\n",
      "2s - loss: 0.0217 - acc: 0.9921 - val_loss: 2.3027 - val_acc: 0.6224\n",
      "Epoch 446/1500\n",
      "Epoch 00445: val_loss did not improve\n",
      "2s - loss: 0.0318 - acc: 0.9881 - val_loss: 2.5773 - val_acc: 0.6042\n",
      "Epoch 447/1500\n",
      "Epoch 00446: val_loss did not improve\n",
      "2s - loss: 0.0188 - acc: 0.9944 - val_loss: 2.8130 - val_acc: 0.6133\n",
      "Epoch 448/1500\n",
      "Epoch 00447: val_loss did not improve\n",
      "2s - loss: 0.0207 - acc: 0.9944 - val_loss: 2.3809 - val_acc: 0.6073\n",
      "Epoch 449/1500\n",
      "Epoch 00448: val_loss did not improve\n",
      "2s - loss: 0.0148 - acc: 0.9953 - val_loss: 2.6180 - val_acc: 0.6042\n",
      "Epoch 450/1500\n",
      "Epoch 00449: val_loss did not improve\n",
      "2s - loss: 0.0210 - acc: 0.9904 - val_loss: 2.6499 - val_acc: 0.5710\n",
      "Epoch 451/1500\n",
      "Epoch 00450: val_loss did not improve\n",
      "2s - loss: 0.1098 - acc: 0.9883 - val_loss: 2.5709 - val_acc: 0.5921\n",
      "Epoch 452/1500\n",
      "Epoch 00451: val_loss did not improve\n",
      "2s - loss: 0.0251 - acc: 0.9896 - val_loss: 2.4633 - val_acc: 0.6103\n",
      "Epoch 453/1500\n",
      "Epoch 00452: val_loss did not improve\n",
      "2s - loss: 0.0267 - acc: 0.9897 - val_loss: 2.6394 - val_acc: 0.5801\n",
      "Epoch 454/1500\n",
      "Epoch 00453: val_loss did not improve\n",
      "2s - loss: 0.0211 - acc: 0.9928 - val_loss: 2.7608 - val_acc: 0.5770\n",
      "Epoch 455/1500\n",
      "Epoch 00454: val_loss did not improve\n",
      "2s - loss: 0.0285 - acc: 0.9904 - val_loss: 2.8220 - val_acc: 0.5861\n",
      "Epoch 456/1500\n",
      "Epoch 00455: val_loss did not improve\n",
      "2s - loss: 0.0269 - acc: 0.9928 - val_loss: 2.5042 - val_acc: 0.6224\n",
      "Epoch 457/1500\n",
      "Epoch 00456: val_loss did not improve\n",
      "2s - loss: 0.0187 - acc: 0.9952 - val_loss: 2.5296 - val_acc: 0.6042\n",
      "Epoch 458/1500\n",
      "Epoch 00457: val_loss did not improve\n",
      "2s - loss: 0.0260 - acc: 0.9905 - val_loss: 2.8753 - val_acc: 0.5529\n",
      "Epoch 459/1500\n",
      "Epoch 00458: val_loss did not improve\n",
      "2s - loss: 0.0228 - acc: 0.9928 - val_loss: 2.6147 - val_acc: 0.5770\n",
      "Epoch 460/1500\n",
      "Epoch 00459: val_loss did not improve\n",
      "2s - loss: 0.0112 - acc: 0.9976 - val_loss: 2.8014 - val_acc: 0.5438\n",
      "Epoch 461/1500\n",
      "Epoch 00460: val_loss did not improve\n",
      "2s - loss: 0.0218 - acc: 0.9898 - val_loss: 2.7714 - val_acc: 0.5589\n",
      "Epoch 462/1500\n",
      "Epoch 00461: val_loss did not improve\n",
      "2s - loss: 0.0186 - acc: 0.9944 - val_loss: 2.4181 - val_acc: 0.5952\n",
      "Epoch 463/1500\n",
      "Epoch 00462: val_loss did not improve\n",
      "2s - loss: 0.0260 - acc: 0.9848 - val_loss: 2.7011 - val_acc: 0.5740\n",
      "Epoch 464/1500\n",
      "Epoch 00463: val_loss did not improve\n",
      "2s - loss: 0.0387 - acc: 0.9929 - val_loss: 2.8121 - val_acc: 0.6133\n",
      "Epoch 465/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00464: val_loss did not improve\n",
      "2s - loss: 0.0597 - acc: 0.9820 - val_loss: 2.7055 - val_acc: 0.6042\n",
      "Epoch 466/1500\n",
      "Epoch 00465: val_loss did not improve\n",
      "2s - loss: 0.0174 - acc: 0.9930 - val_loss: 2.6884 - val_acc: 0.6042\n",
      "Epoch 467/1500\n",
      "Epoch 00466: val_loss did not improve\n",
      "2s - loss: 0.0163 - acc: 0.9952 - val_loss: 2.7017 - val_acc: 0.5891\n",
      "Epoch 468/1500\n",
      "Epoch 00467: val_loss did not improve\n",
      "2s - loss: 0.0266 - acc: 0.9857 - val_loss: 2.7446 - val_acc: 0.5861\n",
      "Epoch 469/1500\n",
      "Epoch 00468: val_loss did not improve\n",
      "2s - loss: 0.0236 - acc: 0.9937 - val_loss: 2.6062 - val_acc: 0.5861\n",
      "Epoch 470/1500\n",
      "Epoch 00469: val_loss did not improve\n",
      "2s - loss: 0.0257 - acc: 0.9872 - val_loss: 2.7411 - val_acc: 0.5801\n",
      "Epoch 471/1500\n",
      "Epoch 00470: val_loss did not improve\n",
      "2s - loss: 0.0348 - acc: 0.9865 - val_loss: 2.8216 - val_acc: 0.5770\n",
      "Epoch 472/1500\n",
      "Epoch 00471: val_loss did not improve\n",
      "2s - loss: 0.0199 - acc: 0.9945 - val_loss: 2.8888 - val_acc: 0.6073\n",
      "Epoch 473/1500\n",
      "Epoch 00472: val_loss did not improve\n",
      "2s - loss: 0.0234 - acc: 0.9912 - val_loss: 2.7071 - val_acc: 0.5861\n",
      "Epoch 474/1500\n",
      "Epoch 00473: val_loss did not improve\n",
      "2s - loss: 0.0248 - acc: 0.9905 - val_loss: 2.7532 - val_acc: 0.5891\n",
      "Epoch 475/1500\n",
      "Epoch 00474: val_loss did not improve\n",
      "2s - loss: 0.0160 - acc: 0.9968 - val_loss: 3.0264 - val_acc: 0.5559\n",
      "Epoch 476/1500\n",
      "Epoch 00475: val_loss did not improve\n",
      "2s - loss: 0.0176 - acc: 0.9929 - val_loss: 2.7432 - val_acc: 0.5891\n",
      "Epoch 477/1500\n",
      "Epoch 00476: val_loss did not improve\n",
      "2s - loss: 0.0492 - acc: 0.9873 - val_loss: 2.8554 - val_acc: 0.5891\n",
      "Epoch 478/1500\n",
      "Epoch 00477: val_loss did not improve\n",
      "2s - loss: 0.0145 - acc: 0.9960 - val_loss: 2.7096 - val_acc: 0.5982\n",
      "Epoch 479/1500\n",
      "Epoch 00478: val_loss did not improve\n",
      "2s - loss: 0.0220 - acc: 0.9913 - val_loss: 2.7273 - val_acc: 0.5921\n",
      "Epoch 480/1500\n",
      "Epoch 00479: val_loss did not improve\n",
      "2s - loss: 0.0236 - acc: 0.9920 - val_loss: 2.7111 - val_acc: 0.5891\n",
      "Epoch 481/1500\n",
      "Epoch 00480: val_loss did not improve\n",
      "2s - loss: 0.0107 - acc: 0.9968 - val_loss: 2.7251 - val_acc: 0.5710\n",
      "Epoch 482/1500\n",
      "Epoch 00481: val_loss did not improve\n",
      "2s - loss: 0.0208 - acc: 0.9945 - val_loss: 2.8701 - val_acc: 0.5891\n",
      "Epoch 483/1500\n",
      "Epoch 00482: val_loss did not improve\n",
      "2s - loss: 0.0142 - acc: 0.9960 - val_loss: 2.6209 - val_acc: 0.5982\n",
      "Epoch 484/1500\n",
      "Epoch 00483: val_loss did not improve\n",
      "2s - loss: 0.0121 - acc: 0.9960 - val_loss: 2.7108 - val_acc: 0.6073\n",
      "Epoch 485/1500\n",
      "Epoch 00484: val_loss did not improve\n",
      "2s - loss: 0.0173 - acc: 0.9960 - val_loss: 2.5193 - val_acc: 0.5982\n",
      "Epoch 486/1500\n",
      "Epoch 00485: val_loss did not improve\n",
      "2s - loss: 0.0205 - acc: 0.9921 - val_loss: 2.7199 - val_acc: 0.5770\n",
      "Epoch 487/1500\n",
      "Epoch 00486: val_loss did not improve\n",
      "2s - loss: 0.0074 - acc: 0.9984 - val_loss: 2.4806 - val_acc: 0.5952\n",
      "Epoch 488/1500\n",
      "Epoch 00487: val_loss did not improve\n",
      "2s - loss: 0.0210 - acc: 0.9937 - val_loss: 2.6681 - val_acc: 0.5801\n",
      "Epoch 489/1500\n",
      "Epoch 00488: val_loss did not improve\n",
      "2s - loss: 0.0412 - acc: 0.9874 - val_loss: 2.6624 - val_acc: 0.5740\n",
      "Epoch 490/1500\n",
      "Epoch 00489: val_loss did not improve\n",
      "2s - loss: 0.0491 - acc: 0.9865 - val_loss: 2.9010 - val_acc: 0.5498\n",
      "Epoch 491/1500\n",
      "Epoch 00490: val_loss did not improve\n",
      "2s - loss: 0.0267 - acc: 0.9928 - val_loss: 2.6388 - val_acc: 0.5952\n",
      "Epoch 492/1500\n",
      "Epoch 00491: val_loss did not improve\n",
      "2s - loss: 0.0300 - acc: 0.9866 - val_loss: 2.6273 - val_acc: 0.6012\n",
      "Epoch 493/1500\n",
      "Epoch 00492: val_loss did not improve\n",
      "2s - loss: 0.0085 - acc: 0.9968 - val_loss: 2.7188 - val_acc: 0.6073\n",
      "Epoch 494/1500\n",
      "Epoch 00493: val_loss did not improve\n",
      "2s - loss: 0.0194 - acc: 0.9936 - val_loss: 2.5708 - val_acc: 0.6103\n",
      "Epoch 495/1500\n",
      "Epoch 00494: val_loss did not improve\n",
      "2s - loss: 0.0216 - acc: 0.9912 - val_loss: 2.6906 - val_acc: 0.5831\n",
      "Epoch 496/1500\n",
      "Epoch 00495: val_loss did not improve\n",
      "2s - loss: 0.0146 - acc: 0.9976 - val_loss: 2.6245 - val_acc: 0.5952\n",
      "Epoch 497/1500\n",
      "Epoch 00496: val_loss did not improve\n",
      "2s - loss: 0.0192 - acc: 0.9913 - val_loss: 2.8089 - val_acc: 0.5650\n",
      "Epoch 498/1500\n",
      "Epoch 00497: val_loss did not improve\n",
      "2s - loss: 0.0134 - acc: 0.9944 - val_loss: 2.9527 - val_acc: 0.5831\n",
      "Epoch 499/1500\n",
      "Epoch 00498: val_loss did not improve\n",
      "2s - loss: 0.0325 - acc: 0.9914 - val_loss: 3.1458 - val_acc: 0.5801\n",
      "Epoch 500/1500\n",
      "Epoch 00499: val_loss did not improve\n",
      "2s - loss: 0.0189 - acc: 0.9952 - val_loss: 2.6380 - val_acc: 0.5801\n",
      "Epoch 501/1500\n",
      "Epoch 00500: val_loss did not improve\n",
      "2s - loss: 0.0181 - acc: 0.9944 - val_loss: 2.4804 - val_acc: 0.6254\n",
      "Epoch 502/1500\n",
      "Epoch 00501: val_loss did not improve\n",
      "2s - loss: 0.0173 - acc: 0.9937 - val_loss: 2.6057 - val_acc: 0.6073\n",
      "Epoch 503/1500\n",
      "Epoch 00502: val_loss did not improve\n",
      "2s - loss: 0.0175 - acc: 0.9928 - val_loss: 2.7395 - val_acc: 0.5801\n",
      "Epoch 504/1500\n",
      "Epoch 00503: val_loss did not improve\n",
      "2s - loss: 0.0177 - acc: 0.9921 - val_loss: 2.7447 - val_acc: 0.6133\n",
      "Epoch 505/1500\n",
      "Epoch 00504: val_loss did not improve\n",
      "2s - loss: 0.0113 - acc: 0.9976 - val_loss: 2.6459 - val_acc: 0.5891\n",
      "Epoch 506/1500\n",
      "Epoch 00505: val_loss did not improve\n",
      "2s - loss: 0.0253 - acc: 0.9899 - val_loss: 3.0513 - val_acc: 0.5438\n",
      "Epoch 507/1500\n",
      "Epoch 00506: val_loss did not improve\n",
      "2s - loss: 0.0165 - acc: 0.9952 - val_loss: 2.8974 - val_acc: 0.5438\n",
      "Epoch 508/1500\n",
      "Epoch 00507: val_loss did not improve\n",
      "2s - loss: 0.0181 - acc: 0.9928 - val_loss: 2.7765 - val_acc: 0.5740\n",
      "Epoch 509/1500\n",
      "Epoch 00508: val_loss did not improve\n",
      "2s - loss: 0.0247 - acc: 0.9905 - val_loss: 2.4484 - val_acc: 0.6103\n",
      "Epoch 510/1500\n",
      "Epoch 00509: val_loss did not improve\n",
      "2s - loss: 0.0108 - acc: 0.9953 - val_loss: 2.8737 - val_acc: 0.5891\n",
      "Epoch 511/1500\n",
      "Epoch 00510: val_loss did not improve\n",
      "2s - loss: 0.0112 - acc: 0.9968 - val_loss: 2.7340 - val_acc: 0.5952\n",
      "Epoch 512/1500\n",
      "Epoch 00511: val_loss did not improve\n",
      "2s - loss: 0.0190 - acc: 0.9968 - val_loss: 2.6884 - val_acc: 0.6042\n",
      "Epoch 513/1500\n",
      "Epoch 00512: val_loss did not improve\n",
      "2s - loss: 0.0162 - acc: 0.9953 - val_loss: 2.6317 - val_acc: 0.5982\n",
      "Epoch 514/1500\n",
      "Epoch 00513: val_loss did not improve\n",
      "2s - loss: 0.0157 - acc: 0.9944 - val_loss: 2.6765 - val_acc: 0.6042\n",
      "Epoch 515/1500\n",
      "Epoch 00514: val_loss did not improve\n",
      "2s - loss: 0.0087 - acc: 0.9976 - val_loss: 2.7672 - val_acc: 0.5891\n",
      "Epoch 516/1500\n",
      "Epoch 00515: val_loss did not improve\n",
      "2s - loss: 0.0196 - acc: 0.9936 - val_loss: 2.7453 - val_acc: 0.5952\n",
      "Epoch 517/1500\n",
      "Epoch 00516: val_loss did not improve\n",
      "2s - loss: 0.0185 - acc: 0.9937 - val_loss: 2.7914 - val_acc: 0.5801\n",
      "Epoch 518/1500\n",
      "Epoch 00517: val_loss did not improve\n",
      "2s - loss: 0.0197 - acc: 0.9944 - val_loss: 2.8247 - val_acc: 0.5559\n",
      "Epoch 519/1500\n",
      "Epoch 00518: val_loss did not improve\n",
      "2s - loss: 0.0124 - acc: 0.9952 - val_loss: 2.8305 - val_acc: 0.5680\n",
      "Epoch 520/1500\n",
      "Epoch 00519: val_loss did not improve\n",
      "2s - loss: 0.0352 - acc: 0.9849 - val_loss: 2.9826 - val_acc: 0.5770\n",
      "Epoch 521/1500\n",
      "Epoch 00520: val_loss did not improve\n",
      "2s - loss: 0.0125 - acc: 0.9976 - val_loss: 2.9389 - val_acc: 0.6012\n",
      "Epoch 522/1500\n",
      "Epoch 00521: val_loss did not improve\n",
      "2s - loss: 0.0152 - acc: 0.9937 - val_loss: 2.6666 - val_acc: 0.5891\n",
      "Epoch 523/1500\n",
      "Epoch 00522: val_loss did not improve\n",
      "2s - loss: 0.0185 - acc: 0.9960 - val_loss: 2.5859 - val_acc: 0.6103\n",
      "Epoch 524/1500\n",
      "Epoch 00523: val_loss did not improve\n",
      "2s - loss: 0.0144 - acc: 0.9960 - val_loss: 2.9263 - val_acc: 0.5740\n",
      "Epoch 525/1500\n",
      "Epoch 00524: val_loss did not improve\n",
      "2s - loss: 0.0100 - acc: 0.9976 - val_loss: 2.7443 - val_acc: 0.5770\n",
      "Epoch 526/1500\n",
      "Epoch 00525: val_loss did not improve\n",
      "2s - loss: 0.0158 - acc: 0.9960 - val_loss: 2.7874 - val_acc: 0.6133\n",
      "Epoch 527/1500\n",
      "Epoch 00526: val_loss did not improve\n",
      "2s - loss: 0.0088 - acc: 0.9976 - val_loss: 2.7726 - val_acc: 0.5801\n",
      "Epoch 528/1500\n",
      "Epoch 00527: val_loss did not improve\n",
      "2s - loss: 0.0093 - acc: 0.9960 - val_loss: 2.8010 - val_acc: 0.6012\n",
      "Epoch 529/1500\n",
      "Epoch 00528: val_loss did not improve\n",
      "2s - loss: 0.0121 - acc: 0.9968 - val_loss: 2.7988 - val_acc: 0.5891\n",
      "Epoch 530/1500\n",
      "Epoch 00529: val_loss did not improve\n",
      "2s - loss: 0.0060 - acc: 0.9992 - val_loss: 2.8910 - val_acc: 0.5770\n",
      "Epoch 531/1500\n",
      "Epoch 00530: val_loss did not improve\n",
      "2s - loss: 0.0110 - acc: 0.9968 - val_loss: 2.8316 - val_acc: 0.6012\n",
      "Epoch 532/1500\n",
      "Epoch 00531: val_loss did not improve\n",
      "2s - loss: 0.0250 - acc: 0.9921 - val_loss: 2.8170 - val_acc: 0.6073\n",
      "Epoch 533/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00532: val_loss did not improve\n",
      "2s - loss: 0.0149 - acc: 0.9937 - val_loss: 2.7211 - val_acc: 0.5650\n",
      "Epoch 534/1500\n",
      "Epoch 00533: val_loss did not improve\n",
      "2s - loss: 0.0096 - acc: 0.9976 - val_loss: 2.9844 - val_acc: 0.5680\n",
      "Epoch 535/1500\n",
      "Epoch 00534: val_loss did not improve\n",
      "2s - loss: 0.0095 - acc: 0.9968 - val_loss: 2.5269 - val_acc: 0.6193\n",
      "Epoch 536/1500\n",
      "Epoch 00535: val_loss did not improve\n",
      "2s - loss: 0.0108 - acc: 0.9952 - val_loss: 2.8998 - val_acc: 0.5680\n",
      "Epoch 537/1500\n",
      "Epoch 00536: val_loss did not improve\n",
      "2s - loss: 0.0317 - acc: 0.9913 - val_loss: 2.4622 - val_acc: 0.6435\n",
      "Epoch 538/1500\n",
      "Epoch 00537: val_loss did not improve\n",
      "2s - loss: 0.0121 - acc: 0.9961 - val_loss: 2.6856 - val_acc: 0.6133\n",
      "Epoch 539/1500\n",
      "Epoch 00538: val_loss did not improve\n",
      "2s - loss: 0.0256 - acc: 0.9928 - val_loss: 2.7020 - val_acc: 0.6193\n",
      "Epoch 540/1500\n",
      "Epoch 00539: val_loss did not improve\n",
      "2s - loss: 0.0456 - acc: 0.9875 - val_loss: 2.9105 - val_acc: 0.5861\n",
      "Epoch 541/1500\n",
      "Epoch 00540: val_loss did not improve\n",
      "2s - loss: 0.0128 - acc: 0.9944 - val_loss: 3.0633 - val_acc: 0.5921\n",
      "Epoch 542/1500\n",
      "Epoch 00541: val_loss did not improve\n",
      "2s - loss: 0.0273 - acc: 0.9864 - val_loss: 2.8873 - val_acc: 0.5740\n",
      "Epoch 543/1500\n",
      "Epoch 00542: val_loss did not improve\n",
      "2s - loss: 0.0174 - acc: 0.9936 - val_loss: 2.8957 - val_acc: 0.6163\n",
      "Epoch 544/1500\n",
      "Epoch 00543: val_loss did not improve\n",
      "2s - loss: 0.0180 - acc: 0.9937 - val_loss: 2.6672 - val_acc: 0.6224\n",
      "Epoch 545/1500\n",
      "Epoch 00544: val_loss did not improve\n",
      "2s - loss: 0.0253 - acc: 0.9905 - val_loss: 2.7285 - val_acc: 0.6163\n",
      "Epoch 546/1500\n",
      "Epoch 00545: val_loss did not improve\n",
      "2s - loss: 0.0140 - acc: 0.9960 - val_loss: 2.6870 - val_acc: 0.6224\n",
      "Epoch 547/1500\n",
      "Epoch 00546: val_loss did not improve\n",
      "2s - loss: 0.0249 - acc: 0.9905 - val_loss: 2.8343 - val_acc: 0.6042\n",
      "Epoch 548/1500\n",
      "Epoch 00547: val_loss did not improve\n",
      "2s - loss: 0.0121 - acc: 0.9968 - val_loss: 2.9790 - val_acc: 0.5680\n",
      "Epoch 549/1500\n",
      "Epoch 00548: val_loss did not improve\n",
      "2s - loss: 0.0136 - acc: 0.9968 - val_loss: 2.7963 - val_acc: 0.6042\n",
      "Epoch 550/1500\n",
      "Epoch 00549: val_loss did not improve\n",
      "2s - loss: 0.0130 - acc: 0.9928 - val_loss: 2.5384 - val_acc: 0.6163\n",
      "Epoch 551/1500\n",
      "Epoch 00550: val_loss did not improve\n",
      "2s - loss: 0.0250 - acc: 0.9888 - val_loss: 2.6802 - val_acc: 0.5982\n",
      "Epoch 552/1500\n",
      "Epoch 00551: val_loss did not improve\n",
      "2s - loss: 0.0039 - acc: 0.9992 - val_loss: 2.6611 - val_acc: 0.6133\n",
      "Epoch 553/1500\n",
      "Epoch 00552: val_loss did not improve\n",
      "2s - loss: 0.0229 - acc: 0.9882 - val_loss: 2.4104 - val_acc: 0.6012\n",
      "Epoch 554/1500\n",
      "Epoch 00553: val_loss did not improve\n",
      "2s - loss: 0.0230 - acc: 0.9897 - val_loss: 2.9400 - val_acc: 0.5831\n",
      "Epoch 555/1500\n",
      "Epoch 00554: val_loss did not improve\n",
      "2s - loss: 0.0121 - acc: 0.9960 - val_loss: 2.7010 - val_acc: 0.5770\n",
      "Epoch 556/1500\n",
      "Epoch 00555: val_loss did not improve\n",
      "2s - loss: 0.0088 - acc: 0.9976 - val_loss: 2.9504 - val_acc: 0.5952\n",
      "Epoch 557/1500\n",
      "Epoch 00556: val_loss did not improve\n",
      "2s - loss: 0.0211 - acc: 0.9912 - val_loss: 2.7631 - val_acc: 0.5921\n",
      "Epoch 558/1500\n",
      "Epoch 00557: val_loss did not improve\n",
      "2s - loss: 0.0233 - acc: 0.9936 - val_loss: 3.0338 - val_acc: 0.5680\n",
      "Epoch 559/1500\n",
      "Epoch 00558: val_loss did not improve\n",
      "2s - loss: 0.0166 - acc: 0.9952 - val_loss: 2.8243 - val_acc: 0.6012\n",
      "Epoch 560/1500\n",
      "Epoch 00559: val_loss did not improve\n",
      "2s - loss: 0.0113 - acc: 0.9976 - val_loss: 3.0291 - val_acc: 0.6012\n",
      "Epoch 561/1500\n",
      "Epoch 00560: val_loss did not improve\n",
      "2s - loss: 0.0067 - acc: 0.9968 - val_loss: 2.8783 - val_acc: 0.5680\n",
      "Epoch 562/1500\n",
      "Epoch 00561: val_loss did not improve\n",
      "2s - loss: 0.0144 - acc: 0.9952 - val_loss: 2.7588 - val_acc: 0.5891\n",
      "Epoch 563/1500\n",
      "Epoch 00562: val_loss did not improve\n",
      "2s - loss: 0.0159 - acc: 0.9944 - val_loss: 2.5278 - val_acc: 0.6163\n",
      "Epoch 564/1500\n",
      "Epoch 00563: val_loss did not improve\n",
      "2s - loss: 0.0163 - acc: 0.9944 - val_loss: 2.8443 - val_acc: 0.5861\n",
      "Epoch 565/1500\n",
      "Epoch 00564: val_loss did not improve\n",
      "2s - loss: 0.0527 - acc: 0.9891 - val_loss: 2.7040 - val_acc: 0.5952\n",
      "Epoch 566/1500\n",
      "Epoch 00565: val_loss did not improve\n",
      "2s - loss: 0.0175 - acc: 0.9920 - val_loss: 2.8424 - val_acc: 0.5801\n",
      "Epoch 567/1500\n",
      "Epoch 00566: val_loss did not improve\n",
      "2s - loss: 0.0305 - acc: 0.9904 - val_loss: 2.6410 - val_acc: 0.5921\n",
      "Epoch 568/1500\n",
      "Epoch 00567: val_loss did not improve\n",
      "2s - loss: 0.0113 - acc: 0.9960 - val_loss: 2.7116 - val_acc: 0.5982\n",
      "Epoch 569/1500\n",
      "Epoch 00568: val_loss did not improve\n",
      "2s - loss: 0.0152 - acc: 0.9960 - val_loss: 2.8038 - val_acc: 0.6042\n",
      "Epoch 570/1500\n",
      "Epoch 00569: val_loss did not improve\n",
      "2s - loss: 0.0121 - acc: 0.9937 - val_loss: 2.7487 - val_acc: 0.5952\n",
      "Epoch 571/1500\n",
      "Epoch 00570: val_loss did not improve\n",
      "2s - loss: 0.0094 - acc: 0.9960 - val_loss: 2.7669 - val_acc: 0.5801\n",
      "Epoch 572/1500\n",
      "Epoch 00571: val_loss did not improve\n",
      "2s - loss: 0.0193 - acc: 0.9944 - val_loss: 2.2466 - val_acc: 0.6526\n",
      "Epoch 573/1500\n",
      "Epoch 00572: val_loss did not improve\n",
      "2s - loss: 0.0201 - acc: 0.9921 - val_loss: 2.8318 - val_acc: 0.5831\n",
      "Epoch 574/1500\n",
      "Epoch 00573: val_loss did not improve\n",
      "2s - loss: 0.0166 - acc: 0.9928 - val_loss: 2.8536 - val_acc: 0.5770\n",
      "Epoch 575/1500\n",
      "Epoch 00574: val_loss did not improve\n",
      "2s - loss: 0.0216 - acc: 0.9945 - val_loss: 2.7261 - val_acc: 0.5952\n",
      "Epoch 576/1500\n",
      "Epoch 00575: val_loss did not improve\n",
      "2s - loss: 0.0456 - acc: 0.9897 - val_loss: 2.7077 - val_acc: 0.6073\n",
      "Epoch 577/1500\n",
      "Epoch 00576: val_loss did not improve\n",
      "2s - loss: 0.0164 - acc: 0.9952 - val_loss: 3.2763 - val_acc: 0.5317\n",
      "Epoch 578/1500\n",
      "Epoch 00577: val_loss did not improve\n",
      "2s - loss: 0.0143 - acc: 0.9952 - val_loss: 2.7170 - val_acc: 0.6073\n",
      "Epoch 579/1500\n",
      "Epoch 00578: val_loss did not improve\n",
      "2s - loss: 0.0080 - acc: 0.9992 - val_loss: 2.7838 - val_acc: 0.5740\n",
      "Epoch 580/1500\n",
      "Epoch 00579: val_loss did not improve\n",
      "2s - loss: 0.0417 - acc: 0.9835 - val_loss: 2.8394 - val_acc: 0.5861\n",
      "Epoch 581/1500\n",
      "Epoch 00580: val_loss did not improve\n",
      "2s - loss: 0.0067 - acc: 0.9976 - val_loss: 2.8684 - val_acc: 0.5891\n",
      "Epoch 582/1500\n",
      "Epoch 00581: val_loss did not improve\n",
      "2s - loss: 0.0098 - acc: 0.9960 - val_loss: 2.7367 - val_acc: 0.6042\n",
      "Epoch 583/1500\n",
      "Epoch 00582: val_loss did not improve\n",
      "2s - loss: 0.0110 - acc: 0.9961 - val_loss: 2.7803 - val_acc: 0.6193\n",
      "Epoch 584/1500\n",
      "Epoch 00583: val_loss did not improve\n",
      "2s - loss: 0.0479 - acc: 0.9906 - val_loss: 2.8083 - val_acc: 0.5831\n",
      "Epoch 585/1500\n",
      "Epoch 00584: val_loss did not improve\n",
      "2s - loss: 0.0226 - acc: 0.9920 - val_loss: 2.8511 - val_acc: 0.6284\n",
      "Epoch 586/1500\n",
      "Epoch 00585: val_loss did not improve\n",
      "2s - loss: 0.0096 - acc: 0.9968 - val_loss: 2.6948 - val_acc: 0.5982\n",
      "Epoch 587/1500\n",
      "Epoch 00586: val_loss did not improve\n",
      "2s - loss: 0.0207 - acc: 0.9928 - val_loss: 2.5157 - val_acc: 0.6254\n",
      "Epoch 588/1500\n",
      "Epoch 00587: val_loss did not improve\n",
      "2s - loss: 0.0159 - acc: 0.9944 - val_loss: 2.9142 - val_acc: 0.5589\n",
      "Epoch 589/1500\n",
      "Epoch 00588: val_loss did not improve\n",
      "2s - loss: 0.0199 - acc: 0.9936 - val_loss: 2.6889 - val_acc: 0.5982\n",
      "Epoch 590/1500\n",
      "Epoch 00589: val_loss did not improve\n",
      "2s - loss: 0.0078 - acc: 0.9976 - val_loss: 2.5946 - val_acc: 0.5921\n",
      "Epoch 591/1500\n",
      "Epoch 00590: val_loss did not improve\n",
      "2s - loss: 0.0614 - acc: 0.9884 - val_loss: 2.9087 - val_acc: 0.5710\n",
      "Epoch 592/1500\n",
      "Epoch 00591: val_loss did not improve\n",
      "2s - loss: 0.0360 - acc: 0.9867 - val_loss: 2.7178 - val_acc: 0.5831\n",
      "Epoch 593/1500\n",
      "Epoch 00592: val_loss did not improve\n",
      "2s - loss: 0.0045 - acc: 0.9992 - val_loss: 2.7493 - val_acc: 0.5680\n",
      "Epoch 594/1500\n",
      "Epoch 00593: val_loss did not improve\n",
      "2s - loss: 0.0125 - acc: 0.9968 - val_loss: 2.6005 - val_acc: 0.5861\n",
      "Epoch 595/1500\n",
      "Epoch 00594: val_loss did not improve\n",
      "2s - loss: 0.0178 - acc: 0.9952 - val_loss: 2.6169 - val_acc: 0.6224\n",
      "Epoch 596/1500\n",
      "Epoch 00595: val_loss did not improve\n",
      "2s - loss: 0.0140 - acc: 0.9952 - val_loss: 2.9692 - val_acc: 0.5921\n",
      "Epoch 597/1500\n",
      "Epoch 00596: val_loss did not improve\n",
      "2s - loss: 0.0129 - acc: 0.9961 - val_loss: 2.5651 - val_acc: 0.6103\n",
      "Epoch 598/1500\n",
      "Epoch 00597: val_loss did not improve\n",
      "2s - loss: 0.0174 - acc: 0.9952 - val_loss: 3.0854 - val_acc: 0.5740\n",
      "Epoch 599/1500\n",
      "Epoch 00598: val_loss did not improve\n",
      "2s - loss: 0.0221 - acc: 0.9921 - val_loss: 2.8091 - val_acc: 0.5801\n",
      "Epoch 600/1500\n",
      "Epoch 00599: val_loss did not improve\n",
      "2s - loss: 0.0127 - acc: 0.9960 - val_loss: 2.8895 - val_acc: 0.6133\n",
      "Epoch 601/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00600: val_loss did not improve\n",
      "2s - loss: 0.0060 - acc: 0.9984 - val_loss: 2.8587 - val_acc: 0.6042\n",
      "Epoch 602/1500\n",
      "Epoch 00601: val_loss did not improve\n",
      "2s - loss: 0.0215 - acc: 0.9912 - val_loss: 3.1478 - val_acc: 0.5861\n",
      "Epoch 603/1500\n",
      "Epoch 00602: val_loss did not improve\n",
      "2s - loss: 0.0382 - acc: 0.9852 - val_loss: 2.6379 - val_acc: 0.6465\n",
      "Epoch 604/1500\n",
      "Epoch 00603: val_loss did not improve\n",
      "2s - loss: 0.0501 - acc: 0.9859 - val_loss: 3.0869 - val_acc: 0.5861\n",
      "Epoch 605/1500\n",
      "Epoch 00604: val_loss did not improve\n",
      "2s - loss: 0.0210 - acc: 0.9921 - val_loss: 2.9723 - val_acc: 0.5921\n",
      "Epoch 606/1500\n",
      "Epoch 00605: val_loss did not improve\n",
      "2s - loss: 0.0121 - acc: 0.9960 - val_loss: 2.7443 - val_acc: 0.5921\n",
      "Epoch 607/1500\n",
      "Epoch 00606: val_loss did not improve\n",
      "2s - loss: 0.0144 - acc: 0.9961 - val_loss: 2.8048 - val_acc: 0.6042\n",
      "Epoch 608/1500\n",
      "Epoch 00607: val_loss did not improve\n",
      "2s - loss: 0.0121 - acc: 0.9968 - val_loss: 2.5523 - val_acc: 0.6163\n",
      "Epoch 609/1500\n",
      "Epoch 00608: val_loss did not improve\n",
      "2s - loss: 0.0070 - acc: 0.9968 - val_loss: 2.8526 - val_acc: 0.5770\n",
      "Epoch 610/1500\n",
      "Epoch 00609: val_loss did not improve\n",
      "2s - loss: 0.0080 - acc: 0.9976 - val_loss: 2.8391 - val_acc: 0.6073\n",
      "Epoch 611/1500\n",
      "Epoch 00610: val_loss did not improve\n",
      "2s - loss: 0.0168 - acc: 0.9960 - val_loss: 2.9497 - val_acc: 0.6163\n",
      "Epoch 612/1500\n",
      "Epoch 00611: val_loss did not improve\n",
      "2s - loss: 0.0209 - acc: 0.9920 - val_loss: 2.9565 - val_acc: 0.5861\n",
      "Epoch 613/1500\n",
      "Epoch 00612: val_loss did not improve\n",
      "2s - loss: 0.0236 - acc: 0.9936 - val_loss: 2.9639 - val_acc: 0.6012\n",
      "Epoch 614/1500\n",
      "Epoch 00613: val_loss did not improve\n",
      "2s - loss: 0.0115 - acc: 0.9968 - val_loss: 2.9237 - val_acc: 0.5921\n",
      "Epoch 615/1500\n",
      "Epoch 00614: val_loss did not improve\n",
      "2s - loss: 0.0310 - acc: 0.9913 - val_loss: 2.9218 - val_acc: 0.5982\n",
      "Epoch 616/1500\n",
      "Epoch 00615: val_loss did not improve\n",
      "2s - loss: 0.0220 - acc: 0.9937 - val_loss: 3.2397 - val_acc: 0.5831\n",
      "Epoch 617/1500\n",
      "Epoch 00616: val_loss did not improve\n",
      "2s - loss: 0.0119 - acc: 0.9961 - val_loss: 2.7589 - val_acc: 0.6344\n",
      "Epoch 618/1500\n",
      "Epoch 00617: val_loss did not improve\n",
      "2s - loss: 0.0132 - acc: 0.9944 - val_loss: 2.5960 - val_acc: 0.6375\n",
      "Epoch 619/1500\n",
      "Epoch 00618: val_loss did not improve\n",
      "2s - loss: 0.0111 - acc: 0.9960 - val_loss: 2.9578 - val_acc: 0.5921\n",
      "Epoch 620/1500\n",
      "Epoch 00619: val_loss did not improve\n",
      "2s - loss: 0.0178 - acc: 0.9953 - val_loss: 2.9913 - val_acc: 0.5801\n",
      "Epoch 621/1500\n",
      "Epoch 00620: val_loss did not improve\n",
      "2s - loss: 0.0266 - acc: 0.9905 - val_loss: 2.6552 - val_acc: 0.6375\n",
      "Epoch 622/1500\n",
      "Epoch 00621: val_loss did not improve\n",
      "2s - loss: 0.0244 - acc: 0.9937 - val_loss: 2.5570 - val_acc: 0.6254\n",
      "Epoch 623/1500\n",
      "Epoch 00622: val_loss did not improve\n",
      "2s - loss: 0.0194 - acc: 0.9905 - val_loss: 2.8014 - val_acc: 0.6012\n",
      "Epoch 624/1500\n",
      "Epoch 00623: val_loss did not improve\n",
      "2s - loss: 0.0204 - acc: 0.9904 - val_loss: 2.5424 - val_acc: 0.6224\n",
      "Epoch 625/1500\n",
      "Epoch 00624: val_loss did not improve\n",
      "2s - loss: 0.0120 - acc: 0.9938 - val_loss: 2.7808 - val_acc: 0.5770\n",
      "Epoch 626/1500\n",
      "Epoch 00625: val_loss did not improve\n",
      "2s - loss: 0.0173 - acc: 0.9944 - val_loss: 3.0193 - val_acc: 0.5710\n",
      "Epoch 627/1500\n",
      "Epoch 00626: val_loss did not improve\n",
      "2s - loss: 0.0146 - acc: 0.9905 - val_loss: 3.0606 - val_acc: 0.5559\n",
      "Epoch 628/1500\n",
      "Epoch 00627: val_loss did not improve\n",
      "2s - loss: 0.0686 - acc: 0.9891 - val_loss: 3.0685 - val_acc: 0.6073\n",
      "Epoch 629/1500\n",
      "Epoch 00628: val_loss did not improve\n",
      "2s - loss: 0.0118 - acc: 0.9937 - val_loss: 2.8381 - val_acc: 0.6133\n",
      "Epoch 630/1500\n",
      "Epoch 00629: val_loss did not improve\n",
      "2s - loss: 0.0157 - acc: 0.9928 - val_loss: 2.9673 - val_acc: 0.6042\n",
      "Epoch 631/1500\n",
      "Epoch 00630: val_loss did not improve\n",
      "2s - loss: 0.0131 - acc: 0.9953 - val_loss: 2.8992 - val_acc: 0.6012\n",
      "Epoch 632/1500\n",
      "Epoch 00631: val_loss did not improve\n",
      "2s - loss: 0.0103 - acc: 0.9976 - val_loss: 3.0216 - val_acc: 0.5801\n",
      "Epoch 633/1500\n",
      "Epoch 00632: val_loss did not improve\n",
      "2s - loss: 0.0106 - acc: 0.9968 - val_loss: 2.8726 - val_acc: 0.5982\n",
      "Epoch 634/1500\n",
      "Epoch 00633: val_loss did not improve\n",
      "2s - loss: 0.0549 - acc: 0.9867 - val_loss: 2.8564 - val_acc: 0.6133\n",
      "Epoch 635/1500\n",
      "Epoch 00634: val_loss did not improve\n",
      "2s - loss: 0.0161 - acc: 0.9944 - val_loss: 3.1956 - val_acc: 0.5529\n",
      "Epoch 636/1500\n",
      "Epoch 00635: val_loss did not improve\n",
      "2s - loss: 0.0056 - acc: 0.9969 - val_loss: 3.1545 - val_acc: 0.5619\n",
      "Epoch 637/1500\n",
      "Epoch 00636: val_loss did not improve\n",
      "2s - loss: 0.0071 - acc: 0.9968 - val_loss: 3.0918 - val_acc: 0.5801\n",
      "Epoch 638/1500\n",
      "Epoch 00637: val_loss did not improve\n",
      "2s - loss: 0.0061 - acc: 0.9992 - val_loss: 3.0398 - val_acc: 0.5921\n",
      "Epoch 639/1500\n",
      "Epoch 00638: val_loss did not improve\n",
      "2s - loss: 0.0072 - acc: 0.9976 - val_loss: 2.8457 - val_acc: 0.5861\n",
      "Epoch 640/1500\n",
      "Epoch 00639: val_loss did not improve\n",
      "2s - loss: 0.0169 - acc: 0.9938 - val_loss: 2.7948 - val_acc: 0.6073\n",
      "Epoch 641/1500\n",
      "Epoch 00640: val_loss did not improve\n",
      "2s - loss: 0.0132 - acc: 0.9952 - val_loss: 2.9115 - val_acc: 0.5861\n",
      "Epoch 642/1500\n",
      "Epoch 00641: val_loss did not improve\n",
      "2s - loss: 0.0117 - acc: 0.9960 - val_loss: 2.8961 - val_acc: 0.6163\n",
      "Epoch 643/1500\n",
      "Epoch 00642: val_loss did not improve\n",
      "2s - loss: 0.0137 - acc: 0.9960 - val_loss: 2.8739 - val_acc: 0.5831\n",
      "Epoch 644/1500\n",
      "Epoch 00643: val_loss did not improve\n",
      "2s - loss: 0.0260 - acc: 0.9921 - val_loss: 3.1717 - val_acc: 0.5529\n",
      "Epoch 645/1500\n",
      "Epoch 00644: val_loss did not improve\n",
      "2s - loss: 0.0131 - acc: 0.9936 - val_loss: 2.9127 - val_acc: 0.5921\n",
      "Epoch 646/1500\n",
      "Epoch 00645: val_loss did not improve\n",
      "2s - loss: 0.0167 - acc: 0.9936 - val_loss: 2.8749 - val_acc: 0.6012\n",
      "Epoch 647/1500\n",
      "Epoch 00646: val_loss did not improve\n",
      "2s - loss: 0.0094 - acc: 0.9968 - val_loss: 2.9238 - val_acc: 0.5891\n",
      "Epoch 648/1500\n",
      "Epoch 00647: val_loss did not improve\n",
      "2s - loss: 0.0087 - acc: 0.9960 - val_loss: 2.8905 - val_acc: 0.5921\n",
      "Epoch 649/1500\n",
      "Epoch 00648: val_loss did not improve\n",
      "2s - loss: 0.0198 - acc: 0.9929 - val_loss: 3.2309 - val_acc: 0.5680\n",
      "Epoch 650/1500\n",
      "Epoch 00649: val_loss did not improve\n",
      "2s - loss: 0.0136 - acc: 0.9944 - val_loss: 3.0195 - val_acc: 0.6224\n",
      "Epoch 651/1500\n",
      "Epoch 00650: val_loss did not improve\n",
      "2s - loss: 0.0114 - acc: 0.9960 - val_loss: 3.0861 - val_acc: 0.5680\n",
      "Epoch 652/1500\n",
      "Epoch 00651: val_loss did not improve\n",
      "2s - loss: 0.0290 - acc: 0.9906 - val_loss: 2.7583 - val_acc: 0.6012\n",
      "Epoch 653/1500\n",
      "Epoch 00652: val_loss did not improve\n",
      "2s - loss: 0.0134 - acc: 0.9952 - val_loss: 3.1859 - val_acc: 0.5861\n",
      "Epoch 654/1500\n",
      "Epoch 00653: val_loss did not improve\n",
      "2s - loss: 0.0076 - acc: 0.9961 - val_loss: 3.1246 - val_acc: 0.5589\n",
      "Epoch 655/1500\n",
      "Epoch 00654: val_loss did not improve\n",
      "2s - loss: 0.0147 - acc: 0.9944 - val_loss: 2.5679 - val_acc: 0.6405\n",
      "Epoch 656/1500\n",
      "Epoch 00655: val_loss did not improve\n",
      "2s - loss: 0.0140 - acc: 0.9960 - val_loss: 2.9478 - val_acc: 0.5982\n",
      "Epoch 657/1500\n",
      "Epoch 00656: val_loss did not improve\n",
      "2s - loss: 0.0293 - acc: 0.9944 - val_loss: 2.9465 - val_acc: 0.5831\n",
      "Epoch 658/1500\n",
      "Epoch 00657: val_loss did not improve\n",
      "2s - loss: 0.0770 - acc: 0.9782 - val_loss: 2.8822 - val_acc: 0.6224\n",
      "Epoch 659/1500\n",
      "Epoch 00658: val_loss did not improve\n",
      "2s - loss: 0.0270 - acc: 0.9889 - val_loss: 3.1399 - val_acc: 0.5952\n",
      "Epoch 660/1500\n",
      "Epoch 00659: val_loss did not improve\n",
      "2s - loss: 0.0089 - acc: 0.9968 - val_loss: 2.7717 - val_acc: 0.6012\n",
      "Epoch 661/1500\n",
      "Epoch 00660: val_loss did not improve\n",
      "2s - loss: 0.0123 - acc: 0.9984 - val_loss: 3.1733 - val_acc: 0.5831\n",
      "Epoch 662/1500\n",
      "Epoch 00661: val_loss did not improve\n",
      "2s - loss: 0.0146 - acc: 0.9960 - val_loss: 2.8074 - val_acc: 0.6254\n",
      "Epoch 663/1500\n",
      "Epoch 00662: val_loss did not improve\n",
      "2s - loss: 0.0151 - acc: 0.9968 - val_loss: 3.1864 - val_acc: 0.5801\n",
      "Epoch 664/1500\n",
      "Epoch 00663: val_loss did not improve\n",
      "2s - loss: 0.0237 - acc: 0.9936 - val_loss: 2.6520 - val_acc: 0.6103\n",
      "Epoch 665/1500\n",
      "Epoch 00664: val_loss did not improve\n",
      "2s - loss: 0.0070 - acc: 0.9984 - val_loss: 2.9802 - val_acc: 0.6042\n",
      "Epoch 666/1500\n",
      "Epoch 00665: val_loss did not improve\n",
      "2s - loss: 0.0142 - acc: 0.9945 - val_loss: 2.8338 - val_acc: 0.5831\n",
      "Epoch 667/1500\n",
      "Epoch 00666: val_loss did not improve\n",
      "2s - loss: 0.0171 - acc: 0.9928 - val_loss: 2.7962 - val_acc: 0.6103\n",
      "Epoch 668/1500\n",
      "Epoch 00667: val_loss did not improve\n",
      "2s - loss: 0.0114 - acc: 0.9952 - val_loss: 3.2182 - val_acc: 0.5468\n",
      "Epoch 669/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00668: val_loss did not improve\n",
      "2s - loss: 0.0122 - acc: 0.9952 - val_loss: 3.1395 - val_acc: 0.6073\n",
      "Epoch 670/1500\n",
      "Epoch 00669: val_loss did not improve\n",
      "2s - loss: 0.0247 - acc: 0.9945 - val_loss: 3.0413 - val_acc: 0.6042\n",
      "Epoch 671/1500\n",
      "Epoch 00670: val_loss did not improve\n",
      "2s - loss: 0.0309 - acc: 0.9914 - val_loss: 3.2870 - val_acc: 0.5710\n",
      "Epoch 672/1500\n",
      "Epoch 00671: val_loss did not improve\n",
      "2s - loss: 0.0423 - acc: 0.9898 - val_loss: 3.0842 - val_acc: 0.6012\n",
      "Epoch 673/1500\n",
      "Epoch 00672: val_loss did not improve\n",
      "2s - loss: 0.0354 - acc: 0.9890 - val_loss: 2.9422 - val_acc: 0.6284\n",
      "Epoch 674/1500\n",
      "Epoch 00673: val_loss did not improve\n",
      "2s - loss: 0.0346 - acc: 0.9868 - val_loss: 2.9328 - val_acc: 0.5891\n",
      "Epoch 675/1500\n",
      "Epoch 00674: val_loss did not improve\n",
      "2s - loss: 0.0138 - acc: 0.9952 - val_loss: 2.9803 - val_acc: 0.6073\n",
      "Epoch 676/1500\n",
      "Epoch 00675: val_loss did not improve\n",
      "2s - loss: 0.0098 - acc: 0.9976 - val_loss: 2.6722 - val_acc: 0.6224\n",
      "Epoch 677/1500\n",
      "Epoch 00676: val_loss did not improve\n",
      "2s - loss: 0.0131 - acc: 0.9952 - val_loss: 2.9231 - val_acc: 0.5740\n",
      "Epoch 678/1500\n",
      "Epoch 00677: val_loss did not improve\n",
      "2s - loss: 0.0040 - acc: 1.0000 - val_loss: 2.7316 - val_acc: 0.6314\n",
      "Epoch 679/1500\n",
      "Epoch 00678: val_loss did not improve\n",
      "2s - loss: 0.0137 - acc: 0.9968 - val_loss: 2.8603 - val_acc: 0.6163\n",
      "Epoch 680/1500\n",
      "Epoch 00679: val_loss did not improve\n",
      "2s - loss: 0.0090 - acc: 0.9952 - val_loss: 3.0090 - val_acc: 0.5801\n",
      "Epoch 681/1500\n",
      "Epoch 00680: val_loss did not improve\n",
      "2s - loss: 0.0071 - acc: 0.9984 - val_loss: 2.7443 - val_acc: 0.6224\n",
      "Epoch 682/1500\n",
      "Epoch 00681: val_loss did not improve\n",
      "2s - loss: 0.0035 - acc: 0.9992 - val_loss: 3.0054 - val_acc: 0.5740\n",
      "Epoch 683/1500\n",
      "Epoch 00682: val_loss did not improve\n",
      "2s - loss: 0.0106 - acc: 0.9952 - val_loss: 3.0305 - val_acc: 0.5921\n",
      "Epoch 684/1500\n",
      "Epoch 00683: val_loss did not improve\n",
      "2s - loss: 0.0149 - acc: 0.9952 - val_loss: 2.8756 - val_acc: 0.6073\n",
      "Epoch 685/1500\n",
      "Epoch 00684: val_loss did not improve\n",
      "2s - loss: 0.0056 - acc: 0.9984 - val_loss: 3.0752 - val_acc: 0.5589\n",
      "Epoch 686/1500\n",
      "Epoch 00685: val_loss did not improve\n",
      "2s - loss: 0.0073 - acc: 0.9976 - val_loss: 2.9258 - val_acc: 0.6163\n",
      "Epoch 687/1500\n",
      "Epoch 00686: val_loss did not improve\n",
      "2s - loss: 0.0177 - acc: 0.9960 - val_loss: 2.8623 - val_acc: 0.5921\n",
      "Epoch 688/1500\n",
      "Epoch 00687: val_loss did not improve\n",
      "2s - loss: 0.0085 - acc: 0.9968 - val_loss: 3.0318 - val_acc: 0.5710\n",
      "Epoch 689/1500\n",
      "Epoch 00688: val_loss did not improve\n",
      "2s - loss: 0.0116 - acc: 0.9961 - val_loss: 2.8759 - val_acc: 0.5861\n",
      "Epoch 690/1500\n",
      "Epoch 00689: val_loss did not improve\n",
      "2s - loss: 0.0761 - acc: 0.9835 - val_loss: 3.2339 - val_acc: 0.5952\n",
      "Epoch 691/1500\n",
      "Epoch 00690: val_loss did not improve\n",
      "2s - loss: 0.0107 - acc: 0.9953 - val_loss: 2.9194 - val_acc: 0.5801\n",
      "Epoch 692/1500\n",
      "Epoch 00691: val_loss did not improve\n",
      "2s - loss: 0.0380 - acc: 0.9889 - val_loss: 2.9400 - val_acc: 0.6344\n",
      "Epoch 693/1500\n",
      "Epoch 00692: val_loss did not improve\n",
      "2s - loss: 0.0140 - acc: 0.9961 - val_loss: 3.1546 - val_acc: 0.6012\n",
      "Epoch 694/1500\n",
      "Epoch 00693: val_loss did not improve\n",
      "2s - loss: 0.0079 - acc: 0.9961 - val_loss: 3.0341 - val_acc: 0.5770\n",
      "Epoch 695/1500\n",
      "Epoch 00694: val_loss did not improve\n",
      "2s - loss: 0.0073 - acc: 0.9968 - val_loss: 3.1256 - val_acc: 0.5801\n",
      "Epoch 696/1500\n",
      "Epoch 00695: val_loss did not improve\n",
      "2s - loss: 0.0161 - acc: 0.9936 - val_loss: 2.6919 - val_acc: 0.6224\n",
      "Epoch 697/1500\n",
      "Epoch 00696: val_loss did not improve\n",
      "2s - loss: 0.0242 - acc: 0.9913 - val_loss: 3.1366 - val_acc: 0.5801\n",
      "Epoch 698/1500\n",
      "Epoch 00697: val_loss did not improve\n",
      "2s - loss: 0.0073 - acc: 0.9976 - val_loss: 3.1713 - val_acc: 0.6042\n",
      "Epoch 699/1500\n",
      "Epoch 00698: val_loss did not improve\n",
      "2s - loss: 0.0197 - acc: 0.9953 - val_loss: 3.0662 - val_acc: 0.5770\n",
      "Epoch 700/1500\n",
      "Epoch 00699: val_loss did not improve\n",
      "2s - loss: 0.0165 - acc: 0.9936 - val_loss: 2.8272 - val_acc: 0.5740\n",
      "Epoch 701/1500\n",
      "Epoch 00700: val_loss did not improve\n",
      "2s - loss: 0.0176 - acc: 0.9944 - val_loss: 2.8980 - val_acc: 0.6193\n",
      "Epoch 702/1500\n",
      "Epoch 00701: val_loss did not improve\n",
      "2s - loss: 0.0262 - acc: 0.9921 - val_loss: 2.9464 - val_acc: 0.5770\n",
      "Epoch 703/1500\n",
      "Epoch 00702: val_loss did not improve\n",
      "2s - loss: 0.0134 - acc: 0.9960 - val_loss: 2.8789 - val_acc: 0.5861\n",
      "Epoch 704/1500\n",
      "Epoch 00703: val_loss did not improve\n",
      "2s - loss: 0.0100 - acc: 0.9968 - val_loss: 2.9477 - val_acc: 0.6073\n",
      "Epoch 705/1500\n",
      "Epoch 00704: val_loss did not improve\n",
      "2s - loss: 0.0393 - acc: 0.9922 - val_loss: 3.0811 - val_acc: 0.5952\n",
      "Epoch 706/1500\n",
      "Epoch 00705: val_loss did not improve\n",
      "2s - loss: 0.0135 - acc: 0.9960 - val_loss: 2.8665 - val_acc: 0.5982\n",
      "Epoch 707/1500\n",
      "Epoch 00706: val_loss did not improve\n",
      "2s - loss: 0.0061 - acc: 0.9984 - val_loss: 2.8432 - val_acc: 0.6193\n",
      "Epoch 708/1500\n",
      "Epoch 00707: val_loss did not improve\n",
      "2s - loss: 0.0041 - acc: 0.9992 - val_loss: 3.3498 - val_acc: 0.5710\n",
      "Epoch 709/1500\n",
      "Epoch 00708: val_loss did not improve\n",
      "2s - loss: 0.0117 - acc: 0.9968 - val_loss: 3.1038 - val_acc: 0.5680\n",
      "Epoch 710/1500\n",
      "Epoch 00709: val_loss did not improve\n",
      "2s - loss: 0.0144 - acc: 0.9945 - val_loss: 2.9827 - val_acc: 0.5831\n",
      "Epoch 711/1500\n",
      "Epoch 00710: val_loss did not improve\n",
      "2s - loss: 0.0102 - acc: 0.9952 - val_loss: 3.0358 - val_acc: 0.5710\n",
      "Epoch 712/1500\n",
      "Epoch 00711: val_loss did not improve\n",
      "2s - loss: 0.0250 - acc: 0.9937 - val_loss: 3.0862 - val_acc: 0.5680\n",
      "Epoch 713/1500\n",
      "Epoch 00712: val_loss did not improve\n",
      "2s - loss: 0.0155 - acc: 0.9944 - val_loss: 3.2828 - val_acc: 0.5559\n",
      "Epoch 714/1500\n",
      "Epoch 00713: val_loss did not improve\n",
      "2s - loss: 0.0113 - acc: 0.9960 - val_loss: 2.9914 - val_acc: 0.5861\n",
      "Epoch 715/1500\n",
      "Epoch 00714: val_loss did not improve\n",
      "2s - loss: 0.0044 - acc: 0.9984 - val_loss: 3.0740 - val_acc: 0.5589\n",
      "Epoch 716/1500\n",
      "Epoch 00715: val_loss did not improve\n",
      "2s - loss: 0.0059 - acc: 0.9976 - val_loss: 3.0135 - val_acc: 0.5861\n",
      "Epoch 717/1500\n",
      "Epoch 00716: val_loss did not improve\n",
      "2s - loss: 0.0122 - acc: 0.9936 - val_loss: 3.0884 - val_acc: 0.5952\n",
      "Epoch 718/1500\n",
      "Epoch 00717: val_loss did not improve\n",
      "2s - loss: 0.0201 - acc: 0.9952 - val_loss: 3.1634 - val_acc: 0.5740\n",
      "Epoch 719/1500\n",
      "Epoch 00718: val_loss did not improve\n",
      "2s - loss: 0.0190 - acc: 0.9953 - val_loss: 3.0800 - val_acc: 0.5891\n",
      "Epoch 720/1500\n",
      "Epoch 00719: val_loss did not improve\n",
      "2s - loss: 0.0130 - acc: 0.9968 - val_loss: 3.1014 - val_acc: 0.5831\n",
      "Epoch 721/1500\n",
      "Epoch 00720: val_loss did not improve\n",
      "2s - loss: 0.0126 - acc: 0.9960 - val_loss: 3.0385 - val_acc: 0.5891\n",
      "Epoch 722/1500\n",
      "Epoch 00721: val_loss did not improve\n",
      "2s - loss: 0.0217 - acc: 0.9945 - val_loss: 2.8034 - val_acc: 0.5891\n",
      "Epoch 723/1500\n",
      "Epoch 00722: val_loss did not improve\n",
      "2s - loss: 0.0034 - acc: 0.9992 - val_loss: 2.7943 - val_acc: 0.5921\n",
      "Epoch 724/1500\n",
      "Epoch 00723: val_loss did not improve\n",
      "2s - loss: 0.0094 - acc: 0.9961 - val_loss: 2.7185 - val_acc: 0.5982\n",
      "Epoch 725/1500\n",
      "Epoch 00724: val_loss did not improve\n",
      "2s - loss: 0.0107 - acc: 0.9968 - val_loss: 3.0062 - val_acc: 0.5861\n",
      "Epoch 726/1500\n",
      "Epoch 00725: val_loss did not improve\n",
      "2s - loss: 0.0547 - acc: 0.9900 - val_loss: 2.8201 - val_acc: 0.6073\n",
      "Epoch 727/1500\n",
      "Epoch 00726: val_loss did not improve\n",
      "2s - loss: 0.0087 - acc: 0.9968 - val_loss: 2.8942 - val_acc: 0.5619\n",
      "Epoch 728/1500\n",
      "Epoch 00727: val_loss did not improve\n",
      "2s - loss: 0.0066 - acc: 0.9968 - val_loss: 2.9427 - val_acc: 0.5861\n",
      "Epoch 729/1500\n",
      "Epoch 00728: val_loss did not improve\n",
      "2s - loss: 0.0136 - acc: 0.9968 - val_loss: 2.9086 - val_acc: 0.6012\n",
      "Epoch 730/1500\n",
      "Epoch 00729: val_loss did not improve\n",
      "2s - loss: 0.0391 - acc: 0.9914 - val_loss: 3.0935 - val_acc: 0.5710\n",
      "Epoch 731/1500\n",
      "Epoch 00730: val_loss did not improve\n",
      "2s - loss: 0.0196 - acc: 0.9937 - val_loss: 2.8881 - val_acc: 0.5982\n",
      "Epoch 732/1500\n",
      "Epoch 00731: val_loss did not improve\n",
      "2s - loss: 0.0074 - acc: 0.9976 - val_loss: 2.9590 - val_acc: 0.5982\n",
      "Epoch 733/1500\n",
      "Epoch 00732: val_loss did not improve\n",
      "2s - loss: 0.0127 - acc: 0.9960 - val_loss: 2.9869 - val_acc: 0.5770\n",
      "Epoch 734/1500\n",
      "Epoch 00733: val_loss did not improve\n",
      "2s - loss: 0.0193 - acc: 0.9945 - val_loss: 3.0935 - val_acc: 0.5921\n",
      "Epoch 735/1500\n",
      "Epoch 00734: val_loss did not improve\n",
      "2s - loss: 0.0373 - acc: 0.9874 - val_loss: 3.3526 - val_acc: 0.5680\n",
      "Epoch 736/1500\n",
      "Epoch 00735: val_loss did not improve\n",
      "2s - loss: 0.0018 - acc: 1.0000 - val_loss: 3.0121 - val_acc: 0.6012\n",
      "Epoch 737/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00736: val_loss did not improve\n",
      "2s - loss: 0.0148 - acc: 0.9915 - val_loss: 2.9096 - val_acc: 0.5921\n",
      "Epoch 738/1500\n",
      "Epoch 00737: val_loss did not improve\n",
      "2s - loss: 0.0135 - acc: 0.9952 - val_loss: 3.0406 - val_acc: 0.6012\n",
      "Epoch 739/1500\n",
      "Epoch 00738: val_loss did not improve\n",
      "2s - loss: 0.0159 - acc: 0.9930 - val_loss: 3.0903 - val_acc: 0.5861\n",
      "Epoch 740/1500\n",
      "Epoch 00739: val_loss did not improve\n",
      "2s - loss: 0.0360 - acc: 0.9921 - val_loss: 3.3679 - val_acc: 0.5650\n",
      "Epoch 741/1500\n",
      "Epoch 00740: val_loss did not improve\n",
      "2s - loss: 0.0101 - acc: 0.9961 - val_loss: 3.0014 - val_acc: 0.5982\n",
      "Epoch 742/1500\n",
      "Epoch 00741: val_loss did not improve\n",
      "2s - loss: 0.0230 - acc: 0.9922 - val_loss: 3.2191 - val_acc: 0.6042\n",
      "Epoch 743/1500\n",
      "Epoch 00742: val_loss did not improve\n",
      "2s - loss: 0.0052 - acc: 0.9992 - val_loss: 3.0314 - val_acc: 0.6073\n",
      "Epoch 744/1500\n",
      "Epoch 00743: val_loss did not improve\n",
      "2s - loss: 0.0112 - acc: 0.9976 - val_loss: 3.0011 - val_acc: 0.5952\n",
      "Epoch 745/1500\n",
      "Epoch 00744: val_loss did not improve\n",
      "2s - loss: 0.0051 - acc: 0.9976 - val_loss: 3.1034 - val_acc: 0.5861\n",
      "Epoch 746/1500\n",
      "Epoch 00745: val_loss did not improve\n",
      "2s - loss: 0.0068 - acc: 0.9984 - val_loss: 3.1426 - val_acc: 0.5982\n",
      "Epoch 747/1500\n",
      "Epoch 00746: val_loss did not improve\n",
      "2s - loss: 0.0056 - acc: 0.9992 - val_loss: 3.5570 - val_acc: 0.5710\n",
      "Epoch 748/1500\n",
      "Epoch 00747: val_loss did not improve\n",
      "2s - loss: 0.0268 - acc: 0.9913 - val_loss: 3.2276 - val_acc: 0.5891\n",
      "Epoch 749/1500\n",
      "Epoch 00748: val_loss did not improve\n",
      "2s - loss: 0.0245 - acc: 0.9905 - val_loss: 3.2014 - val_acc: 0.6012\n",
      "Epoch 750/1500\n",
      "Epoch 00749: val_loss did not improve\n",
      "2s - loss: 0.0172 - acc: 0.9906 - val_loss: 3.0934 - val_acc: 0.6073\n",
      "Epoch 751/1500\n",
      "Epoch 00750: val_loss did not improve\n",
      "2s - loss: 0.0057 - acc: 0.9984 - val_loss: 3.2616 - val_acc: 0.5770\n",
      "Epoch 752/1500\n",
      "Epoch 00751: val_loss did not improve\n",
      "2s - loss: 0.0058 - acc: 0.9976 - val_loss: 3.0691 - val_acc: 0.6042\n",
      "Epoch 753/1500\n",
      "Epoch 00752: val_loss did not improve\n",
      "2s - loss: 0.0033 - acc: 0.9992 - val_loss: 3.0587 - val_acc: 0.5921\n",
      "Epoch 754/1500\n",
      "Epoch 00753: val_loss did not improve\n",
      "2s - loss: 0.0072 - acc: 0.9984 - val_loss: 3.2823 - val_acc: 0.5861\n",
      "Epoch 755/1500\n",
      "Epoch 00754: val_loss did not improve\n",
      "2s - loss: 0.0196 - acc: 0.9953 - val_loss: 3.0363 - val_acc: 0.5740\n",
      "Epoch 756/1500\n",
      "Epoch 00755: val_loss did not improve\n",
      "2s - loss: 0.0058 - acc: 0.9976 - val_loss: 2.9364 - val_acc: 0.5861\n",
      "Epoch 757/1500\n",
      "Epoch 00756: val_loss did not improve\n",
      "2s - loss: 0.0125 - acc: 0.9968 - val_loss: 2.8742 - val_acc: 0.5861\n",
      "Epoch 758/1500\n",
      "Epoch 00757: val_loss did not improve\n",
      "2s - loss: 0.0085 - acc: 0.9976 - val_loss: 3.2371 - val_acc: 0.5801\n",
      "Epoch 759/1500\n",
      "Epoch 00758: val_loss did not improve\n",
      "2s - loss: 0.0290 - acc: 0.9945 - val_loss: 3.0699 - val_acc: 0.6103\n",
      "Epoch 760/1500\n",
      "Epoch 00759: val_loss did not improve\n",
      "2s - loss: 0.0045 - acc: 1.0000 - val_loss: 2.9031 - val_acc: 0.5982\n",
      "Epoch 761/1500\n",
      "Epoch 00760: val_loss did not improve\n",
      "2s - loss: 0.0075 - acc: 0.9977 - val_loss: 3.0684 - val_acc: 0.5982\n",
      "Epoch 762/1500\n",
      "Epoch 00761: val_loss did not improve\n",
      "2s - loss: 0.0104 - acc: 0.9968 - val_loss: 3.1386 - val_acc: 0.5740\n",
      "Epoch 763/1500\n",
      "Epoch 00762: val_loss did not improve\n",
      "2s - loss: 0.0227 - acc: 0.9923 - val_loss: 3.1157 - val_acc: 0.5952\n",
      "Epoch 764/1500\n",
      "Epoch 00763: val_loss did not improve\n",
      "2s - loss: 0.0031 - acc: 0.9992 - val_loss: 3.2049 - val_acc: 0.5891\n",
      "Epoch 765/1500\n",
      "Epoch 00764: val_loss did not improve\n",
      "2s - loss: 0.0072 - acc: 0.9984 - val_loss: 3.0920 - val_acc: 0.5710\n",
      "Epoch 766/1500\n",
      "Epoch 00765: val_loss did not improve\n",
      "2s - loss: 0.0085 - acc: 0.9968 - val_loss: 3.2501 - val_acc: 0.6012\n",
      "Epoch 767/1500\n",
      "Epoch 00766: val_loss did not improve\n",
      "2s - loss: 0.0112 - acc: 0.9961 - val_loss: 3.0503 - val_acc: 0.6163\n",
      "Epoch 768/1500\n",
      "Epoch 00767: val_loss did not improve\n",
      "2s - loss: 0.0102 - acc: 0.9968 - val_loss: 3.1892 - val_acc: 0.5680\n",
      "Epoch 769/1500\n",
      "Epoch 00768: val_loss did not improve\n",
      "2s - loss: 0.0093 - acc: 0.9968 - val_loss: 3.0821 - val_acc: 0.6344\n",
      "Epoch 770/1500\n",
      "Epoch 00769: val_loss did not improve\n",
      "2s - loss: 0.0085 - acc: 0.9960 - val_loss: 3.2831 - val_acc: 0.5861\n",
      "Epoch 771/1500\n",
      "Epoch 00770: val_loss did not improve\n",
      "2s - loss: 0.0249 - acc: 0.9912 - val_loss: 3.0023 - val_acc: 0.6073\n",
      "Epoch 772/1500\n",
      "Epoch 00771: val_loss did not improve\n",
      "2s - loss: 0.0156 - acc: 0.9930 - val_loss: 3.0514 - val_acc: 0.6224\n",
      "Epoch 773/1500\n",
      "Epoch 00772: val_loss did not improve\n",
      "2s - loss: 0.0031 - acc: 0.9992 - val_loss: 2.8584 - val_acc: 0.6042\n",
      "Epoch 774/1500\n",
      "Epoch 00773: val_loss did not improve\n",
      "2s - loss: 0.0205 - acc: 0.9937 - val_loss: 3.2935 - val_acc: 0.5921\n",
      "Epoch 775/1500\n",
      "Epoch 00774: val_loss did not improve\n",
      "2s - loss: 0.0109 - acc: 0.9945 - val_loss: 2.9808 - val_acc: 0.6193\n",
      "Epoch 776/1500\n",
      "Epoch 00775: val_loss did not improve\n",
      "2s - loss: 0.0214 - acc: 0.9930 - val_loss: 3.0039 - val_acc: 0.5740\n",
      "Epoch 777/1500\n",
      "Epoch 00776: val_loss did not improve\n",
      "2s - loss: 0.0329 - acc: 0.9929 - val_loss: 2.8838 - val_acc: 0.6133\n",
      "Epoch 778/1500\n",
      "Epoch 00777: val_loss did not improve\n",
      "2s - loss: 0.0291 - acc: 0.9897 - val_loss: 3.0311 - val_acc: 0.5891\n",
      "Epoch 779/1500\n",
      "Epoch 00778: val_loss did not improve\n",
      "2s - loss: 0.0097 - acc: 0.9961 - val_loss: 3.1328 - val_acc: 0.5891\n",
      "Epoch 780/1500\n",
      "Epoch 00779: val_loss did not improve\n",
      "2s - loss: 0.0098 - acc: 0.9960 - val_loss: 2.9921 - val_acc: 0.6163\n",
      "Epoch 781/1500\n",
      "Epoch 00780: val_loss did not improve\n",
      "2s - loss: 0.0067 - acc: 0.9984 - val_loss: 3.2884 - val_acc: 0.5740\n",
      "Epoch 782/1500\n",
      "Epoch 00781: val_loss did not improve\n",
      "2s - loss: 0.0172 - acc: 0.9929 - val_loss: 2.9967 - val_acc: 0.6103\n",
      "Epoch 783/1500\n",
      "Epoch 00782: val_loss did not improve\n",
      "2s - loss: 0.0047 - acc: 0.9992 - val_loss: 3.1742 - val_acc: 0.6193\n",
      "Epoch 784/1500\n",
      "Epoch 00783: val_loss did not improve\n",
      "2s - loss: 0.0133 - acc: 0.9968 - val_loss: 3.0479 - val_acc: 0.6163\n",
      "Epoch 785/1500\n",
      "Epoch 00784: val_loss did not improve\n",
      "2s - loss: 0.0030 - acc: 1.0000 - val_loss: 2.9754 - val_acc: 0.6254\n",
      "Epoch 786/1500\n",
      "Epoch 00785: val_loss did not improve\n",
      "2s - loss: 0.0048 - acc: 0.9968 - val_loss: 3.2017 - val_acc: 0.5801\n",
      "Epoch 787/1500\n",
      "Epoch 00786: val_loss did not improve\n",
      "2s - loss: 0.0071 - acc: 0.9976 - val_loss: 2.9793 - val_acc: 0.5982\n",
      "Epoch 788/1500\n",
      "Epoch 00787: val_loss did not improve\n",
      "2s - loss: 0.0154 - acc: 0.9936 - val_loss: 3.3604 - val_acc: 0.5680\n",
      "Epoch 789/1500\n",
      "Epoch 00788: val_loss did not improve\n",
      "2s - loss: 0.0304 - acc: 0.9938 - val_loss: 3.1239 - val_acc: 0.5921\n",
      "Epoch 790/1500\n",
      "Epoch 00789: val_loss did not improve\n",
      "2s - loss: 0.0157 - acc: 0.9961 - val_loss: 3.0529 - val_acc: 0.5982\n",
      "Epoch 791/1500\n",
      "Epoch 00790: val_loss did not improve\n",
      "2s - loss: 0.0066 - acc: 0.9984 - val_loss: 2.9116 - val_acc: 0.6133\n",
      "Epoch 792/1500\n",
      "Epoch 00791: val_loss did not improve\n",
      "2s - loss: 0.1009 - acc: 0.9860 - val_loss: 2.8977 - val_acc: 0.6103\n",
      "Epoch 793/1500\n",
      "Epoch 00792: val_loss did not improve\n",
      "2s - loss: 0.0361 - acc: 0.9891 - val_loss: 3.0006 - val_acc: 0.5982\n",
      "Epoch 794/1500\n",
      "Epoch 00793: val_loss did not improve\n",
      "2s - loss: 0.0097 - acc: 0.9945 - val_loss: 3.1296 - val_acc: 0.5952\n",
      "Epoch 795/1500\n",
      "Epoch 00794: val_loss did not improve\n",
      "2s - loss: 0.0057 - acc: 0.9976 - val_loss: 3.5046 - val_acc: 0.5589\n",
      "Epoch 796/1500\n",
      "Epoch 00795: val_loss did not improve\n",
      "2s - loss: 0.0064 - acc: 0.9968 - val_loss: 3.0264 - val_acc: 0.6193\n",
      "Epoch 797/1500\n",
      "Epoch 00796: val_loss did not improve\n",
      "2s - loss: 0.0049 - acc: 0.9976 - val_loss: 2.7982 - val_acc: 0.6284\n",
      "Epoch 798/1500\n",
      "Epoch 00797: val_loss did not improve\n",
      "2s - loss: 0.0109 - acc: 0.9960 - val_loss: 3.4262 - val_acc: 0.5740\n",
      "Epoch 799/1500\n",
      "Epoch 00798: val_loss did not improve\n",
      "2s - loss: 0.0039 - acc: 0.9992 - val_loss: 3.0612 - val_acc: 0.5952\n",
      "Epoch 800/1500\n",
      "Epoch 00799: val_loss did not improve\n",
      "2s - loss: 0.0205 - acc: 0.9960 - val_loss: 3.1306 - val_acc: 0.6193\n",
      "Epoch 801/1500\n",
      "Epoch 00800: val_loss did not improve\n",
      "2s - loss: 0.0063 - acc: 0.9984 - val_loss: 3.1508 - val_acc: 0.5952\n",
      "Epoch 802/1500\n",
      "Epoch 00801: val_loss did not improve\n",
      "2s - loss: 0.0080 - acc: 0.9968 - val_loss: 3.2909 - val_acc: 0.5831\n",
      "Epoch 803/1500\n",
      "Epoch 00802: val_loss did not improve\n",
      "2s - loss: 0.0137 - acc: 0.9968 - val_loss: 3.5019 - val_acc: 0.5891\n",
      "Epoch 804/1500\n",
      "Epoch 00803: val_loss did not improve\n",
      "2s - loss: 0.0335 - acc: 0.9915 - val_loss: 3.1027 - val_acc: 0.5921\n",
      "Epoch 805/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00804: val_loss did not improve\n",
      "2s - loss: 0.0190 - acc: 0.9920 - val_loss: 3.0603 - val_acc: 0.6073\n",
      "Epoch 806/1500\n",
      "Epoch 00805: val_loss did not improve\n",
      "2s - loss: 0.0102 - acc: 0.9968 - val_loss: 2.9660 - val_acc: 0.6073\n",
      "Epoch 807/1500\n",
      "Epoch 00806: val_loss did not improve\n",
      "2s - loss: 0.0107 - acc: 0.9952 - val_loss: 3.0563 - val_acc: 0.5982\n",
      "Epoch 808/1500\n",
      "Epoch 00807: val_loss did not improve\n",
      "2s - loss: 0.0084 - acc: 0.9952 - val_loss: 2.6462 - val_acc: 0.6435\n",
      "Epoch 809/1500\n",
      "Epoch 00808: val_loss did not improve\n",
      "2s - loss: 0.0168 - acc: 0.9936 - val_loss: 3.0135 - val_acc: 0.6042\n",
      "Epoch 810/1500\n",
      "Epoch 00809: val_loss did not improve\n",
      "2s - loss: 0.0168 - acc: 0.9944 - val_loss: 2.9810 - val_acc: 0.6254\n",
      "Epoch 811/1500\n",
      "Epoch 00810: val_loss did not improve\n",
      "2s - loss: 0.0072 - acc: 0.9968 - val_loss: 3.1015 - val_acc: 0.6163\n",
      "Epoch 812/1500\n",
      "Epoch 00811: val_loss did not improve\n",
      "2s - loss: 0.0101 - acc: 0.9968 - val_loss: 3.2276 - val_acc: 0.5982\n",
      "Epoch 813/1500\n",
      "Epoch 00812: val_loss did not improve\n",
      "2s - loss: 0.0051 - acc: 0.9992 - val_loss: 2.9161 - val_acc: 0.5982\n",
      "Epoch 814/1500\n",
      "Epoch 00813: val_loss did not improve\n",
      "2s - loss: 0.0063 - acc: 0.9984 - val_loss: 3.2071 - val_acc: 0.5801\n",
      "Epoch 815/1500\n",
      "Epoch 00814: val_loss did not improve\n",
      "2s - loss: 0.0057 - acc: 0.9976 - val_loss: 3.6746 - val_acc: 0.5740\n",
      "Epoch 816/1500\n",
      "Epoch 00815: val_loss did not improve\n",
      "2s - loss: 0.0056 - acc: 0.9976 - val_loss: 2.9995 - val_acc: 0.5982\n",
      "Epoch 817/1500\n",
      "Epoch 00816: val_loss did not improve\n",
      "2s - loss: 0.0305 - acc: 0.9929 - val_loss: 3.2914 - val_acc: 0.5619\n",
      "Epoch 818/1500\n",
      "Epoch 00817: val_loss did not improve\n",
      "2s - loss: 0.0087 - acc: 0.9960 - val_loss: 3.0499 - val_acc: 0.5740\n",
      "Epoch 819/1500\n",
      "Epoch 00818: val_loss did not improve\n",
      "2s - loss: 0.0310 - acc: 0.9904 - val_loss: 3.1539 - val_acc: 0.5801\n",
      "Epoch 820/1500\n",
      "Epoch 00819: val_loss did not improve\n",
      "2s - loss: 0.0035 - acc: 0.9984 - val_loss: 3.0383 - val_acc: 0.6133\n",
      "Epoch 821/1500\n",
      "Epoch 00820: val_loss did not improve\n",
      "2s - loss: 0.0236 - acc: 0.9922 - val_loss: 2.8163 - val_acc: 0.6284\n",
      "Epoch 822/1500\n",
      "Epoch 00821: val_loss did not improve\n",
      "2s - loss: 0.0124 - acc: 0.9961 - val_loss: 3.1977 - val_acc: 0.5891\n",
      "Epoch 823/1500\n",
      "Epoch 00822: val_loss did not improve\n",
      "2s - loss: 0.0056 - acc: 0.9968 - val_loss: 3.2824 - val_acc: 0.5952\n",
      "Epoch 824/1500\n",
      "Epoch 00823: val_loss did not improve\n",
      "2s - loss: 0.0179 - acc: 0.9945 - val_loss: 3.0646 - val_acc: 0.6012\n",
      "Epoch 825/1500\n",
      "Epoch 00824: val_loss did not improve\n",
      "2s - loss: 0.0312 - acc: 0.9953 - val_loss: 3.1727 - val_acc: 0.6042\n",
      "Epoch 826/1500\n",
      "Epoch 00825: val_loss did not improve\n",
      "2s - loss: 0.0424 - acc: 0.9899 - val_loss: 3.1474 - val_acc: 0.5921\n",
      "Epoch 827/1500\n",
      "Epoch 00826: val_loss did not improve\n",
      "2s - loss: 0.0073 - acc: 0.9961 - val_loss: 3.1727 - val_acc: 0.5680\n",
      "Epoch 828/1500\n",
      "Epoch 00827: val_loss did not improve\n",
      "2s - loss: 0.0068 - acc: 0.9976 - val_loss: 3.0237 - val_acc: 0.5982\n",
      "Epoch 829/1500\n",
      "Epoch 00828: val_loss did not improve\n",
      "2s - loss: 0.0117 - acc: 0.9960 - val_loss: 3.2261 - val_acc: 0.6042\n",
      "Epoch 830/1500\n",
      "Epoch 00829: val_loss did not improve\n",
      "2s - loss: 0.0104 - acc: 0.9976 - val_loss: 3.4663 - val_acc: 0.5801\n",
      "Epoch 831/1500\n",
      "Epoch 00830: val_loss did not improve\n",
      "2s - loss: 0.0249 - acc: 0.9907 - val_loss: 2.9439 - val_acc: 0.6344\n",
      "Epoch 832/1500\n",
      "Epoch 00831: val_loss did not improve\n",
      "2s - loss: 0.0045 - acc: 0.9984 - val_loss: 3.0263 - val_acc: 0.6344\n",
      "Epoch 833/1500\n",
      "Epoch 00832: val_loss did not improve\n",
      "2s - loss: 0.0074 - acc: 0.9976 - val_loss: 3.2277 - val_acc: 0.6133\n",
      "Epoch 834/1500\n",
      "Epoch 00833: val_loss did not improve\n",
      "2s - loss: 0.0086 - acc: 0.9968 - val_loss: 3.0389 - val_acc: 0.6224\n",
      "Epoch 835/1500\n",
      "Epoch 00834: val_loss did not improve\n",
      "2s - loss: 0.0155 - acc: 0.9953 - val_loss: 3.5419 - val_acc: 0.5952\n",
      "Epoch 836/1500\n",
      "Epoch 00835: val_loss did not improve\n",
      "2s - loss: 0.0134 - acc: 0.9961 - val_loss: 3.4453 - val_acc: 0.5801\n",
      "Epoch 837/1500\n",
      "Epoch 00836: val_loss did not improve\n",
      "2s - loss: 0.0139 - acc: 0.9945 - val_loss: 3.1117 - val_acc: 0.5831\n",
      "Epoch 838/1500\n",
      "Epoch 00837: val_loss did not improve\n",
      "2s - loss: 0.0138 - acc: 0.9928 - val_loss: 3.1576 - val_acc: 0.6073\n",
      "Epoch 839/1500\n",
      "Epoch 00838: val_loss did not improve\n",
      "2s - loss: 0.0203 - acc: 0.9952 - val_loss: 3.3438 - val_acc: 0.6073\n",
      "Epoch 840/1500\n",
      "Epoch 00839: val_loss did not improve\n",
      "2s - loss: 0.0017 - acc: 1.0000 - val_loss: 3.2087 - val_acc: 0.6012\n",
      "Epoch 841/1500\n",
      "Epoch 00840: val_loss did not improve\n",
      "2s - loss: 0.0146 - acc: 0.9921 - val_loss: 3.3287 - val_acc: 0.6073\n",
      "Epoch 842/1500\n",
      "Epoch 00841: val_loss did not improve\n",
      "2s - loss: 0.0091 - acc: 0.9960 - val_loss: 3.1528 - val_acc: 0.6344\n",
      "Epoch 843/1500\n",
      "Epoch 00842: val_loss did not improve\n",
      "2s - loss: 0.0143 - acc: 0.9960 - val_loss: 3.1673 - val_acc: 0.6224\n",
      "Epoch 844/1500\n",
      "Epoch 00843: val_loss did not improve\n",
      "2s - loss: 0.0190 - acc: 0.9936 - val_loss: 3.3248 - val_acc: 0.5770\n",
      "Epoch 845/1500\n",
      "Epoch 00844: val_loss did not improve\n",
      "2s - loss: 0.0235 - acc: 0.9891 - val_loss: 2.7380 - val_acc: 0.6224\n",
      "Epoch 846/1500\n",
      "Epoch 00845: val_loss did not improve\n",
      "2s - loss: 0.0051 - acc: 0.9984 - val_loss: 2.7995 - val_acc: 0.6344\n",
      "Epoch 847/1500\n",
      "Epoch 00846: val_loss did not improve\n",
      "2s - loss: 0.0150 - acc: 0.9960 - val_loss: 3.2906 - val_acc: 0.5921\n",
      "Epoch 848/1500\n",
      "Epoch 00847: val_loss did not improve\n",
      "2s - loss: 0.0643 - acc: 0.9915 - val_loss: 3.2432 - val_acc: 0.5891\n",
      "Epoch 849/1500\n",
      "Epoch 00848: val_loss did not improve\n",
      "2s - loss: 0.0160 - acc: 0.9969 - val_loss: 3.2240 - val_acc: 0.5801\n",
      "Epoch 850/1500\n",
      "Epoch 00849: val_loss did not improve\n",
      "2s - loss: 0.0206 - acc: 0.9929 - val_loss: 3.2961 - val_acc: 0.6133\n",
      "Epoch 851/1500\n",
      "Epoch 00850: val_loss did not improve\n",
      "2s - loss: 0.0096 - acc: 0.9976 - val_loss: 2.9986 - val_acc: 0.5952\n",
      "Epoch 852/1500\n",
      "Epoch 00851: val_loss did not improve\n",
      "2s - loss: 0.0059 - acc: 0.9984 - val_loss: 2.9705 - val_acc: 0.6193\n",
      "Epoch 853/1500\n",
      "Epoch 00852: val_loss did not improve\n",
      "2s - loss: 0.0078 - acc: 0.9969 - val_loss: 3.3267 - val_acc: 0.5801\n",
      "Epoch 854/1500\n",
      "Epoch 00853: val_loss did not improve\n",
      "2s - loss: 0.0075 - acc: 0.9976 - val_loss: 2.8426 - val_acc: 0.6224\n",
      "Epoch 855/1500\n",
      "Epoch 00854: val_loss did not improve\n",
      "2s - loss: 0.0046 - acc: 0.9992 - val_loss: 2.9770 - val_acc: 0.6103\n",
      "Epoch 856/1500\n",
      "Epoch 00855: val_loss did not improve\n",
      "2s - loss: 0.0212 - acc: 0.9914 - val_loss: 3.2468 - val_acc: 0.5468\n",
      "Epoch 857/1500\n",
      "Epoch 00856: val_loss did not improve\n",
      "2s - loss: 0.0057 - acc: 0.9976 - val_loss: 3.0818 - val_acc: 0.6012\n",
      "Epoch 858/1500\n",
      "Epoch 00857: val_loss did not improve\n",
      "2s - loss: 0.0321 - acc: 0.9937 - val_loss: 3.0250 - val_acc: 0.6224\n",
      "Epoch 859/1500\n",
      "Epoch 00858: val_loss did not improve\n",
      "2s - loss: 0.0153 - acc: 0.9969 - val_loss: 3.4482 - val_acc: 0.5861\n",
      "Epoch 860/1500\n",
      "Epoch 00859: val_loss did not improve\n",
      "2s - loss: 0.0028 - acc: 1.0000 - val_loss: 3.0472 - val_acc: 0.6103\n",
      "Epoch 861/1500\n",
      "Epoch 00860: val_loss did not improve\n",
      "2s - loss: 0.0369 - acc: 0.9938 - val_loss: 3.3150 - val_acc: 0.6103\n",
      "Epoch 862/1500\n",
      "Epoch 00861: val_loss did not improve\n",
      "2s - loss: 0.0114 - acc: 0.9929 - val_loss: 3.0213 - val_acc: 0.6103\n",
      "Epoch 863/1500\n",
      "Epoch 00862: val_loss did not improve\n",
      "2s - loss: 0.0144 - acc: 0.9937 - val_loss: 3.5359 - val_acc: 0.5589\n",
      "Epoch 864/1500\n",
      "Epoch 00863: val_loss did not improve\n",
      "2s - loss: 0.0095 - acc: 0.9976 - val_loss: 2.6443 - val_acc: 0.6435\n",
      "Epoch 865/1500\n",
      "Epoch 00864: val_loss did not improve\n",
      "2s - loss: 0.0090 - acc: 0.9984 - val_loss: 3.2336 - val_acc: 0.5982\n",
      "Epoch 866/1500\n",
      "Epoch 00865: val_loss did not improve\n",
      "2s - loss: 0.0078 - acc: 0.9960 - val_loss: 3.2059 - val_acc: 0.5952\n",
      "Epoch 867/1500\n",
      "Epoch 00866: val_loss did not improve\n",
      "2s - loss: 0.0052 - acc: 0.9976 - val_loss: 3.1598 - val_acc: 0.6193\n",
      "Epoch 868/1500\n",
      "Epoch 00867: val_loss did not improve\n",
      "2s - loss: 0.0132 - acc: 0.9936 - val_loss: 3.1827 - val_acc: 0.5982\n",
      "Epoch 869/1500\n",
      "Epoch 00868: val_loss did not improve\n",
      "2s - loss: 0.0152 - acc: 0.9945 - val_loss: 2.9524 - val_acc: 0.6163\n",
      "Epoch 870/1500\n",
      "Epoch 00869: val_loss did not improve\n",
      "2s - loss: 0.0270 - acc: 0.9914 - val_loss: 3.1700 - val_acc: 0.6042\n",
      "Epoch 871/1500\n",
      "Epoch 00870: val_loss did not improve\n",
      "2s - loss: 0.0097 - acc: 0.9976 - val_loss: 3.0997 - val_acc: 0.6163\n",
      "Epoch 872/1500\n",
      "Epoch 00871: val_loss did not improve\n",
      "2s - loss: 0.0047 - acc: 0.9992 - val_loss: 3.1012 - val_acc: 0.5921\n",
      "Epoch 873/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00872: val_loss did not improve\n",
      "2s - loss: 0.0314 - acc: 0.9921 - val_loss: 3.2093 - val_acc: 0.5952\n",
      "Epoch 874/1500\n",
      "Epoch 00873: val_loss did not improve\n",
      "2s - loss: 0.0021 - acc: 1.0000 - val_loss: 3.0318 - val_acc: 0.6133\n",
      "Epoch 875/1500\n",
      "Epoch 00874: val_loss did not improve\n",
      "2s - loss: 0.0048 - acc: 0.9977 - val_loss: 3.1138 - val_acc: 0.6073\n",
      "Epoch 876/1500\n",
      "Epoch 00875: val_loss did not improve\n",
      "2s - loss: 0.0065 - acc: 0.9961 - val_loss: 2.9564 - val_acc: 0.6314\n",
      "Epoch 877/1500\n",
      "Epoch 00876: val_loss did not improve\n",
      "2s - loss: 0.0097 - acc: 0.9953 - val_loss: 3.3714 - val_acc: 0.6163\n",
      "Epoch 878/1500\n",
      "Epoch 00877: val_loss did not improve\n",
      "2s - loss: 0.0101 - acc: 0.9960 - val_loss: 2.9400 - val_acc: 0.6344\n",
      "Epoch 879/1500\n",
      "Epoch 00878: val_loss did not improve\n",
      "2s - loss: 0.0037 - acc: 0.9992 - val_loss: 3.1190 - val_acc: 0.6042\n",
      "Epoch 880/1500\n",
      "Epoch 00879: val_loss did not improve\n",
      "2s - loss: 0.0085 - acc: 0.9976 - val_loss: 3.2638 - val_acc: 0.5952\n",
      "Epoch 881/1500\n",
      "Epoch 00880: val_loss did not improve\n",
      "2s - loss: 0.0035 - acc: 0.9992 - val_loss: 2.6818 - val_acc: 0.6314\n",
      "Epoch 882/1500\n",
      "Epoch 00881: val_loss did not improve\n",
      "2s - loss: 0.0039 - acc: 0.9992 - val_loss: 3.4039 - val_acc: 0.6133\n",
      "Epoch 883/1500\n",
      "Epoch 00882: val_loss did not improve\n",
      "2s - loss: 0.0121 - acc: 0.9960 - val_loss: 3.1908 - val_acc: 0.5861\n",
      "Epoch 884/1500\n",
      "Epoch 00883: val_loss did not improve\n",
      "2s - loss: 0.0155 - acc: 0.9952 - val_loss: 3.0663 - val_acc: 0.5982\n",
      "Epoch 885/1500\n",
      "Epoch 00884: val_loss did not improve\n",
      "2s - loss: 0.0105 - acc: 0.9960 - val_loss: 3.1082 - val_acc: 0.6254\n",
      "Epoch 886/1500\n",
      "Epoch 00885: val_loss did not improve\n",
      "2s - loss: 0.0101 - acc: 0.9976 - val_loss: 3.4599 - val_acc: 0.6103\n",
      "Epoch 887/1500\n",
      "Epoch 00886: val_loss did not improve\n",
      "2s - loss: 0.0159 - acc: 0.9968 - val_loss: 3.1575 - val_acc: 0.5861\n",
      "Epoch 888/1500\n",
      "Epoch 00887: val_loss did not improve\n",
      "2s - loss: 0.0077 - acc: 0.9984 - val_loss: 3.3902 - val_acc: 0.5680\n",
      "Epoch 889/1500\n",
      "Epoch 00888: val_loss did not improve\n",
      "2s - loss: 0.0076 - acc: 0.9976 - val_loss: 3.2495 - val_acc: 0.6012\n",
      "Epoch 890/1500\n",
      "Epoch 00889: val_loss did not improve\n",
      "2s - loss: 0.0201 - acc: 0.9936 - val_loss: 3.2465 - val_acc: 0.6073\n",
      "Epoch 891/1500\n",
      "Epoch 00890: val_loss did not improve\n",
      "2s - loss: 0.0038 - acc: 0.9984 - val_loss: 3.0043 - val_acc: 0.6344\n",
      "Epoch 892/1500\n",
      "Epoch 00891: val_loss did not improve\n",
      "2s - loss: 0.0060 - acc: 0.9976 - val_loss: 3.4218 - val_acc: 0.5891\n",
      "Epoch 893/1500\n",
      "Epoch 00892: val_loss did not improve\n",
      "2s - loss: 0.0072 - acc: 0.9960 - val_loss: 3.3553 - val_acc: 0.5831\n",
      "Epoch 894/1500\n",
      "Epoch 00893: val_loss did not improve\n",
      "2s - loss: 0.0049 - acc: 0.9976 - val_loss: 3.3349 - val_acc: 0.5921\n",
      "Epoch 895/1500\n",
      "Epoch 00894: val_loss did not improve\n",
      "2s - loss: 0.0080 - acc: 0.9976 - val_loss: 3.3343 - val_acc: 0.5861\n",
      "Epoch 896/1500\n",
      "Epoch 00895: val_loss did not improve\n",
      "2s - loss: 0.0097 - acc: 0.9968 - val_loss: 3.0951 - val_acc: 0.6344\n",
      "Epoch 897/1500\n",
      "Epoch 00896: val_loss did not improve\n",
      "2s - loss: 0.0101 - acc: 0.9976 - val_loss: 3.2860 - val_acc: 0.5891\n",
      "Epoch 898/1500\n",
      "Epoch 00897: val_loss did not improve\n",
      "2s - loss: 0.0115 - acc: 0.9968 - val_loss: 3.1682 - val_acc: 0.5831\n",
      "Epoch 899/1500\n",
      "Epoch 00898: val_loss did not improve\n",
      "2s - loss: 0.0035 - acc: 1.0000 - val_loss: 3.3528 - val_acc: 0.6103\n",
      "Epoch 900/1500\n",
      "Epoch 00899: val_loss did not improve\n",
      "2s - loss: 0.0024 - acc: 0.9992 - val_loss: 3.1286 - val_acc: 0.6224\n",
      "Epoch 901/1500\n",
      "Epoch 00900: val_loss did not improve\n",
      "2s - loss: 0.0057 - acc: 0.9984 - val_loss: 3.1753 - val_acc: 0.6284\n",
      "Epoch 902/1500\n",
      "Epoch 00901: val_loss did not improve\n",
      "2s - loss: 0.0019 - acc: 0.9992 - val_loss: 3.5014 - val_acc: 0.5861\n",
      "Epoch 903/1500\n",
      "Epoch 00902: val_loss did not improve\n",
      "2s - loss: 0.0073 - acc: 0.9960 - val_loss: 2.8923 - val_acc: 0.6435\n",
      "Epoch 904/1500\n",
      "Epoch 00903: val_loss did not improve\n",
      "2s - loss: 0.0075 - acc: 0.9961 - val_loss: 3.2240 - val_acc: 0.6073\n",
      "Epoch 905/1500\n",
      "Epoch 00904: val_loss did not improve\n",
      "2s - loss: 0.0164 - acc: 0.9913 - val_loss: 3.0895 - val_acc: 0.6284\n",
      "Epoch 906/1500\n",
      "Epoch 00905: val_loss did not improve\n",
      "2s - loss: 0.0481 - acc: 0.9876 - val_loss: 3.2988 - val_acc: 0.5710\n",
      "Epoch 907/1500\n",
      "Epoch 00906: val_loss did not improve\n",
      "2s - loss: 0.0194 - acc: 0.9930 - val_loss: 3.0213 - val_acc: 0.5650\n",
      "Epoch 908/1500\n",
      "Epoch 00907: val_loss did not improve\n",
      "2s - loss: 0.0115 - acc: 0.9984 - val_loss: 3.1231 - val_acc: 0.5589\n",
      "Epoch 909/1500\n",
      "Epoch 00908: val_loss did not improve\n",
      "2s - loss: 0.0047 - acc: 0.9992 - val_loss: 3.1681 - val_acc: 0.5861\n",
      "Epoch 910/1500\n",
      "Epoch 00909: val_loss did not improve\n",
      "2s - loss: 0.0177 - acc: 0.9952 - val_loss: 3.1126 - val_acc: 0.5952\n",
      "Epoch 911/1500\n",
      "Epoch 00910: val_loss did not improve\n",
      "2s - loss: 0.0090 - acc: 0.9953 - val_loss: 3.2595 - val_acc: 0.5740\n",
      "Epoch 912/1500\n",
      "Epoch 00911: val_loss did not improve\n",
      "2s - loss: 0.0064 - acc: 0.9976 - val_loss: 3.2908 - val_acc: 0.5770\n",
      "Epoch 913/1500\n",
      "Epoch 00912: val_loss did not improve\n",
      "2s - loss: 0.0024 - acc: 0.9992 - val_loss: 3.1534 - val_acc: 0.5831\n",
      "Epoch 914/1500\n",
      "Epoch 00913: val_loss did not improve\n",
      "2s - loss: 0.0025 - acc: 1.0000 - val_loss: 3.0684 - val_acc: 0.5861\n",
      "Epoch 915/1500\n",
      "Epoch 00914: val_loss did not improve\n",
      "2s - loss: 0.0102 - acc: 0.9992 - val_loss: 3.2888 - val_acc: 0.5982\n",
      "Epoch 916/1500\n",
      "Epoch 00915: val_loss did not improve\n",
      "2s - loss: 0.0084 - acc: 0.9976 - val_loss: 3.2787 - val_acc: 0.6012\n",
      "Epoch 917/1500\n",
      "Epoch 00916: val_loss did not improve\n",
      "2s - loss: 0.0059 - acc: 0.9969 - val_loss: 3.4508 - val_acc: 0.5801\n",
      "Epoch 918/1500\n",
      "Epoch 00917: val_loss did not improve\n",
      "2s - loss: 0.0114 - acc: 0.9969 - val_loss: 3.0549 - val_acc: 0.5921\n",
      "Epoch 919/1500\n",
      "Epoch 00918: val_loss did not improve\n",
      "2s - loss: 0.0152 - acc: 0.9960 - val_loss: 3.2447 - val_acc: 0.5952\n",
      "Epoch 920/1500\n",
      "Epoch 00919: val_loss did not improve\n",
      "2s - loss: 0.0051 - acc: 0.9992 - val_loss: 3.0549 - val_acc: 0.6254\n",
      "Epoch 921/1500\n",
      "Epoch 00920: val_loss did not improve\n",
      "2s - loss: 0.0040 - acc: 0.9984 - val_loss: 3.1904 - val_acc: 0.5740\n",
      "Epoch 922/1500\n",
      "Epoch 00921: val_loss did not improve\n",
      "2s - loss: 0.0084 - acc: 0.9976 - val_loss: 3.0929 - val_acc: 0.6254\n",
      "Epoch 923/1500\n",
      "Epoch 00922: val_loss did not improve\n",
      "2s - loss: 0.0660 - acc: 0.9861 - val_loss: 3.2039 - val_acc: 0.5952\n",
      "Epoch 924/1500\n",
      "Epoch 00923: val_loss did not improve\n",
      "2s - loss: 0.0193 - acc: 0.9938 - val_loss: 3.1697 - val_acc: 0.6073\n",
      "Epoch 925/1500\n",
      "Epoch 00924: val_loss did not improve\n",
      "2s - loss: 0.0336 - acc: 0.9897 - val_loss: 2.9002 - val_acc: 0.6405\n",
      "Epoch 926/1500\n",
      "Epoch 00925: val_loss did not improve\n",
      "2s - loss: 0.0155 - acc: 0.9945 - val_loss: 3.4444 - val_acc: 0.5921\n",
      "Epoch 927/1500\n",
      "Epoch 00926: val_loss did not improve\n",
      "2s - loss: 0.0096 - acc: 0.9968 - val_loss: 3.2931 - val_acc: 0.6012\n",
      "Epoch 928/1500\n",
      "Epoch 00927: val_loss did not improve\n",
      "2s - loss: 0.0053 - acc: 0.9976 - val_loss: 3.2818 - val_acc: 0.6012\n",
      "Epoch 929/1500\n",
      "Epoch 00928: val_loss did not improve\n",
      "2s - loss: 0.0021 - acc: 0.9992 - val_loss: 3.3961 - val_acc: 0.5831\n",
      "Epoch 930/1500\n",
      "Epoch 00929: val_loss did not improve\n",
      "2s - loss: 0.0193 - acc: 0.9960 - val_loss: 3.3707 - val_acc: 0.5801\n",
      "Epoch 931/1500\n",
      "Epoch 00930: val_loss did not improve\n",
      "2s - loss: 0.0121 - acc: 0.9968 - val_loss: 3.1990 - val_acc: 0.5861\n",
      "Epoch 932/1500\n",
      "Epoch 00931: val_loss did not improve\n",
      "2s - loss: 0.0421 - acc: 0.9930 - val_loss: 3.3010 - val_acc: 0.5891\n",
      "Epoch 933/1500\n",
      "Epoch 00932: val_loss did not improve\n",
      "2s - loss: 0.0029 - acc: 0.9992 - val_loss: 3.5460 - val_acc: 0.5831\n",
      "Epoch 934/1500\n",
      "Epoch 00933: val_loss did not improve\n",
      "2s - loss: 0.0065 - acc: 0.9969 - val_loss: 3.2835 - val_acc: 0.6103\n",
      "Epoch 935/1500\n",
      "Epoch 00934: val_loss did not improve\n",
      "2s - loss: 0.0055 - acc: 0.9968 - val_loss: 3.3321 - val_acc: 0.6133\n",
      "Epoch 936/1500\n",
      "Epoch 00935: val_loss did not improve\n",
      "2s - loss: 0.0040 - acc: 0.9992 - val_loss: 3.2222 - val_acc: 0.5982\n",
      "Epoch 937/1500\n",
      "Epoch 00936: val_loss did not improve\n",
      "2s - loss: 0.0086 - acc: 0.9976 - val_loss: 3.0513 - val_acc: 0.5891\n",
      "Epoch 938/1500\n",
      "Epoch 00937: val_loss did not improve\n",
      "2s - loss: 0.0214 - acc: 0.9928 - val_loss: 3.4338 - val_acc: 0.6042\n",
      "Epoch 939/1500\n",
      "Epoch 00938: val_loss did not improve\n",
      "2s - loss: 0.0053 - acc: 0.9984 - val_loss: 3.3066 - val_acc: 0.6042\n",
      "Epoch 940/1500\n",
      "Epoch 00939: val_loss did not improve\n",
      "2s - loss: 0.0025 - acc: 0.9992 - val_loss: 3.2699 - val_acc: 0.6073\n",
      "Epoch 941/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00940: val_loss did not improve\n",
      "2s - loss: 0.0061 - acc: 0.9976 - val_loss: 3.3893 - val_acc: 0.5891\n",
      "Epoch 942/1500\n",
      "Epoch 00941: val_loss did not improve\n",
      "2s - loss: 0.0169 - acc: 0.9945 - val_loss: 3.2425 - val_acc: 0.6103\n",
      "Epoch 943/1500\n",
      "Epoch 00942: val_loss did not improve\n",
      "2s - loss: 0.0483 - acc: 0.9899 - val_loss: 3.2930 - val_acc: 0.5921\n",
      "Epoch 944/1500\n",
      "Epoch 00943: val_loss did not improve\n",
      "2s - loss: 0.0112 - acc: 0.9929 - val_loss: 3.4320 - val_acc: 0.5740\n",
      "Epoch 945/1500\n",
      "Epoch 00944: val_loss did not improve\n",
      "2s - loss: 0.0171 - acc: 0.9936 - val_loss: 3.3503 - val_acc: 0.6012\n",
      "Epoch 946/1500\n",
      "Epoch 00945: val_loss did not improve\n",
      "2s - loss: 0.0139 - acc: 0.9944 - val_loss: 3.9547 - val_acc: 0.5438\n",
      "Epoch 947/1500\n",
      "Epoch 00946: val_loss did not improve\n",
      "2s - loss: 0.0100 - acc: 0.9968 - val_loss: 3.3695 - val_acc: 0.5982\n",
      "Epoch 948/1500\n",
      "Epoch 00947: val_loss did not improve\n",
      "2s - loss: 0.0043 - acc: 0.9992 - val_loss: 3.1538 - val_acc: 0.6042\n",
      "Epoch 949/1500\n",
      "Epoch 00948: val_loss did not improve\n",
      "2s - loss: 0.0133 - acc: 0.9961 - val_loss: 3.3092 - val_acc: 0.6103\n",
      "Epoch 950/1500\n",
      "Epoch 00949: val_loss did not improve\n",
      "2s - loss: 0.0126 - acc: 0.9937 - val_loss: 3.4659 - val_acc: 0.5952\n",
      "Epoch 951/1500\n",
      "Epoch 00950: val_loss did not improve\n",
      "2s - loss: 0.0028 - acc: 1.0000 - val_loss: 2.8899 - val_acc: 0.6254\n",
      "Epoch 952/1500\n",
      "Epoch 00951: val_loss did not improve\n",
      "2s - loss: 0.0107 - acc: 0.9960 - val_loss: 3.4462 - val_acc: 0.5770\n",
      "Epoch 953/1500\n",
      "Epoch 00952: val_loss did not improve\n",
      "2s - loss: 0.0198 - acc: 0.9945 - val_loss: 3.3198 - val_acc: 0.6073\n",
      "Epoch 954/1500\n",
      "Epoch 00953: val_loss did not improve\n",
      "2s - loss: 0.0462 - acc: 0.9915 - val_loss: 3.3597 - val_acc: 0.6073\n",
      "Epoch 955/1500\n",
      "Epoch 00954: val_loss did not improve\n",
      "2s - loss: 0.0033 - acc: 0.9992 - val_loss: 3.5608 - val_acc: 0.5831\n",
      "Epoch 956/1500\n",
      "Epoch 00955: val_loss did not improve\n",
      "2s - loss: 0.0028 - acc: 0.9984 - val_loss: 2.9607 - val_acc: 0.5982\n",
      "Epoch 957/1500\n",
      "Epoch 00956: val_loss did not improve\n",
      "2s - loss: 0.0059 - acc: 0.9976 - val_loss: 3.3629 - val_acc: 0.5831\n",
      "Epoch 958/1500\n",
      "Epoch 00957: val_loss did not improve\n",
      "2s - loss: 0.0226 - acc: 0.9952 - val_loss: 3.4075 - val_acc: 0.5952\n",
      "Epoch 959/1500\n",
      "Epoch 00958: val_loss did not improve\n",
      "2s - loss: 0.0138 - acc: 0.9953 - val_loss: 3.5041 - val_acc: 0.6073\n",
      "Epoch 960/1500\n",
      "Epoch 00959: val_loss did not improve\n",
      "2s - loss: 0.0154 - acc: 0.9952 - val_loss: 3.1746 - val_acc: 0.6314\n",
      "Epoch 961/1500\n",
      "Epoch 00960: val_loss did not improve\n",
      "2s - loss: 0.0032 - acc: 0.9984 - val_loss: 3.0704 - val_acc: 0.6193\n",
      "Epoch 962/1500\n",
      "Epoch 00961: val_loss did not improve\n",
      "2s - loss: 0.0160 - acc: 0.9953 - val_loss: 3.2331 - val_acc: 0.6073\n",
      "Epoch 963/1500\n",
      "Epoch 00962: val_loss did not improve\n",
      "2s - loss: 0.0147 - acc: 0.9928 - val_loss: 3.4722 - val_acc: 0.5982\n",
      "Epoch 964/1500\n",
      "Epoch 00963: val_loss did not improve\n",
      "2s - loss: 0.0052 - acc: 0.9984 - val_loss: 3.2532 - val_acc: 0.5891\n",
      "Epoch 965/1500\n",
      "Epoch 00964: val_loss did not improve\n",
      "2s - loss: 0.0058 - acc: 0.9992 - val_loss: 3.5739 - val_acc: 0.5982\n",
      "Epoch 966/1500\n",
      "Epoch 00965: val_loss did not improve\n",
      "2s - loss: 0.0043 - acc: 0.9977 - val_loss: 3.2821 - val_acc: 0.5861\n",
      "Epoch 967/1500\n",
      "Epoch 00966: val_loss did not improve\n",
      "2s - loss: 0.0047 - acc: 0.9992 - val_loss: 3.3421 - val_acc: 0.5891\n",
      "Epoch 968/1500\n",
      "Epoch 00967: val_loss did not improve\n",
      "2s - loss: 0.0016 - acc: 1.0000 - val_loss: 2.9957 - val_acc: 0.5770\n",
      "Epoch 969/1500\n",
      "Epoch 00968: val_loss did not improve\n",
      "2s - loss: 0.0041 - acc: 0.9976 - val_loss: 3.3262 - val_acc: 0.5861\n",
      "Epoch 970/1500\n",
      "Epoch 00969: val_loss did not improve\n",
      "2s - loss: 0.0014 - acc: 1.0000 - val_loss: 3.0874 - val_acc: 0.6193\n",
      "Epoch 971/1500\n",
      "Epoch 00970: val_loss did not improve\n",
      "2s - loss: 0.0177 - acc: 0.9969 - val_loss: 3.2658 - val_acc: 0.6012\n",
      "Epoch 972/1500\n",
      "Epoch 00971: val_loss did not improve\n",
      "2s - loss: 0.0117 - acc: 0.9968 - val_loss: 3.1414 - val_acc: 0.5891\n",
      "Epoch 973/1500\n",
      "Epoch 00972: val_loss did not improve\n",
      "2s - loss: 0.0056 - acc: 0.9976 - val_loss: 3.1444 - val_acc: 0.5891\n",
      "Epoch 974/1500\n",
      "Epoch 00973: val_loss did not improve\n",
      "2s - loss: 0.0107 - acc: 0.9968 - val_loss: 3.4201 - val_acc: 0.5770\n",
      "Epoch 975/1500\n",
      "Epoch 00974: val_loss did not improve\n",
      "2s - loss: 0.0366 - acc: 0.9922 - val_loss: 3.3237 - val_acc: 0.6073\n",
      "Epoch 976/1500\n",
      "Epoch 00975: val_loss did not improve\n",
      "2s - loss: 0.0109 - acc: 0.9969 - val_loss: 3.4703 - val_acc: 0.5770\n",
      "Epoch 977/1500\n",
      "Epoch 00976: val_loss did not improve\n",
      "2s - loss: 0.0841 - acc: 0.9853 - val_loss: 3.2893 - val_acc: 0.5680\n",
      "Epoch 978/1500\n",
      "Epoch 00977: val_loss did not improve\n",
      "2s - loss: 0.0039 - acc: 0.9992 - val_loss: 3.1378 - val_acc: 0.6073\n",
      "Epoch 979/1500\n",
      "Epoch 00978: val_loss did not improve\n",
      "2s - loss: 0.0095 - acc: 0.9968 - val_loss: 3.1436 - val_acc: 0.6163\n",
      "Epoch 980/1500\n",
      "Epoch 00979: val_loss did not improve\n",
      "2s - loss: 0.0069 - acc: 0.9976 - val_loss: 3.0206 - val_acc: 0.5982\n",
      "Epoch 981/1500\n",
      "Epoch 00980: val_loss did not improve\n",
      "2s - loss: 0.0045 - acc: 0.9992 - val_loss: 3.3003 - val_acc: 0.6012\n",
      "Epoch 982/1500\n",
      "Epoch 00981: val_loss did not improve\n",
      "2s - loss: 0.0082 - acc: 0.9969 - val_loss: 3.3823 - val_acc: 0.5831\n",
      "Epoch 983/1500\n",
      "Epoch 00982: val_loss did not improve\n",
      "2s - loss: 0.0057 - acc: 0.9976 - val_loss: 3.4930 - val_acc: 0.6012\n",
      "Epoch 984/1500\n",
      "Epoch 00983: val_loss did not improve\n",
      "2s - loss: 0.0046 - acc: 0.9992 - val_loss: 3.3688 - val_acc: 0.6073\n",
      "Epoch 985/1500\n",
      "Epoch 00984: val_loss did not improve\n",
      "2s - loss: 0.0062 - acc: 0.9984 - val_loss: 3.0298 - val_acc: 0.6103\n",
      "Epoch 986/1500\n",
      "Epoch 00985: val_loss did not improve\n",
      "2s - loss: 0.0059 - acc: 0.9984 - val_loss: 3.3567 - val_acc: 0.5680\n",
      "Epoch 987/1500\n",
      "Epoch 00986: val_loss did not improve\n",
      "2s - loss: 0.0060 - acc: 0.9976 - val_loss: 3.2530 - val_acc: 0.6344\n",
      "Epoch 988/1500\n",
      "Epoch 00987: val_loss did not improve\n",
      "2s - loss: 0.0043 - acc: 0.9992 - val_loss: 3.1160 - val_acc: 0.6344\n",
      "Epoch 989/1500\n",
      "Epoch 00988: val_loss did not improve\n",
      "2s - loss: 0.0198 - acc: 0.9969 - val_loss: 3.3440 - val_acc: 0.5770\n",
      "Epoch 990/1500\n",
      "Epoch 00989: val_loss did not improve\n",
      "2s - loss: 0.0035 - acc: 0.9992 - val_loss: 3.3455 - val_acc: 0.6012\n",
      "Epoch 991/1500\n",
      "Epoch 00990: val_loss did not improve\n",
      "2s - loss: 0.0048 - acc: 0.9984 - val_loss: 3.3347 - val_acc: 0.5921\n",
      "Epoch 992/1500\n",
      "Epoch 00991: val_loss did not improve\n",
      "2s - loss: 0.0109 - acc: 0.9969 - val_loss: 3.6666 - val_acc: 0.5680\n",
      "Epoch 993/1500\n",
      "Epoch 00992: val_loss did not improve\n",
      "2s - loss: 0.0119 - acc: 0.9945 - val_loss: 3.0925 - val_acc: 0.5861\n",
      "Epoch 994/1500\n",
      "Epoch 00993: val_loss did not improve\n",
      "2s - loss: 0.0151 - acc: 0.9953 - val_loss: 3.2649 - val_acc: 0.5831\n",
      "Epoch 995/1500\n",
      "Epoch 00994: val_loss did not improve\n",
      "2s - loss: 0.0069 - acc: 0.9968 - val_loss: 3.1628 - val_acc: 0.6405\n",
      "Epoch 996/1500\n",
      "Epoch 00995: val_loss did not improve\n",
      "2s - loss: 0.0140 - acc: 0.9952 - val_loss: 3.4872 - val_acc: 0.6133\n",
      "Epoch 997/1500\n",
      "Epoch 00996: val_loss did not improve\n",
      "2s - loss: 0.0114 - acc: 0.9960 - val_loss: 3.2614 - val_acc: 0.6103\n",
      "Epoch 998/1500\n",
      "Epoch 00997: val_loss did not improve\n",
      "2s - loss: 0.0070 - acc: 0.9976 - val_loss: 3.1914 - val_acc: 0.6042\n",
      "Epoch 999/1500\n",
      "Epoch 00998: val_loss did not improve\n",
      "2s - loss: 0.0097 - acc: 0.9960 - val_loss: 3.5954 - val_acc: 0.5831\n",
      "Epoch 1000/1500\n",
      "Epoch 00999: val_loss did not improve\n",
      "2s - loss: 0.0338 - acc: 0.9922 - val_loss: 3.3516 - val_acc: 0.5921\n",
      "Epoch 1001/1500\n",
      "Epoch 01000: val_loss did not improve\n",
      "2s - loss: 0.0071 - acc: 0.9984 - val_loss: 3.5832 - val_acc: 0.5710\n",
      "Epoch 1002/1500\n",
      "Epoch 01001: val_loss did not improve\n",
      "2s - loss: 0.0101 - acc: 0.9960 - val_loss: 3.5825 - val_acc: 0.5770\n",
      "Epoch 1003/1500\n",
      "Epoch 01002: val_loss did not improve\n",
      "2s - loss: 0.0126 - acc: 0.9968 - val_loss: 3.3869 - val_acc: 0.5619\n",
      "Epoch 1004/1500\n",
      "Epoch 01003: val_loss did not improve\n",
      "2s - loss: 0.0034 - acc: 0.9992 - val_loss: 3.3489 - val_acc: 0.5952\n",
      "Epoch 1005/1500\n",
      "Epoch 01004: val_loss did not improve\n",
      "2s - loss: 0.0062 - acc: 0.9976 - val_loss: 3.1955 - val_acc: 0.6103\n",
      "Epoch 1006/1500\n",
      "Epoch 01005: val_loss did not improve\n",
      "2s - loss: 0.0151 - acc: 0.9938 - val_loss: 3.5752 - val_acc: 0.5529\n",
      "Epoch 1007/1500\n",
      "Epoch 01006: val_loss did not improve\n",
      "2s - loss: 0.0011 - acc: 1.0000 - val_loss: 3.3429 - val_acc: 0.5921\n",
      "Epoch 1008/1500\n",
      "Epoch 01007: val_loss did not improve\n",
      "2s - loss: 0.0065 - acc: 0.9976 - val_loss: 3.3008 - val_acc: 0.5801\n",
      "Epoch 1009/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01008: val_loss did not improve\n",
      "2s - loss: 0.0062 - acc: 0.9984 - val_loss: 3.0050 - val_acc: 0.5952\n",
      "Epoch 1010/1500\n",
      "Epoch 01009: val_loss did not improve\n",
      "2s - loss: 0.0048 - acc: 0.9992 - val_loss: 3.5674 - val_acc: 0.5861\n",
      "Epoch 1011/1500\n",
      "Epoch 01010: val_loss did not improve\n",
      "2s - loss: 0.0017 - acc: 1.0000 - val_loss: 3.2826 - val_acc: 0.5740\n",
      "Epoch 1012/1500\n",
      "Epoch 01011: val_loss did not improve\n",
      "2s - loss: 0.0019 - acc: 1.0000 - val_loss: 3.5337 - val_acc: 0.5770\n",
      "Epoch 1013/1500\n",
      "Epoch 01012: val_loss did not improve\n",
      "2s - loss: 0.0076 - acc: 0.9953 - val_loss: 3.6569 - val_acc: 0.5891\n",
      "Epoch 1014/1500\n",
      "Epoch 01013: val_loss did not improve\n",
      "2s - loss: 0.0126 - acc: 0.9968 - val_loss: 3.4977 - val_acc: 0.5770\n",
      "Epoch 1015/1500\n",
      "Epoch 01014: val_loss did not improve\n",
      "2s - loss: 0.0200 - acc: 0.9953 - val_loss: 2.9731 - val_acc: 0.5921\n",
      "Epoch 1016/1500\n",
      "Epoch 01015: val_loss did not improve\n",
      "2s - loss: 0.0095 - acc: 0.9968 - val_loss: 3.0039 - val_acc: 0.6284\n",
      "Epoch 1017/1500\n",
      "Epoch 01016: val_loss did not improve\n",
      "2s - loss: 0.0023 - acc: 0.9992 - val_loss: 3.1597 - val_acc: 0.6073\n",
      "Epoch 1018/1500\n",
      "Epoch 01017: val_loss did not improve\n",
      "2s - loss: 0.0127 - acc: 0.9969 - val_loss: 2.9735 - val_acc: 0.6314\n",
      "Epoch 1019/1500\n",
      "Epoch 01018: val_loss did not improve\n",
      "2s - loss: 0.0236 - acc: 0.9946 - val_loss: 3.2708 - val_acc: 0.6163\n",
      "Epoch 1020/1500\n",
      "Epoch 01019: val_loss did not improve\n",
      "2s - loss: 0.0087 - acc: 0.9976 - val_loss: 3.7769 - val_acc: 0.5589\n",
      "Epoch 1021/1500\n",
      "Epoch 01020: val_loss did not improve\n",
      "2s - loss: 0.0241 - acc: 0.9969 - val_loss: 3.3792 - val_acc: 0.6042\n",
      "Epoch 1022/1500\n",
      "Epoch 01021: val_loss did not improve\n",
      "2s - loss: 0.0094 - acc: 0.9984 - val_loss: 3.1862 - val_acc: 0.6314\n",
      "Epoch 1023/1500\n",
      "Epoch 01022: val_loss did not improve\n",
      "2s - loss: 0.0011 - acc: 1.0000 - val_loss: 3.4377 - val_acc: 0.5982\n",
      "Epoch 1024/1500\n",
      "Epoch 01023: val_loss did not improve\n",
      "2s - loss: 0.0054 - acc: 0.9968 - val_loss: 3.2479 - val_acc: 0.6193\n",
      "Epoch 1025/1500\n",
      "Epoch 01024: val_loss did not improve\n",
      "2s - loss: 0.0120 - acc: 0.9936 - val_loss: 3.2998 - val_acc: 0.5952\n",
      "Epoch 1026/1500\n",
      "Epoch 01025: val_loss did not improve\n",
      "2s - loss: 0.0112 - acc: 0.9976 - val_loss: 2.9670 - val_acc: 0.6254\n",
      "Epoch 1027/1500\n",
      "Epoch 01026: val_loss did not improve\n",
      "2s - loss: 0.0088 - acc: 0.9984 - val_loss: 3.3094 - val_acc: 0.6042\n",
      "Epoch 1028/1500\n",
      "Epoch 01027: val_loss did not improve\n",
      "2s - loss: 0.0160 - acc: 0.9968 - val_loss: 3.2741 - val_acc: 0.6193\n",
      "Epoch 1029/1500\n",
      "Epoch 01028: val_loss did not improve\n",
      "2s - loss: 0.0061 - acc: 0.9984 - val_loss: 3.0989 - val_acc: 0.6163\n",
      "Epoch 1030/1500\n",
      "Epoch 01029: val_loss did not improve\n",
      "2s - loss: 0.0063 - acc: 0.9976 - val_loss: 3.4100 - val_acc: 0.6133\n",
      "Epoch 1031/1500\n",
      "Epoch 01030: val_loss did not improve\n",
      "2s - loss: 0.0029 - acc: 0.9984 - val_loss: 3.4800 - val_acc: 0.5740\n",
      "Epoch 1032/1500\n",
      "Epoch 01031: val_loss did not improve\n",
      "2s - loss: 0.0029 - acc: 0.9992 - val_loss: 3.3513 - val_acc: 0.5801\n",
      "Epoch 1033/1500\n",
      "Epoch 01032: val_loss did not improve\n",
      "2s - loss: 0.0057 - acc: 0.9984 - val_loss: 3.4971 - val_acc: 0.5740\n",
      "Epoch 1034/1500\n",
      "Epoch 01033: val_loss did not improve\n",
      "2s - loss: 0.0121 - acc: 0.9969 - val_loss: 3.1262 - val_acc: 0.6133\n",
      "Epoch 1035/1500\n",
      "Epoch 01034: val_loss did not improve\n",
      "2s - loss: 0.0016 - acc: 1.0000 - val_loss: 3.4465 - val_acc: 0.5831\n",
      "Epoch 1036/1500\n",
      "Epoch 01035: val_loss did not improve\n",
      "2s - loss: 0.0043 - acc: 0.9984 - val_loss: 3.3049 - val_acc: 0.5982\n",
      "Epoch 1037/1500\n",
      "Epoch 01036: val_loss did not improve\n",
      "2s - loss: 0.0045 - acc: 0.9992 - val_loss: 3.7768 - val_acc: 0.5861\n",
      "Epoch 1038/1500\n",
      "Epoch 01037: val_loss did not improve\n",
      "2s - loss: 0.0275 - acc: 0.9907 - val_loss: 3.5569 - val_acc: 0.5801\n",
      "Epoch 1039/1500\n",
      "Epoch 01038: val_loss did not improve\n",
      "2s - loss: 0.0039 - acc: 0.9984 - val_loss: 3.5319 - val_acc: 0.5952\n",
      "Epoch 1040/1500\n",
      "Epoch 01039: val_loss did not improve\n",
      "2s - loss: 0.0139 - acc: 0.9945 - val_loss: 3.4280 - val_acc: 0.5921\n",
      "Epoch 1041/1500\n",
      "Epoch 01040: val_loss did not improve\n",
      "2s - loss: 0.0037 - acc: 0.9984 - val_loss: 3.3375 - val_acc: 0.5891\n",
      "Epoch 1042/1500\n",
      "Epoch 01041: val_loss did not improve\n",
      "2s - loss: 0.0298 - acc: 0.9937 - val_loss: 3.3291 - val_acc: 0.5861\n",
      "Epoch 1043/1500\n",
      "Epoch 01042: val_loss did not improve\n",
      "2s - loss: 0.0215 - acc: 0.9954 - val_loss: 3.2169 - val_acc: 0.6012\n",
      "Epoch 1044/1500\n",
      "Epoch 01043: val_loss did not improve\n",
      "2s - loss: 0.0022 - acc: 0.9984 - val_loss: 3.2248 - val_acc: 0.6012\n",
      "Epoch 1045/1500\n",
      "Epoch 01044: val_loss did not improve\n",
      "2s - loss: 0.0033 - acc: 0.9984 - val_loss: 3.5396 - val_acc: 0.6163\n",
      "Epoch 1046/1500\n",
      "Epoch 01045: val_loss did not improve\n",
      "2s - loss: 0.0031 - acc: 0.9992 - val_loss: 3.5563 - val_acc: 0.6042\n",
      "Epoch 1047/1500\n",
      "Epoch 01046: val_loss did not improve\n",
      "2s - loss: 0.0102 - acc: 0.9968 - val_loss: 3.3806 - val_acc: 0.5861\n",
      "Epoch 1048/1500\n",
      "Epoch 01047: val_loss did not improve\n",
      "2s - loss: 0.0031 - acc: 0.9992 - val_loss: 3.3548 - val_acc: 0.6133\n",
      "Epoch 1049/1500\n",
      "Epoch 01048: val_loss did not improve\n",
      "2s - loss: 0.0043 - acc: 0.9992 - val_loss: 3.5875 - val_acc: 0.5529\n",
      "Epoch 1050/1500\n",
      "Epoch 01049: val_loss did not improve\n",
      "2s - loss: 0.0180 - acc: 0.9936 - val_loss: 3.2823 - val_acc: 0.6314\n",
      "Epoch 1051/1500\n",
      "Epoch 01050: val_loss did not improve\n",
      "2s - loss: 0.0087 - acc: 0.9968 - val_loss: 3.4313 - val_acc: 0.5740\n",
      "Epoch 1052/1500\n",
      "Epoch 01051: val_loss did not improve\n",
      "2s - loss: 0.0141 - acc: 0.9968 - val_loss: 3.4062 - val_acc: 0.5710\n",
      "Epoch 1053/1500\n",
      "Epoch 01052: val_loss did not improve\n",
      "2s - loss: 0.0044 - acc: 0.9984 - val_loss: 3.4949 - val_acc: 0.5831\n",
      "Epoch 1054/1500\n",
      "Epoch 01053: val_loss did not improve\n",
      "2s - loss: 0.0105 - acc: 0.9953 - val_loss: 3.4792 - val_acc: 0.6254\n",
      "Epoch 1055/1500\n",
      "Epoch 01054: val_loss did not improve\n",
      "2s - loss: 0.0276 - acc: 0.9931 - val_loss: 3.6368 - val_acc: 0.5861\n",
      "Epoch 1056/1500\n",
      "Epoch 01055: val_loss did not improve\n",
      "2s - loss: 0.0043 - acc: 0.9984 - val_loss: 3.4659 - val_acc: 0.6042\n",
      "Epoch 1057/1500\n",
      "Epoch 01056: val_loss did not improve\n",
      "2s - loss: 0.0037 - acc: 1.0000 - val_loss: 3.3248 - val_acc: 0.5952\n",
      "Epoch 1058/1500\n",
      "Epoch 01057: val_loss did not improve\n",
      "2s - loss: 0.0023 - acc: 0.9992 - val_loss: 3.6240 - val_acc: 0.5831\n",
      "Epoch 1059/1500\n",
      "Epoch 01058: val_loss did not improve\n",
      "2s - loss: 0.0090 - acc: 0.9945 - val_loss: 3.6243 - val_acc: 0.5921\n",
      "Epoch 1060/1500\n",
      "Epoch 01059: val_loss did not improve\n",
      "2s - loss: 0.0050 - acc: 0.9984 - val_loss: 3.3580 - val_acc: 0.6073\n",
      "Epoch 1061/1500\n",
      "Epoch 01060: val_loss did not improve\n",
      "2s - loss: 0.0065 - acc: 0.9976 - val_loss: 3.3433 - val_acc: 0.6012\n",
      "Epoch 1062/1500\n",
      "Epoch 01061: val_loss did not improve\n",
      "2s - loss: 0.0074 - acc: 0.9968 - val_loss: 3.3121 - val_acc: 0.6073\n",
      "Epoch 1063/1500\n",
      "Epoch 01062: val_loss did not improve\n",
      "2s - loss: 0.0019 - acc: 1.0000 - val_loss: 3.4480 - val_acc: 0.6073\n",
      "Epoch 1064/1500\n",
      "Epoch 01063: val_loss did not improve\n",
      "2s - loss: 0.0443 - acc: 0.9930 - val_loss: 3.6988 - val_acc: 0.5891\n",
      "Epoch 1065/1500\n",
      "Epoch 01064: val_loss did not improve\n",
      "2s - loss: 0.0035 - acc: 0.9984 - val_loss: 3.4298 - val_acc: 0.5952\n",
      "Epoch 1066/1500\n",
      "Epoch 01065: val_loss did not improve\n",
      "2s - loss: 0.0050 - acc: 0.9984 - val_loss: 3.3102 - val_acc: 0.6042\n",
      "Epoch 1067/1500\n",
      "Epoch 01066: val_loss did not improve\n",
      "2s - loss: 0.0250 - acc: 0.9937 - val_loss: 3.5310 - val_acc: 0.5831\n",
      "Epoch 1068/1500\n",
      "Epoch 01067: val_loss did not improve\n",
      "2s - loss: 0.0073 - acc: 0.9984 - val_loss: 3.3099 - val_acc: 0.5921\n",
      "Epoch 1069/1500\n",
      "Epoch 01068: val_loss did not improve\n",
      "2s - loss: 0.0017 - acc: 1.0000 - val_loss: 3.1875 - val_acc: 0.6163\n",
      "Epoch 1070/1500\n",
      "Epoch 01069: val_loss did not improve\n",
      "2s - loss: 0.0037 - acc: 0.9992 - val_loss: 3.5149 - val_acc: 0.5921\n",
      "Epoch 1071/1500\n",
      "Epoch 01070: val_loss did not improve\n",
      "2s - loss: 0.0037 - acc: 0.9984 - val_loss: 3.4718 - val_acc: 0.6042\n",
      "Epoch 1072/1500\n",
      "Epoch 01071: val_loss did not improve\n",
      "2s - loss: 0.0022 - acc: 0.9992 - val_loss: 3.3264 - val_acc: 0.5921\n",
      "Epoch 1073/1500\n",
      "Epoch 01072: val_loss did not improve\n",
      "2s - loss: 0.0040 - acc: 0.9992 - val_loss: 3.5418 - val_acc: 0.5891\n",
      "Epoch 1074/1500\n",
      "Epoch 01073: val_loss did not improve\n",
      "2s - loss: 0.0166 - acc: 0.9928 - val_loss: 3.1839 - val_acc: 0.6103\n",
      "Epoch 1075/1500\n",
      "Epoch 01074: val_loss did not improve\n",
      "2s - loss: 0.0151 - acc: 0.9953 - val_loss: 3.2605 - val_acc: 0.6133\n",
      "Epoch 1076/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01075: val_loss did not improve\n",
      "2s - loss: 0.0572 - acc: 0.9892 - val_loss: 3.6559 - val_acc: 0.5801\n",
      "Epoch 1077/1500\n",
      "Epoch 01076: val_loss did not improve\n",
      "2s - loss: 0.0072 - acc: 0.9984 - val_loss: 3.6522 - val_acc: 0.5952\n",
      "Epoch 1078/1500\n",
      "Epoch 01077: val_loss did not improve\n",
      "2s - loss: 0.0207 - acc: 0.9960 - val_loss: 3.3818 - val_acc: 0.5982\n",
      "Epoch 1079/1500\n",
      "Epoch 01078: val_loss did not improve\n",
      "2s - loss: 0.0019 - acc: 0.9992 - val_loss: 3.3831 - val_acc: 0.5861\n",
      "Epoch 1080/1500\n",
      "Epoch 01079: val_loss did not improve\n",
      "2s - loss: 0.0032 - acc: 0.9984 - val_loss: 3.3282 - val_acc: 0.6042\n",
      "Epoch 1081/1500\n",
      "Epoch 01080: val_loss did not improve\n",
      "2s - loss: 0.0146 - acc: 0.9953 - val_loss: 3.2171 - val_acc: 0.5831\n",
      "Epoch 1082/1500\n",
      "Epoch 01081: val_loss did not improve\n",
      "2s - loss: 0.0086 - acc: 0.9984 - val_loss: 3.4533 - val_acc: 0.5770\n",
      "Epoch 1083/1500\n",
      "Epoch 01082: val_loss did not improve\n",
      "2s - loss: 0.0316 - acc: 0.9953 - val_loss: 3.4214 - val_acc: 0.5529\n",
      "Epoch 1084/1500\n",
      "Epoch 01083: val_loss did not improve\n",
      "2s - loss: 0.0024 - acc: 1.0000 - val_loss: 3.4101 - val_acc: 0.5619\n",
      "Epoch 1085/1500\n",
      "Epoch 01084: val_loss did not improve\n",
      "2s - loss: 0.0140 - acc: 0.9960 - val_loss: 3.2321 - val_acc: 0.5801\n",
      "Epoch 1086/1500\n",
      "Epoch 01085: val_loss did not improve\n",
      "2s - loss: 0.0052 - acc: 0.9976 - val_loss: 3.1857 - val_acc: 0.5921\n",
      "Epoch 1087/1500\n",
      "Epoch 01086: val_loss did not improve\n",
      "2s - loss: 0.0063 - acc: 0.9984 - val_loss: 3.2192 - val_acc: 0.5982\n",
      "Epoch 1088/1500\n",
      "Epoch 01087: val_loss did not improve\n",
      "2s - loss: 0.0072 - acc: 0.9976 - val_loss: 3.4866 - val_acc: 0.5861\n",
      "Epoch 1089/1500\n",
      "Epoch 01088: val_loss did not improve\n",
      "2s - loss: 0.0028 - acc: 0.9992 - val_loss: 3.5434 - val_acc: 0.6012\n",
      "Epoch 1090/1500\n",
      "Epoch 01089: val_loss did not improve\n",
      "2s - loss: 0.0039 - acc: 0.9992 - val_loss: 3.4254 - val_acc: 0.5891\n",
      "Epoch 1091/1500\n",
      "Epoch 01090: val_loss did not improve\n",
      "2s - loss: 0.0068 - acc: 0.9984 - val_loss: 3.5844 - val_acc: 0.5831\n",
      "Epoch 1092/1500\n",
      "Epoch 01091: val_loss did not improve\n",
      "2s - loss: 0.0018 - acc: 1.0000 - val_loss: 3.5182 - val_acc: 0.5589\n",
      "Epoch 1093/1500\n",
      "Epoch 01092: val_loss did not improve\n",
      "2s - loss: 0.0074 - acc: 0.9946 - val_loss: 3.0095 - val_acc: 0.6042\n",
      "Epoch 1094/1500\n",
      "Epoch 01093: val_loss did not improve\n",
      "2s - loss: 0.0115 - acc: 0.9968 - val_loss: 3.6218 - val_acc: 0.5740\n",
      "Epoch 1095/1500\n",
      "Epoch 01094: val_loss did not improve\n",
      "2s - loss: 0.0027 - acc: 1.0000 - val_loss: 3.4183 - val_acc: 0.5831\n",
      "Epoch 1096/1500\n",
      "Epoch 01095: val_loss did not improve\n",
      "2s - loss: 0.0140 - acc: 0.9937 - val_loss: 3.4520 - val_acc: 0.5619\n",
      "Epoch 1097/1500\n",
      "Epoch 01096: val_loss did not improve\n",
      "2s - loss: 0.0076 - acc: 0.9968 - val_loss: 3.5191 - val_acc: 0.5801\n",
      "Epoch 1098/1500\n",
      "Epoch 01097: val_loss did not improve\n",
      "2s - loss: 0.0080 - acc: 0.9968 - val_loss: 3.5433 - val_acc: 0.5921\n",
      "Epoch 1099/1500\n",
      "Epoch 01098: val_loss did not improve\n",
      "2s - loss: 0.0045 - acc: 0.9976 - val_loss: 3.5952 - val_acc: 0.6012\n",
      "Epoch 1100/1500\n",
      "Epoch 01099: val_loss did not improve\n",
      "2s - loss: 0.0027 - acc: 0.9992 - val_loss: 3.5747 - val_acc: 0.5740\n",
      "Epoch 1101/1500\n",
      "Epoch 01100: val_loss did not improve\n",
      "2s - loss: 0.0060 - acc: 0.9992 - val_loss: 3.4011 - val_acc: 0.5861\n",
      "Epoch 1102/1500\n",
      "Epoch 01101: val_loss did not improve\n",
      "2s - loss: 0.0073 - acc: 0.9961 - val_loss: 3.6752 - val_acc: 0.5770\n",
      "Epoch 1103/1500\n",
      "Epoch 01102: val_loss did not improve\n",
      "2s - loss: 0.0167 - acc: 0.9968 - val_loss: 3.6030 - val_acc: 0.5408\n",
      "Epoch 1104/1500\n",
      "Epoch 01103: val_loss did not improve\n",
      "2s - loss: 0.0076 - acc: 0.9984 - val_loss: 3.3341 - val_acc: 0.5861\n",
      "Epoch 1105/1500\n",
      "Epoch 01104: val_loss did not improve\n",
      "2s - loss: 0.0045 - acc: 0.9984 - val_loss: 3.3584 - val_acc: 0.5952\n",
      "Epoch 1106/1500\n",
      "Epoch 01105: val_loss did not improve\n",
      "2s - loss: 0.0019 - acc: 0.9992 - val_loss: 3.6664 - val_acc: 0.5559\n",
      "Epoch 1107/1500\n",
      "Epoch 01106: val_loss did not improve\n",
      "2s - loss: 0.0026 - acc: 0.9992 - val_loss: 3.2685 - val_acc: 0.6012\n",
      "Epoch 1108/1500\n",
      "Epoch 01107: val_loss did not improve\n",
      "2s - loss: 0.0081 - acc: 0.9952 - val_loss: 3.4354 - val_acc: 0.5891\n",
      "Epoch 1109/1500\n",
      "Epoch 01108: val_loss did not improve\n",
      "2s - loss: 0.0079 - acc: 0.9968 - val_loss: 3.7711 - val_acc: 0.5257\n",
      "Epoch 1110/1500\n",
      "Epoch 01109: val_loss did not improve\n",
      "2s - loss: 0.0137 - acc: 0.9952 - val_loss: 3.1520 - val_acc: 0.6133\n",
      "Epoch 1111/1500\n",
      "Epoch 01110: val_loss did not improve\n",
      "2s - loss: 0.0032 - acc: 0.9992 - val_loss: 3.5017 - val_acc: 0.5650\n",
      "Epoch 1112/1500\n",
      "Epoch 01111: val_loss did not improve\n",
      "2s - loss: 0.0098 - acc: 0.9968 - val_loss: 3.4475 - val_acc: 0.5801\n",
      "Epoch 1113/1500\n",
      "Epoch 01112: val_loss did not improve\n",
      "2s - loss: 0.0054 - acc: 0.9992 - val_loss: 3.5044 - val_acc: 0.5831\n",
      "Epoch 1114/1500\n",
      "Epoch 01113: val_loss did not improve\n",
      "2s - loss: 0.0096 - acc: 0.9968 - val_loss: 3.5149 - val_acc: 0.5801\n",
      "Epoch 1115/1500\n",
      "Epoch 01114: val_loss did not improve\n",
      "2s - loss: 9.3114e-04 - acc: 1.0000 - val_loss: 3.3093 - val_acc: 0.5952\n",
      "Epoch 1116/1500\n",
      "Epoch 01115: val_loss did not improve\n",
      "2s - loss: 0.0069 - acc: 0.9969 - val_loss: 3.2968 - val_acc: 0.6042\n",
      "Epoch 1117/1500\n",
      "Epoch 01116: val_loss did not improve\n",
      "2s - loss: 0.0031 - acc: 0.9992 - val_loss: 3.2311 - val_acc: 0.5982\n",
      "Epoch 1118/1500\n",
      "Epoch 01117: val_loss did not improve\n",
      "2s - loss: 0.0089 - acc: 0.9968 - val_loss: 3.6815 - val_acc: 0.5559\n",
      "Epoch 1119/1500\n",
      "Epoch 01118: val_loss did not improve\n",
      "2s - loss: 0.0047 - acc: 0.9984 - val_loss: 3.1162 - val_acc: 0.6073\n",
      "Epoch 1120/1500\n",
      "Epoch 01119: val_loss did not improve\n",
      "2s - loss: 0.0036 - acc: 0.9992 - val_loss: 3.3214 - val_acc: 0.5952\n",
      "Epoch 1121/1500\n",
      "Epoch 01120: val_loss did not improve\n",
      "2s - loss: 0.0044 - acc: 0.9992 - val_loss: 3.3566 - val_acc: 0.5952\n",
      "Epoch 1122/1500\n",
      "Epoch 01121: val_loss did not improve\n",
      "2s - loss: 0.0018 - acc: 0.9992 - val_loss: 3.5809 - val_acc: 0.5619\n",
      "Epoch 1123/1500\n",
      "Epoch 01122: val_loss did not improve\n",
      "2s - loss: 0.0051 - acc: 0.9984 - val_loss: 3.6385 - val_acc: 0.5740\n",
      "Epoch 1124/1500\n",
      "Epoch 01123: val_loss did not improve\n",
      "2s - loss: 0.0037 - acc: 0.9984 - val_loss: 3.3522 - val_acc: 0.6103\n",
      "Epoch 1125/1500\n",
      "Epoch 01124: val_loss did not improve\n",
      "2s - loss: 0.0033 - acc: 0.9992 - val_loss: 3.5282 - val_acc: 0.5921\n",
      "Epoch 1126/1500\n",
      "Epoch 01125: val_loss did not improve\n",
      "2s - loss: 0.0182 - acc: 0.9969 - val_loss: 3.3275 - val_acc: 0.5921\n",
      "Epoch 1127/1500\n",
      "Epoch 01126: val_loss did not improve\n",
      "2s - loss: 9.4446e-04 - acc: 1.0000 - val_loss: 3.8872 - val_acc: 0.5438\n",
      "Epoch 1128/1500\n",
      "Epoch 01127: val_loss did not improve\n",
      "2s - loss: 0.0084 - acc: 0.9976 - val_loss: 3.2159 - val_acc: 0.6073\n",
      "Epoch 1129/1500\n",
      "Epoch 01128: val_loss did not improve\n",
      "2s - loss: 0.0063 - acc: 0.9976 - val_loss: 3.1628 - val_acc: 0.5770\n",
      "Epoch 1130/1500\n",
      "Epoch 01129: val_loss did not improve\n",
      "2s - loss: 0.0173 - acc: 0.9930 - val_loss: 3.4819 - val_acc: 0.5891\n",
      "Epoch 1131/1500\n",
      "Epoch 01130: val_loss did not improve\n",
      "2s - loss: 0.0098 - acc: 0.9984 - val_loss: 3.4404 - val_acc: 0.5740\n",
      "Epoch 1132/1500\n",
      "Epoch 01131: val_loss did not improve\n",
      "2s - loss: 0.0060 - acc: 0.9984 - val_loss: 3.5326 - val_acc: 0.5801\n",
      "Epoch 1133/1500\n",
      "Epoch 01132: val_loss did not improve\n",
      "2s - loss: 0.0040 - acc: 0.9992 - val_loss: 3.3854 - val_acc: 0.5982\n",
      "Epoch 1134/1500\n",
      "Epoch 01133: val_loss did not improve\n",
      "2s - loss: 0.0142 - acc: 0.9937 - val_loss: 2.9175 - val_acc: 0.6284\n",
      "Epoch 1135/1500\n",
      "Epoch 01134: val_loss did not improve\n",
      "2s - loss: 8.3247e-04 - acc: 1.0000 - val_loss: 3.7739 - val_acc: 0.5468\n",
      "Epoch 1136/1500\n",
      "Epoch 01135: val_loss did not improve\n",
      "2s - loss: 0.0176 - acc: 0.9929 - val_loss: 3.5085 - val_acc: 0.5982\n",
      "Epoch 1137/1500\n",
      "Epoch 01136: val_loss did not improve\n",
      "2s - loss: 0.0095 - acc: 0.9977 - val_loss: 3.4023 - val_acc: 0.5801\n",
      "Epoch 1138/1500\n",
      "Epoch 01137: val_loss did not improve\n",
      "2s - loss: 0.0151 - acc: 0.9969 - val_loss: 3.4193 - val_acc: 0.5801\n",
      "Epoch 1139/1500\n",
      "Epoch 01138: val_loss did not improve\n",
      "2s - loss: 0.0088 - acc: 0.9976 - val_loss: 2.9505 - val_acc: 0.6224\n",
      "Epoch 1140/1500\n",
      "Epoch 01139: val_loss did not improve\n",
      "2s - loss: 0.0124 - acc: 0.9960 - val_loss: 3.1099 - val_acc: 0.5952\n",
      "Epoch 1141/1500\n",
      "Epoch 01140: val_loss did not improve\n",
      "2s - loss: 0.0124 - acc: 0.9946 - val_loss: 3.3921 - val_acc: 0.6042\n",
      "Epoch 1142/1500\n",
      "Epoch 01141: val_loss did not improve\n",
      "2s - loss: 0.0094 - acc: 0.9976 - val_loss: 3.2185 - val_acc: 0.5831\n",
      "Epoch 1143/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01142: val_loss did not improve\n",
      "2s - loss: 0.0098 - acc: 0.9976 - val_loss: 3.2950 - val_acc: 0.5891\n",
      "Epoch 1144/1500\n",
      "Epoch 01143: val_loss did not improve\n",
      "2s - loss: 0.0046 - acc: 0.9984 - val_loss: 3.5438 - val_acc: 0.5861\n",
      "Epoch 1145/1500\n",
      "Epoch 01144: val_loss did not improve\n",
      "2s - loss: 0.0089 - acc: 0.9968 - val_loss: 3.2568 - val_acc: 0.6073\n",
      "Epoch 1146/1500\n",
      "Epoch 01145: val_loss did not improve\n",
      "2s - loss: 0.0016 - acc: 0.9992 - val_loss: 3.1609 - val_acc: 0.6042\n",
      "Epoch 1147/1500\n",
      "Epoch 01146: val_loss did not improve\n",
      "2s - loss: 0.0039 - acc: 0.9977 - val_loss: 3.4330 - val_acc: 0.5952\n",
      "Epoch 1148/1500\n",
      "Epoch 01147: val_loss did not improve\n",
      "2s - loss: 0.0104 - acc: 0.9977 - val_loss: 3.1538 - val_acc: 0.6193\n",
      "Epoch 1149/1500\n",
      "Epoch 01148: val_loss did not improve\n",
      "2s - loss: 0.0258 - acc: 0.9897 - val_loss: 3.4153 - val_acc: 0.6012\n",
      "Epoch 1150/1500\n",
      "Epoch 01149: val_loss did not improve\n",
      "2s - loss: 0.0157 - acc: 0.9937 - val_loss: 3.4004 - val_acc: 0.6042\n",
      "Epoch 1151/1500\n",
      "Epoch 01150: val_loss did not improve\n",
      "2s - loss: 0.0131 - acc: 0.9968 - val_loss: 3.3498 - val_acc: 0.6073\n",
      "Epoch 1152/1500\n",
      "Epoch 01151: val_loss did not improve\n",
      "2s - loss: 0.0015 - acc: 1.0000 - val_loss: 3.4631 - val_acc: 0.5921\n",
      "Epoch 1153/1500\n",
      "Epoch 01152: val_loss did not improve\n",
      "2s - loss: 0.0045 - acc: 0.9984 - val_loss: 3.5097 - val_acc: 0.5801\n",
      "Epoch 1154/1500\n",
      "Epoch 01153: val_loss did not improve\n",
      "2s - loss: 0.0118 - acc: 0.9969 - val_loss: 3.0285 - val_acc: 0.6103\n",
      "Epoch 1155/1500\n",
      "Epoch 01154: val_loss did not improve\n",
      "2s - loss: 0.0014 - acc: 1.0000 - val_loss: 3.3503 - val_acc: 0.5770\n",
      "Epoch 1156/1500\n",
      "Epoch 01155: val_loss did not improve\n",
      "2s - loss: 0.0041 - acc: 0.9976 - val_loss: 3.6490 - val_acc: 0.5589\n",
      "Epoch 1157/1500\n",
      "Epoch 01156: val_loss did not improve\n",
      "2s - loss: 0.0068 - acc: 0.9976 - val_loss: 3.4339 - val_acc: 0.5891\n",
      "Epoch 1158/1500\n",
      "Epoch 01157: val_loss did not improve\n",
      "2s - loss: 0.0079 - acc: 0.9969 - val_loss: 3.2574 - val_acc: 0.5891\n",
      "Epoch 1159/1500\n",
      "Epoch 01158: val_loss did not improve\n",
      "2s - loss: 0.0023 - acc: 0.9992 - val_loss: 3.3713 - val_acc: 0.5831\n",
      "Epoch 1160/1500\n",
      "Epoch 01159: val_loss did not improve\n",
      "2s - loss: 0.0053 - acc: 0.9984 - val_loss: 3.5430 - val_acc: 0.5861\n",
      "Epoch 1161/1500\n",
      "Epoch 01160: val_loss did not improve\n",
      "2s - loss: 0.0030 - acc: 0.9984 - val_loss: 3.3237 - val_acc: 0.6103\n",
      "Epoch 1162/1500\n",
      "Epoch 01161: val_loss did not improve\n",
      "2s - loss: 0.0066 - acc: 0.9976 - val_loss: 3.4353 - val_acc: 0.5861\n",
      "Epoch 1163/1500\n",
      "Epoch 01162: val_loss did not improve\n",
      "2s - loss: 0.0020 - acc: 1.0000 - val_loss: 3.4121 - val_acc: 0.6042\n",
      "Epoch 1164/1500\n",
      "Epoch 01163: val_loss did not improve\n",
      "2s - loss: 0.0060 - acc: 0.9992 - val_loss: 3.2610 - val_acc: 0.5891\n",
      "Epoch 1165/1500\n",
      "Epoch 01164: val_loss did not improve\n",
      "2s - loss: 0.0046 - acc: 0.9984 - val_loss: 3.5476 - val_acc: 0.6133\n",
      "Epoch 1166/1500\n",
      "Epoch 01165: val_loss did not improve\n",
      "2s - loss: 0.0100 - acc: 0.9976 - val_loss: 3.2454 - val_acc: 0.6375\n",
      "Epoch 1167/1500\n",
      "Epoch 01166: val_loss did not improve\n",
      "2s - loss: 0.0029 - acc: 0.9984 - val_loss: 3.3429 - val_acc: 0.5982\n",
      "Epoch 1168/1500\n",
      "Epoch 01167: val_loss did not improve\n",
      "2s - loss: 0.0218 - acc: 0.9922 - val_loss: 3.7807 - val_acc: 0.5770\n",
      "Epoch 1169/1500\n",
      "Epoch 01168: val_loss did not improve\n",
      "2s - loss: 0.0271 - acc: 0.9930 - val_loss: 3.3721 - val_acc: 0.5921\n",
      "Epoch 1170/1500\n",
      "Epoch 01169: val_loss did not improve\n",
      "2s - loss: 0.0118 - acc: 0.9952 - val_loss: 2.9188 - val_acc: 0.6586\n",
      "Epoch 1171/1500\n",
      "Epoch 01170: val_loss did not improve\n",
      "2s - loss: 0.0044 - acc: 0.9976 - val_loss: 3.4815 - val_acc: 0.6042\n",
      "Epoch 1172/1500\n",
      "Epoch 01171: val_loss did not improve\n",
      "2s - loss: 0.0049 - acc: 0.9984 - val_loss: 3.3294 - val_acc: 0.6224\n",
      "Epoch 1173/1500\n",
      "Epoch 01172: val_loss did not improve\n",
      "2s - loss: 0.0077 - acc: 0.9945 - val_loss: 3.5873 - val_acc: 0.5921\n",
      "Epoch 1174/1500\n",
      "Epoch 01173: val_loss did not improve\n",
      "2s - loss: 0.0029 - acc: 0.9992 - val_loss: 3.7389 - val_acc: 0.5438\n",
      "Epoch 1175/1500\n",
      "Epoch 01174: val_loss did not improve\n",
      "2s - loss: 0.0265 - acc: 0.9937 - val_loss: 3.4155 - val_acc: 0.5982\n",
      "Epoch 1176/1500\n",
      "Epoch 01175: val_loss did not improve\n",
      "2s - loss: 0.0048 - acc: 0.9984 - val_loss: 3.4932 - val_acc: 0.6012\n",
      "Epoch 1177/1500\n",
      "Epoch 01176: val_loss did not improve\n",
      "2s - loss: 0.0176 - acc: 0.9954 - val_loss: 3.5727 - val_acc: 0.5982\n",
      "Epoch 1178/1500\n",
      "Epoch 01177: val_loss did not improve\n",
      "2s - loss: 0.0048 - acc: 0.9984 - val_loss: 3.5682 - val_acc: 0.5710\n",
      "Epoch 1179/1500\n",
      "Epoch 01178: val_loss did not improve\n",
      "2s - loss: 0.0025 - acc: 0.9992 - val_loss: 3.5165 - val_acc: 0.5740\n",
      "Epoch 1180/1500\n",
      "Epoch 01179: val_loss did not improve\n",
      "2s - loss: 0.0035 - acc: 0.9976 - val_loss: 3.1808 - val_acc: 0.6163\n",
      "Epoch 1181/1500\n",
      "Epoch 01180: val_loss did not improve\n",
      "2s - loss: 0.0061 - acc: 0.9976 - val_loss: 3.3995 - val_acc: 0.5861\n",
      "Epoch 1182/1500\n",
      "Epoch 01181: val_loss did not improve\n",
      "2s - loss: 0.0193 - acc: 0.9936 - val_loss: 3.1346 - val_acc: 0.5982\n",
      "Epoch 1183/1500\n",
      "Epoch 01182: val_loss did not improve\n",
      "2s - loss: 0.0050 - acc: 0.9976 - val_loss: 3.4483 - val_acc: 0.5801\n",
      "Epoch 1184/1500\n",
      "Epoch 01183: val_loss did not improve\n",
      "2s - loss: 0.0025 - acc: 0.9984 - val_loss: 3.2801 - val_acc: 0.6163\n",
      "Epoch 1185/1500\n",
      "Epoch 01184: val_loss did not improve\n",
      "2s - loss: 0.0059 - acc: 0.9968 - val_loss: 3.4175 - val_acc: 0.5801\n",
      "Epoch 1186/1500\n",
      "Epoch 01185: val_loss did not improve\n",
      "2s - loss: 0.0215 - acc: 0.9945 - val_loss: 3.3787 - val_acc: 0.5770\n",
      "Epoch 1187/1500\n",
      "Epoch 01186: val_loss did not improve\n",
      "2s - loss: 0.0029 - acc: 0.9977 - val_loss: 3.6466 - val_acc: 0.5831\n",
      "Epoch 1188/1500\n",
      "Epoch 01187: val_loss did not improve\n",
      "2s - loss: 0.0025 - acc: 0.9984 - val_loss: 3.3578 - val_acc: 0.5921\n",
      "Epoch 1189/1500\n",
      "Epoch 01188: val_loss did not improve\n",
      "2s - loss: 0.0058 - acc: 0.9968 - val_loss: 3.2370 - val_acc: 0.5982\n",
      "Epoch 1190/1500\n",
      "Epoch 01189: val_loss did not improve\n",
      "2s - loss: 0.0110 - acc: 0.9976 - val_loss: 3.2811 - val_acc: 0.6163\n",
      "Epoch 1191/1500\n",
      "Epoch 01190: val_loss did not improve\n",
      "2s - loss: 0.0061 - acc: 0.9984 - val_loss: 3.2938 - val_acc: 0.6224\n",
      "Epoch 1192/1500\n",
      "Epoch 01191: val_loss did not improve\n",
      "2s - loss: 0.0019 - acc: 1.0000 - val_loss: 3.6617 - val_acc: 0.5559\n",
      "Epoch 1193/1500\n",
      "Epoch 01192: val_loss did not improve\n",
      "2s - loss: 0.0100 - acc: 0.9968 - val_loss: 3.6502 - val_acc: 0.5740\n",
      "Epoch 1194/1500\n",
      "Epoch 01193: val_loss did not improve\n",
      "2s - loss: 0.0293 - acc: 0.9915 - val_loss: 3.5878 - val_acc: 0.5770\n",
      "Epoch 1195/1500\n",
      "Epoch 01194: val_loss did not improve\n",
      "2s - loss: 0.0020 - acc: 0.9992 - val_loss: 3.6672 - val_acc: 0.5861\n",
      "Epoch 1196/1500\n",
      "Epoch 01195: val_loss did not improve\n",
      "2s - loss: 0.0334 - acc: 0.9899 - val_loss: 3.5930 - val_acc: 0.5891\n",
      "Epoch 1197/1500\n",
      "Epoch 01196: val_loss did not improve\n",
      "2s - loss: 0.0040 - acc: 0.9976 - val_loss: 3.3733 - val_acc: 0.5982\n",
      "Epoch 1198/1500\n",
      "Epoch 01197: val_loss did not improve\n",
      "2s - loss: 0.0034 - acc: 0.9992 - val_loss: 3.4828 - val_acc: 0.5921\n",
      "Epoch 1199/1500\n",
      "Epoch 01198: val_loss did not improve\n",
      "2s - loss: 0.0124 - acc: 0.9960 - val_loss: 3.3737 - val_acc: 0.6012\n",
      "Epoch 1200/1500\n",
      "Epoch 01199: val_loss did not improve\n",
      "2s - loss: 0.0024 - acc: 0.9992 - val_loss: 3.5997 - val_acc: 0.5529\n",
      "Epoch 1201/1500\n",
      "Epoch 01200: val_loss did not improve\n",
      "2s - loss: 0.0023 - acc: 0.9992 - val_loss: 3.2632 - val_acc: 0.5891\n",
      "Epoch 1202/1500\n",
      "Epoch 01201: val_loss did not improve\n",
      "2s - loss: 0.0049 - acc: 0.9992 - val_loss: 3.2963 - val_acc: 0.5952\n",
      "Epoch 1203/1500\n",
      "Epoch 01202: val_loss did not improve\n",
      "2s - loss: 0.0069 - acc: 0.9984 - val_loss: 3.3391 - val_acc: 0.5891\n",
      "Epoch 1204/1500\n",
      "Epoch 01203: val_loss did not improve\n",
      "2s - loss: 0.0021 - acc: 0.9992 - val_loss: 3.3332 - val_acc: 0.5801\n",
      "Epoch 1205/1500\n",
      "Epoch 01204: val_loss did not improve\n",
      "2s - loss: 0.0120 - acc: 0.9944 - val_loss: 3.1386 - val_acc: 0.6193\n",
      "Epoch 1206/1500\n",
      "Epoch 01205: val_loss did not improve\n",
      "2s - loss: 0.0083 - acc: 0.9969 - val_loss: 4.1289 - val_acc: 0.5227\n",
      "Epoch 1207/1500\n",
      "Epoch 01206: val_loss did not improve\n",
      "2s - loss: 0.0160 - acc: 0.9960 - val_loss: 3.6888 - val_acc: 0.5831\n",
      "Epoch 1208/1500\n",
      "Epoch 01207: val_loss did not improve\n",
      "2s - loss: 0.0104 - acc: 0.9968 - val_loss: 3.3498 - val_acc: 0.5952\n",
      "Epoch 1209/1500\n",
      "Epoch 01208: val_loss did not improve\n",
      "2s - loss: 0.0100 - acc: 0.9953 - val_loss: 3.3439 - val_acc: 0.5831\n",
      "Epoch 1210/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01209: val_loss did not improve\n",
      "2s - loss: 0.0105 - acc: 0.9968 - val_loss: 3.7079 - val_acc: 0.5982\n",
      "Epoch 1211/1500\n",
      "Epoch 01210: val_loss did not improve\n",
      "2s - loss: 0.0039 - acc: 0.9992 - val_loss: 3.6372 - val_acc: 0.5952\n",
      "Epoch 1212/1500\n",
      "Epoch 01211: val_loss did not improve\n",
      "2s - loss: 0.0088 - acc: 0.9945 - val_loss: 3.7286 - val_acc: 0.5650\n",
      "Epoch 1213/1500\n",
      "Epoch 01212: val_loss did not improve\n",
      "2s - loss: 0.0112 - acc: 0.9968 - val_loss: 3.3462 - val_acc: 0.6193\n",
      "Epoch 1214/1500\n",
      "Epoch 01213: val_loss did not improve\n",
      "2s - loss: 0.0081 - acc: 0.9976 - val_loss: 2.9164 - val_acc: 0.6526\n",
      "Epoch 1215/1500\n",
      "Epoch 01214: val_loss did not improve\n",
      "2s - loss: 0.0072 - acc: 0.9976 - val_loss: 3.4054 - val_acc: 0.5921\n",
      "Epoch 1216/1500\n",
      "Epoch 01215: val_loss did not improve\n",
      "2s - loss: 0.0101 - acc: 0.9961 - val_loss: 3.6609 - val_acc: 0.5861\n",
      "Epoch 1217/1500\n",
      "Epoch 01216: val_loss did not improve\n",
      "2s - loss: 0.0013 - acc: 1.0000 - val_loss: 3.3083 - val_acc: 0.6163\n",
      "Epoch 1218/1500\n",
      "Epoch 01217: val_loss did not improve\n",
      "2s - loss: 0.0279 - acc: 0.9914 - val_loss: 3.2002 - val_acc: 0.6133\n",
      "Epoch 1219/1500\n",
      "Epoch 01218: val_loss did not improve\n",
      "2s - loss: 5.1408e-04 - acc: 1.0000 - val_loss: 3.2139 - val_acc: 0.6254\n",
      "Epoch 1220/1500\n",
      "Epoch 01219: val_loss did not improve\n",
      "2s - loss: 0.0073 - acc: 0.9968 - val_loss: 3.8291 - val_acc: 0.5710\n",
      "Epoch 1221/1500\n",
      "Epoch 01220: val_loss did not improve\n",
      "2s - loss: 0.0042 - acc: 0.9984 - val_loss: 3.5795 - val_acc: 0.5710\n",
      "Epoch 1222/1500\n",
      "Epoch 01221: val_loss did not improve\n",
      "2s - loss: 0.0112 - acc: 0.9960 - val_loss: 3.4812 - val_acc: 0.6012\n",
      "Epoch 1223/1500\n",
      "Epoch 01222: val_loss did not improve\n",
      "2s - loss: 0.0041 - acc: 0.9992 - val_loss: 3.5241 - val_acc: 0.6375\n",
      "Epoch 1224/1500\n",
      "Epoch 01223: val_loss did not improve\n",
      "2s - loss: 0.0035 - acc: 0.9992 - val_loss: 3.2907 - val_acc: 0.5801\n",
      "Epoch 1225/1500\n",
      "Epoch 01224: val_loss did not improve\n",
      "2s - loss: 0.0026 - acc: 0.9992 - val_loss: 3.3560 - val_acc: 0.5952\n",
      "Epoch 1226/1500\n",
      "Epoch 01225: val_loss did not improve\n",
      "2s - loss: 0.0014 - acc: 1.0000 - val_loss: 3.2868 - val_acc: 0.5952\n",
      "Epoch 1227/1500\n",
      "Epoch 01226: val_loss did not improve\n",
      "2s - loss: 0.0134 - acc: 0.9976 - val_loss: 3.5211 - val_acc: 0.5952\n",
      "Epoch 1228/1500\n",
      "Epoch 01227: val_loss did not improve\n",
      "2s - loss: 0.0173 - acc: 0.9937 - val_loss: 3.4549 - val_acc: 0.6163\n",
      "Epoch 1229/1500\n",
      "Epoch 01228: val_loss did not improve\n",
      "2s - loss: 0.0040 - acc: 0.9984 - val_loss: 3.3587 - val_acc: 0.6314\n",
      "Epoch 1230/1500\n",
      "Epoch 01229: val_loss did not improve\n",
      "2s - loss: 0.0146 - acc: 0.9960 - val_loss: 3.5252 - val_acc: 0.5952\n",
      "Epoch 1231/1500\n",
      "Epoch 01230: val_loss did not improve\n",
      "2s - loss: 0.0029 - acc: 0.9992 - val_loss: 3.3101 - val_acc: 0.6526\n",
      "Epoch 1232/1500\n",
      "Epoch 01231: val_loss did not improve\n",
      "2s - loss: 0.0032 - acc: 0.9992 - val_loss: 3.5126 - val_acc: 0.6193\n",
      "Epoch 1233/1500\n",
      "Epoch 01232: val_loss did not improve\n",
      "2s - loss: 0.0115 - acc: 0.9929 - val_loss: 3.7304 - val_acc: 0.6163\n",
      "Epoch 1234/1500\n",
      "Epoch 01233: val_loss did not improve\n",
      "2s - loss: 0.0036 - acc: 0.9984 - val_loss: 3.3625 - val_acc: 0.6073\n",
      "Epoch 1235/1500\n",
      "Epoch 01234: val_loss did not improve\n",
      "2s - loss: 0.0018 - acc: 0.9992 - val_loss: 3.4210 - val_acc: 0.6224\n",
      "Epoch 1236/1500\n",
      "Epoch 01235: val_loss did not improve\n",
      "2s - loss: 0.0067 - acc: 0.9984 - val_loss: 3.6614 - val_acc: 0.5891\n",
      "Epoch 1237/1500\n",
      "Epoch 01236: val_loss did not improve\n",
      "2s - loss: 0.0569 - acc: 0.9938 - val_loss: 3.6103 - val_acc: 0.5921\n",
      "Epoch 1238/1500\n",
      "Epoch 01237: val_loss did not improve\n",
      "2s - loss: 0.0036 - acc: 0.9976 - val_loss: 3.7030 - val_acc: 0.5921\n",
      "Epoch 1239/1500\n",
      "Epoch 01238: val_loss did not improve\n",
      "2s - loss: 0.0094 - acc: 0.9976 - val_loss: 3.1602 - val_acc: 0.6133\n",
      "Epoch 1240/1500\n",
      "Epoch 01239: val_loss did not improve\n",
      "2s - loss: 0.0059 - acc: 0.9984 - val_loss: 3.6228 - val_acc: 0.5982\n",
      "Epoch 1241/1500\n",
      "Epoch 01240: val_loss did not improve\n",
      "2s - loss: 0.0193 - acc: 0.9968 - val_loss: 3.3506 - val_acc: 0.6012\n",
      "Epoch 1242/1500\n",
      "Epoch 01241: val_loss did not improve\n",
      "2s - loss: 0.0037 - acc: 0.9976 - val_loss: 3.3969 - val_acc: 0.6042\n",
      "Epoch 1243/1500\n",
      "Epoch 01242: val_loss did not improve\n",
      "2s - loss: 0.0075 - acc: 0.9976 - val_loss: 3.6866 - val_acc: 0.5770\n",
      "Epoch 1244/1500\n",
      "Epoch 01243: val_loss did not improve\n",
      "2s - loss: 0.0057 - acc: 0.9976 - val_loss: 3.5236 - val_acc: 0.6012\n",
      "Epoch 1245/1500\n",
      "Epoch 01244: val_loss did not improve\n",
      "2s - loss: 0.0040 - acc: 0.9969 - val_loss: 3.4866 - val_acc: 0.6163\n",
      "Epoch 1246/1500\n",
      "Epoch 01245: val_loss did not improve\n",
      "2s - loss: 0.0609 - acc: 0.9884 - val_loss: 3.3615 - val_acc: 0.5952\n",
      "Epoch 1247/1500\n",
      "Epoch 01246: val_loss did not improve\n",
      "2s - loss: 0.0060 - acc: 0.9984 - val_loss: 3.5493 - val_acc: 0.5921\n",
      "Epoch 1248/1500\n",
      "Epoch 01247: val_loss did not improve\n",
      "2s - loss: 0.0243 - acc: 0.9954 - val_loss: 3.4969 - val_acc: 0.5861\n",
      "Epoch 1249/1500\n",
      "Epoch 01248: val_loss did not improve\n",
      "2s - loss: 0.0018 - acc: 0.9992 - val_loss: 3.7771 - val_acc: 0.5740\n",
      "Epoch 1250/1500\n",
      "Epoch 01249: val_loss did not improve\n",
      "2s - loss: 0.0076 - acc: 0.9961 - val_loss: 3.6604 - val_acc: 0.5801\n",
      "Epoch 1251/1500\n",
      "Epoch 01250: val_loss did not improve\n",
      "2s - loss: 0.0165 - acc: 0.9977 - val_loss: 3.4611 - val_acc: 0.5891\n",
      "Epoch 1252/1500\n",
      "Epoch 01251: val_loss did not improve\n",
      "2s - loss: 0.0089 - acc: 0.9984 - val_loss: 3.8069 - val_acc: 0.6012\n",
      "Epoch 1253/1500\n",
      "Epoch 01252: val_loss did not improve\n",
      "2s - loss: 0.0060 - acc: 0.9969 - val_loss: 3.7308 - val_acc: 0.5680\n",
      "Epoch 1254/1500\n",
      "Epoch 01253: val_loss did not improve\n",
      "2s - loss: 0.0061 - acc: 0.9976 - val_loss: 3.2792 - val_acc: 0.6314\n",
      "Epoch 1255/1500\n",
      "Epoch 01254: val_loss did not improve\n",
      "2s - loss: 0.0369 - acc: 0.9923 - val_loss: 3.4913 - val_acc: 0.5891\n",
      "Epoch 1256/1500\n",
      "Epoch 01255: val_loss did not improve\n",
      "2s - loss: 0.0130 - acc: 0.9954 - val_loss: 3.4812 - val_acc: 0.5952\n",
      "Epoch 1257/1500\n",
      "Epoch 01256: val_loss did not improve\n",
      "2s - loss: 6.5506e-04 - acc: 1.0000 - val_loss: 3.8252 - val_acc: 0.5801\n",
      "Epoch 1258/1500\n",
      "Epoch 01257: val_loss did not improve\n",
      "2s - loss: 0.0081 - acc: 0.9984 - val_loss: 3.6635 - val_acc: 0.5801\n",
      "Epoch 1259/1500\n",
      "Epoch 01258: val_loss did not improve\n",
      "2s - loss: 0.0066 - acc: 0.9976 - val_loss: 3.3374 - val_acc: 0.5921\n",
      "Epoch 1260/1500\n",
      "Epoch 01259: val_loss did not improve\n",
      "2s - loss: 0.0067 - acc: 0.9984 - val_loss: 3.6640 - val_acc: 0.5952\n",
      "Epoch 1261/1500\n",
      "Epoch 01260: val_loss did not improve\n",
      "2s - loss: 0.0041 - acc: 0.9976 - val_loss: 3.9303 - val_acc: 0.5831\n",
      "Epoch 1262/1500\n",
      "Epoch 01261: val_loss did not improve\n",
      "2s - loss: 0.0034 - acc: 0.9984 - val_loss: 3.5568 - val_acc: 0.6012\n",
      "Epoch 1263/1500\n",
      "Epoch 01262: val_loss did not improve\n",
      "2s - loss: 0.0017 - acc: 1.0000 - val_loss: 3.4967 - val_acc: 0.6224\n",
      "Epoch 1264/1500\n",
      "Epoch 01263: val_loss did not improve\n",
      "2s - loss: 0.0049 - acc: 0.9992 - val_loss: 3.2838 - val_acc: 0.6163\n",
      "Epoch 1265/1500\n",
      "Epoch 01264: val_loss did not improve\n",
      "2s - loss: 0.0032 - acc: 0.9992 - val_loss: 3.4794 - val_acc: 0.6314\n",
      "Epoch 1266/1500\n",
      "Epoch 01265: val_loss did not improve\n",
      "2s - loss: 0.0059 - acc: 0.9968 - val_loss: 3.6117 - val_acc: 0.5801\n",
      "Epoch 1267/1500\n",
      "Epoch 01266: val_loss did not improve\n",
      "2s - loss: 0.0182 - acc: 0.9969 - val_loss: 3.5166 - val_acc: 0.5891\n",
      "Epoch 1268/1500\n",
      "Epoch 01267: val_loss did not improve\n",
      "2s - loss: 0.0106 - acc: 0.9945 - val_loss: 3.6730 - val_acc: 0.5710\n",
      "Epoch 1269/1500\n",
      "Epoch 01268: val_loss did not improve\n",
      "2s - loss: 0.0069 - acc: 0.9960 - val_loss: 3.5643 - val_acc: 0.5891\n",
      "Epoch 1270/1500\n",
      "Epoch 01269: val_loss did not improve\n",
      "2s - loss: 0.0073 - acc: 0.9968 - val_loss: 3.1782 - val_acc: 0.6042\n",
      "Epoch 1271/1500\n",
      "Epoch 01270: val_loss did not improve\n",
      "2s - loss: 0.0055 - acc: 0.9984 - val_loss: 3.7254 - val_acc: 0.5891\n",
      "Epoch 1272/1500\n",
      "Epoch 01271: val_loss did not improve\n",
      "2s - loss: 0.0077 - acc: 0.9976 - val_loss: 3.5028 - val_acc: 0.6103\n",
      "Epoch 1273/1500\n",
      "Epoch 01272: val_loss did not improve\n",
      "2s - loss: 0.0015 - acc: 1.0000 - val_loss: 3.6496 - val_acc: 0.6193\n",
      "Epoch 1274/1500\n",
      "Epoch 01273: val_loss did not improve\n",
      "2s - loss: 0.0115 - acc: 0.9969 - val_loss: 3.5437 - val_acc: 0.6042\n",
      "Epoch 1275/1500\n",
      "Epoch 01274: val_loss did not improve\n",
      "2s - loss: 0.0077 - acc: 0.9969 - val_loss: 3.4474 - val_acc: 0.6344\n",
      "Epoch 1276/1500\n",
      "Epoch 01275: val_loss did not improve\n",
      "2s - loss: 0.0087 - acc: 0.9984 - val_loss: 3.5413 - val_acc: 0.5770\n",
      "Epoch 1277/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01276: val_loss did not improve\n",
      "2s - loss: 0.0031 - acc: 1.0000 - val_loss: 3.6259 - val_acc: 0.5921\n",
      "Epoch 1278/1500\n",
      "Epoch 01277: val_loss did not improve\n",
      "2s - loss: 0.0021 - acc: 0.9992 - val_loss: 3.5377 - val_acc: 0.6314\n",
      "Epoch 1279/1500\n",
      "Epoch 01278: val_loss did not improve\n",
      "2s - loss: 0.0016 - acc: 0.9992 - val_loss: 3.5884 - val_acc: 0.6103\n",
      "Epoch 1280/1500\n",
      "Epoch 01279: val_loss did not improve\n",
      "2s - loss: 0.0030 - acc: 0.9992 - val_loss: 3.4017 - val_acc: 0.6073\n",
      "Epoch 1281/1500\n",
      "Epoch 01280: val_loss did not improve\n",
      "2s - loss: 0.0034 - acc: 0.9992 - val_loss: 3.7205 - val_acc: 0.5710\n",
      "Epoch 1282/1500\n",
      "Epoch 01281: val_loss did not improve\n",
      "2s - loss: 0.0154 - acc: 0.9952 - val_loss: 3.7045 - val_acc: 0.6073\n",
      "Epoch 1283/1500\n",
      "Epoch 01282: val_loss did not improve\n",
      "2s - loss: 0.0266 - acc: 0.9969 - val_loss: 3.7267 - val_acc: 0.5710\n",
      "Epoch 1284/1500\n",
      "Epoch 01283: val_loss did not improve\n",
      "2s - loss: 0.0116 - acc: 0.9976 - val_loss: 3.6676 - val_acc: 0.5982\n",
      "Epoch 1285/1500\n",
      "Epoch 01284: val_loss did not improve\n",
      "2s - loss: 0.0064 - acc: 0.9984 - val_loss: 3.7531 - val_acc: 0.5801\n",
      "Epoch 1286/1500\n",
      "Epoch 01285: val_loss did not improve\n",
      "2s - loss: 0.0032 - acc: 0.9984 - val_loss: 3.7863 - val_acc: 0.5831\n",
      "Epoch 1287/1500\n",
      "Epoch 01286: val_loss did not improve\n",
      "2s - loss: 0.0073 - acc: 0.9961 - val_loss: 3.8319 - val_acc: 0.6042\n",
      "Epoch 1288/1500\n",
      "Epoch 01287: val_loss did not improve\n",
      "2s - loss: 0.0088 - acc: 0.9976 - val_loss: 3.5661 - val_acc: 0.5770\n",
      "Epoch 1289/1500\n",
      "Epoch 01288: val_loss did not improve\n",
      "2s - loss: 6.5183e-04 - acc: 1.0000 - val_loss: 3.2689 - val_acc: 0.6103\n",
      "Epoch 1290/1500\n",
      "Epoch 01289: val_loss did not improve\n",
      "2s - loss: 0.0154 - acc: 0.9960 - val_loss: 3.9154 - val_acc: 0.5921\n",
      "Epoch 1291/1500\n",
      "Epoch 01290: val_loss did not improve\n",
      "2s - loss: 0.0059 - acc: 0.9984 - val_loss: 3.6000 - val_acc: 0.6012\n",
      "Epoch 1292/1500\n",
      "Epoch 01291: val_loss did not improve\n",
      "2s - loss: 0.0015 - acc: 0.9992 - val_loss: 3.6299 - val_acc: 0.5952\n",
      "Epoch 1293/1500\n",
      "Epoch 01292: val_loss did not improve\n",
      "2s - loss: 0.0025 - acc: 1.0000 - val_loss: 3.5890 - val_acc: 0.6012\n",
      "Epoch 1294/1500\n",
      "Epoch 01293: val_loss did not improve\n",
      "2s - loss: 0.0056 - acc: 0.9976 - val_loss: 3.5049 - val_acc: 0.6163\n",
      "Epoch 1295/1500\n",
      "Epoch 01294: val_loss did not improve\n",
      "2s - loss: 0.0042 - acc: 0.9984 - val_loss: 3.5442 - val_acc: 0.6193\n",
      "Epoch 1296/1500\n",
      "Epoch 01295: val_loss did not improve\n",
      "2s - loss: 0.0068 - acc: 0.9984 - val_loss: 3.2455 - val_acc: 0.6133\n",
      "Epoch 1297/1500\n",
      "Epoch 01296: val_loss did not improve\n",
      "2s - loss: 0.0198 - acc: 0.9968 - val_loss: 3.4903 - val_acc: 0.6193\n",
      "Epoch 1298/1500\n",
      "Epoch 01297: val_loss did not improve\n",
      "2s - loss: 7.0330e-04 - acc: 1.0000 - val_loss: 3.4405 - val_acc: 0.6163\n",
      "Epoch 1299/1500\n",
      "Epoch 01298: val_loss did not improve\n",
      "2s - loss: 0.0367 - acc: 0.9915 - val_loss: 3.0659 - val_acc: 0.6133\n",
      "Epoch 1300/1500\n",
      "Epoch 01299: val_loss did not improve\n",
      "2s - loss: 0.0208 - acc: 0.9923 - val_loss: 3.5482 - val_acc: 0.5831\n",
      "Epoch 1301/1500\n",
      "Epoch 01300: val_loss did not improve\n",
      "2s - loss: 0.0062 - acc: 0.9984 - val_loss: 3.3589 - val_acc: 0.5861\n",
      "Epoch 1302/1500\n",
      "Epoch 01301: val_loss did not improve\n",
      "2s - loss: 0.0048 - acc: 0.9976 - val_loss: 3.4113 - val_acc: 0.6224\n",
      "Epoch 1303/1500\n",
      "Epoch 01302: val_loss did not improve\n",
      "2s - loss: 0.0053 - acc: 0.9969 - val_loss: 3.6479 - val_acc: 0.5770\n",
      "Epoch 1304/1500\n",
      "Epoch 01303: val_loss did not improve\n",
      "2s - loss: 0.0078 - acc: 0.9968 - val_loss: 3.2875 - val_acc: 0.6193\n",
      "Epoch 1305/1500\n",
      "Epoch 01304: val_loss did not improve\n",
      "2s - loss: 0.0010 - acc: 0.9992 - val_loss: 3.6581 - val_acc: 0.5770\n",
      "Epoch 1306/1500\n",
      "Epoch 01305: val_loss did not improve\n",
      "2s - loss: 0.0073 - acc: 0.9984 - val_loss: 3.7279 - val_acc: 0.5801\n",
      "Epoch 1307/1500\n",
      "Epoch 01306: val_loss did not improve\n",
      "2s - loss: 0.0025 - acc: 0.9984 - val_loss: 3.6363 - val_acc: 0.5891\n",
      "Epoch 1308/1500\n",
      "Epoch 01307: val_loss did not improve\n",
      "2s - loss: 0.0059 - acc: 0.9968 - val_loss: 3.6049 - val_acc: 0.5952\n",
      "Epoch 1309/1500\n",
      "Epoch 01308: val_loss did not improve\n",
      "2s - loss: 0.0187 - acc: 0.9922 - val_loss: 3.4572 - val_acc: 0.6012\n",
      "Epoch 1310/1500\n",
      "Epoch 01309: val_loss did not improve\n",
      "2s - loss: 0.0045 - acc: 0.9976 - val_loss: 3.4274 - val_acc: 0.6103\n",
      "Epoch 1311/1500\n",
      "Epoch 01310: val_loss did not improve\n",
      "2s - loss: 0.0036 - acc: 0.9984 - val_loss: 3.5012 - val_acc: 0.5861\n",
      "Epoch 1312/1500\n",
      "Epoch 01311: val_loss did not improve\n",
      "2s - loss: 0.0056 - acc: 0.9984 - val_loss: 3.4246 - val_acc: 0.6073\n",
      "Epoch 1313/1500\n",
      "Epoch 01312: val_loss did not improve\n",
      "2s - loss: 0.0287 - acc: 0.9937 - val_loss: 3.6539 - val_acc: 0.5589\n",
      "Epoch 1314/1500\n",
      "Epoch 01313: val_loss did not improve\n",
      "2s - loss: 0.0024 - acc: 0.9984 - val_loss: 3.4519 - val_acc: 0.5740\n",
      "Epoch 1315/1500\n",
      "Epoch 01314: val_loss did not improve\n",
      "2s - loss: 0.0191 - acc: 0.9953 - val_loss: 3.9909 - val_acc: 0.5106\n",
      "Epoch 1316/1500\n",
      "Epoch 01315: val_loss did not improve\n",
      "2s - loss: 0.0013 - acc: 1.0000 - val_loss: 3.4834 - val_acc: 0.5831\n",
      "Epoch 1317/1500\n",
      "Epoch 01316: val_loss did not improve\n",
      "2s - loss: 0.0113 - acc: 0.9992 - val_loss: 3.8148 - val_acc: 0.5468\n",
      "Epoch 1318/1500\n",
      "Epoch 01317: val_loss did not improve\n",
      "2s - loss: 0.0072 - acc: 0.9976 - val_loss: 3.5464 - val_acc: 0.6193\n",
      "Epoch 1319/1500\n",
      "Epoch 01318: val_loss did not improve\n",
      "2s - loss: 0.0022 - acc: 0.9992 - val_loss: 3.5616 - val_acc: 0.5680\n",
      "Epoch 1320/1500\n",
      "Epoch 01319: val_loss did not improve\n",
      "2s - loss: 0.0075 - acc: 0.9968 - val_loss: 3.5935 - val_acc: 0.5921\n",
      "Epoch 1321/1500\n",
      "Epoch 01320: val_loss did not improve\n",
      "2s - loss: 4.5144e-04 - acc: 1.0000 - val_loss: 3.8135 - val_acc: 0.5710\n",
      "Epoch 1322/1500\n",
      "Epoch 01321: val_loss did not improve\n",
      "2s - loss: 0.0095 - acc: 0.9984 - val_loss: 3.6108 - val_acc: 0.5891\n",
      "Epoch 1323/1500\n",
      "Epoch 01322: val_loss did not improve\n",
      "2s - loss: 0.0013 - acc: 1.0000 - val_loss: 3.3083 - val_acc: 0.6163\n",
      "Epoch 1324/1500\n",
      "Epoch 01323: val_loss did not improve\n",
      "2s - loss: 0.0115 - acc: 0.9960 - val_loss: 3.6970 - val_acc: 0.5680\n",
      "Epoch 1325/1500\n",
      "Epoch 01324: val_loss did not improve\n",
      "2s - loss: 0.0059 - acc: 0.9984 - val_loss: 3.4205 - val_acc: 0.5801\n",
      "Epoch 1326/1500\n",
      "Epoch 01325: val_loss did not improve\n",
      "2s - loss: 0.0032 - acc: 0.9984 - val_loss: 3.4528 - val_acc: 0.5982\n",
      "Epoch 1327/1500\n",
      "Epoch 01326: val_loss did not improve\n",
      "2s - loss: 0.0126 - acc: 0.9952 - val_loss: 3.6728 - val_acc: 0.5982\n",
      "Epoch 1328/1500\n",
      "Epoch 01327: val_loss did not improve\n",
      "2s - loss: 2.1286e-04 - acc: 1.0000 - val_loss: 3.3502 - val_acc: 0.5982\n",
      "Epoch 1329/1500\n",
      "Epoch 01328: val_loss did not improve\n",
      "2s - loss: 0.0022 - acc: 0.9992 - val_loss: 3.3471 - val_acc: 0.6042\n",
      "Epoch 1330/1500\n",
      "Epoch 01329: val_loss did not improve\n",
      "2s - loss: 0.0014 - acc: 0.9992 - val_loss: 3.9105 - val_acc: 0.5891\n",
      "Epoch 1331/1500\n",
      "Epoch 01330: val_loss did not improve\n",
      "2s - loss: 0.0110 - acc: 0.9961 - val_loss: 3.5552 - val_acc: 0.5891\n",
      "Epoch 1332/1500\n",
      "Epoch 01331: val_loss did not improve\n",
      "2s - loss: 0.0069 - acc: 0.9953 - val_loss: 3.8278 - val_acc: 0.5861\n",
      "Epoch 1333/1500\n",
      "Epoch 01332: val_loss did not improve\n",
      "2s - loss: 0.0194 - acc: 0.9961 - val_loss: 3.3439 - val_acc: 0.6314\n",
      "Epoch 1334/1500\n",
      "Epoch 01333: val_loss did not improve\n",
      "2s - loss: 0.0049 - acc: 0.9992 - val_loss: 3.6701 - val_acc: 0.5740\n",
      "Epoch 1335/1500\n",
      "Epoch 01334: val_loss did not improve\n",
      "2s - loss: 2.8613e-04 - acc: 1.0000 - val_loss: 3.5668 - val_acc: 0.5861\n",
      "Epoch 1336/1500\n",
      "Epoch 01335: val_loss did not improve\n",
      "2s - loss: 0.0018 - acc: 0.9992 - val_loss: 3.3812 - val_acc: 0.6224\n",
      "Epoch 1337/1500\n",
      "Epoch 01336: val_loss did not improve\n",
      "2s - loss: 0.0251 - acc: 0.9937 - val_loss: 3.6318 - val_acc: 0.5921\n",
      "Epoch 1338/1500\n",
      "Epoch 01337: val_loss did not improve\n",
      "2s - loss: 0.0180 - acc: 0.9930 - val_loss: 3.6151 - val_acc: 0.6163\n",
      "Epoch 1339/1500\n",
      "Epoch 01338: val_loss did not improve\n",
      "2s - loss: 0.0020 - acc: 0.9992 - val_loss: 3.8177 - val_acc: 0.5831\n",
      "Epoch 1340/1500\n",
      "Epoch 01339: val_loss did not improve\n",
      "2s - loss: 0.0014 - acc: 1.0000 - val_loss: 3.8812 - val_acc: 0.5468\n",
      "Epoch 1341/1500\n",
      "Epoch 01340: val_loss did not improve\n",
      "2s - loss: 0.0011 - acc: 1.0000 - val_loss: 3.5513 - val_acc: 0.5650\n",
      "Epoch 1342/1500\n",
      "Epoch 01341: val_loss did not improve\n",
      "2s - loss: 0.0072 - acc: 0.9968 - val_loss: 3.6226 - val_acc: 0.6042\n",
      "Epoch 1343/1500\n",
      "Epoch 01342: val_loss did not improve\n",
      "2s - loss: 0.0110 - acc: 0.9953 - val_loss: 3.7821 - val_acc: 0.5891\n",
      "Epoch 1344/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01343: val_loss did not improve\n",
      "2s - loss: 0.0033 - acc: 0.9992 - val_loss: 3.7476 - val_acc: 0.6073\n",
      "Epoch 1345/1500\n",
      "Epoch 01344: val_loss did not improve\n",
      "2s - loss: 0.0021 - acc: 0.9992 - val_loss: 3.5844 - val_acc: 0.5982\n",
      "Epoch 1346/1500\n",
      "Epoch 01345: val_loss did not improve\n",
      "2s - loss: 0.0042 - acc: 0.9976 - val_loss: 3.6907 - val_acc: 0.5921\n",
      "Epoch 1347/1500\n",
      "Epoch 01346: val_loss did not improve\n",
      "2s - loss: 0.0027 - acc: 0.9992 - val_loss: 3.8839 - val_acc: 0.5619\n",
      "Epoch 1348/1500\n",
      "Epoch 01347: val_loss did not improve\n",
      "2s - loss: 0.0052 - acc: 0.9976 - val_loss: 4.2244 - val_acc: 0.5408\n",
      "Epoch 1349/1500\n",
      "Epoch 01348: val_loss did not improve\n",
      "2s - loss: 0.0116 - acc: 0.9969 - val_loss: 3.4834 - val_acc: 0.6254\n",
      "Epoch 1350/1500\n",
      "Epoch 01349: val_loss did not improve\n",
      "2s - loss: 0.0016 - acc: 0.9992 - val_loss: 3.6328 - val_acc: 0.6042\n",
      "Epoch 1351/1500\n",
      "Epoch 01350: val_loss did not improve\n",
      "2s - loss: 0.0129 - acc: 0.9960 - val_loss: 3.5757 - val_acc: 0.5710\n",
      "Epoch 1352/1500\n",
      "Epoch 01351: val_loss did not improve\n",
      "2s - loss: 0.0057 - acc: 0.9992 - val_loss: 3.4648 - val_acc: 0.5952\n",
      "Epoch 1353/1500\n",
      "Epoch 01352: val_loss did not improve\n",
      "2s - loss: 0.0021 - acc: 0.9992 - val_loss: 3.7381 - val_acc: 0.5831\n",
      "Epoch 1354/1500\n",
      "Epoch 01353: val_loss did not improve\n",
      "2s - loss: 0.0292 - acc: 0.9946 - val_loss: 3.3176 - val_acc: 0.6133\n",
      "Epoch 1355/1500\n",
      "Epoch 01354: val_loss did not improve\n",
      "2s - loss: 0.0029 - acc: 0.9992 - val_loss: 3.4906 - val_acc: 0.5982\n",
      "Epoch 1356/1500\n",
      "Epoch 01355: val_loss did not improve\n",
      "2s - loss: 0.0094 - acc: 0.9984 - val_loss: 3.6685 - val_acc: 0.5952\n",
      "Epoch 1357/1500\n",
      "Epoch 01356: val_loss did not improve\n",
      "2s - loss: 0.0037 - acc: 0.9977 - val_loss: 3.3880 - val_acc: 0.6012\n",
      "Epoch 1358/1500\n",
      "Epoch 01357: val_loss did not improve\n",
      "2s - loss: 0.0031 - acc: 0.9977 - val_loss: 3.5586 - val_acc: 0.5891\n",
      "Epoch 1359/1500\n",
      "Epoch 01358: val_loss did not improve\n",
      "2s - loss: 7.6656e-04 - acc: 1.0000 - val_loss: 3.8489 - val_acc: 0.5680\n",
      "Epoch 1360/1500\n",
      "Epoch 01359: val_loss did not improve\n",
      "2s - loss: 0.0013 - acc: 1.0000 - val_loss: 3.4423 - val_acc: 0.6103\n",
      "Epoch 1361/1500\n",
      "Epoch 01360: val_loss did not improve\n",
      "2s - loss: 0.0196 - acc: 0.9961 - val_loss: 3.6842 - val_acc: 0.6254\n",
      "Epoch 1362/1500\n",
      "Epoch 01361: val_loss did not improve\n",
      "2s - loss: 0.0037 - acc: 0.9969 - val_loss: 3.5711 - val_acc: 0.6042\n",
      "Epoch 1363/1500\n",
      "Epoch 01362: val_loss did not improve\n",
      "2s - loss: 0.0036 - acc: 0.9992 - val_loss: 3.4192 - val_acc: 0.6073\n",
      "Epoch 1364/1500\n",
      "Epoch 01363: val_loss did not improve\n",
      "2s - loss: 0.0013 - acc: 1.0000 - val_loss: 3.6742 - val_acc: 0.5921\n",
      "Epoch 1365/1500\n",
      "Epoch 01364: val_loss did not improve\n",
      "2s - loss: 0.0067 - acc: 0.9984 - val_loss: 3.3816 - val_acc: 0.6193\n",
      "Epoch 1366/1500\n",
      "Epoch 01365: val_loss did not improve\n",
      "2s - loss: 0.0066 - acc: 0.9976 - val_loss: 3.5314 - val_acc: 0.5710\n",
      "Epoch 1367/1500\n",
      "Epoch 01366: val_loss did not improve\n",
      "2s - loss: 0.0167 - acc: 0.9952 - val_loss: 3.6713 - val_acc: 0.5770\n",
      "Epoch 1368/1500\n",
      "Epoch 01367: val_loss did not improve\n",
      "2s - loss: 0.0100 - acc: 0.9960 - val_loss: 3.7283 - val_acc: 0.5831\n",
      "Epoch 1369/1500\n",
      "Epoch 01368: val_loss did not improve\n",
      "2s - loss: 0.0084 - acc: 0.9984 - val_loss: 3.7445 - val_acc: 0.5831\n",
      "Epoch 1370/1500\n",
      "Epoch 01369: val_loss did not improve\n",
      "2s - loss: 0.0227 - acc: 0.9953 - val_loss: 3.8135 - val_acc: 0.5619\n",
      "Epoch 1371/1500\n",
      "Epoch 01370: val_loss did not improve\n",
      "2s - loss: 0.0020 - acc: 0.9992 - val_loss: 3.4684 - val_acc: 0.5952\n",
      "Epoch 1372/1500\n",
      "Epoch 01371: val_loss did not improve\n",
      "2s - loss: 0.0084 - acc: 0.9968 - val_loss: 3.6733 - val_acc: 0.5921\n",
      "Epoch 1373/1500\n",
      "Epoch 01372: val_loss did not improve\n",
      "2s - loss: 0.0059 - acc: 0.9992 - val_loss: 3.5867 - val_acc: 0.5921\n",
      "Epoch 1374/1500\n",
      "Epoch 01373: val_loss did not improve\n",
      "2s - loss: 0.0065 - acc: 0.9968 - val_loss: 3.3432 - val_acc: 0.6012\n",
      "Epoch 1375/1500\n",
      "Epoch 01374: val_loss did not improve\n",
      "2s - loss: 0.0126 - acc: 0.9954 - val_loss: 3.4785 - val_acc: 0.5801\n",
      "Epoch 1376/1500\n",
      "Epoch 01375: val_loss did not improve\n",
      "2s - loss: 8.7845e-04 - acc: 1.0000 - val_loss: 3.9293 - val_acc: 0.5287\n",
      "Epoch 1377/1500\n",
      "Epoch 01376: val_loss did not improve\n",
      "2s - loss: 0.0101 - acc: 0.9976 - val_loss: 3.4687 - val_acc: 0.6193\n",
      "Epoch 1378/1500\n",
      "Epoch 01377: val_loss did not improve\n",
      "2s - loss: 5.8206e-04 - acc: 1.0000 - val_loss: 3.5088 - val_acc: 0.5861\n",
      "Epoch 1379/1500\n",
      "Epoch 01378: val_loss did not improve\n",
      "2s - loss: 0.0054 - acc: 0.9984 - val_loss: 3.6970 - val_acc: 0.5831\n",
      "Epoch 1380/1500\n",
      "Epoch 01379: val_loss did not improve\n",
      "2s - loss: 0.0035 - acc: 0.9992 - val_loss: 3.7492 - val_acc: 0.5861\n",
      "Epoch 1381/1500\n",
      "Epoch 01380: val_loss did not improve\n",
      "2s - loss: 0.0027 - acc: 0.9984 - val_loss: 3.3501 - val_acc: 0.6314\n",
      "Epoch 1382/1500\n",
      "Epoch 01381: val_loss did not improve\n",
      "2s - loss: 0.0121 - acc: 0.9953 - val_loss: 3.7158 - val_acc: 0.5891\n",
      "Epoch 1383/1500\n",
      "Epoch 01382: val_loss did not improve\n",
      "2s - loss: 0.0030 - acc: 0.9992 - val_loss: 3.6041 - val_acc: 0.5861\n",
      "Epoch 1384/1500\n",
      "Epoch 01383: val_loss did not improve\n",
      "2s - loss: 0.0045 - acc: 0.9984 - val_loss: 3.8352 - val_acc: 0.5891\n",
      "Epoch 1385/1500\n",
      "Epoch 01384: val_loss did not improve\n",
      "2s - loss: 0.0019 - acc: 1.0000 - val_loss: 3.9098 - val_acc: 0.5559\n",
      "Epoch 1386/1500\n",
      "Epoch 01385: val_loss did not improve\n",
      "2s - loss: 0.0102 - acc: 0.9953 - val_loss: 3.6089 - val_acc: 0.5982\n",
      "Epoch 1387/1500\n",
      "Epoch 01386: val_loss did not improve\n",
      "2s - loss: 0.0083 - acc: 0.9976 - val_loss: 3.3402 - val_acc: 0.6073\n",
      "Epoch 1388/1500\n",
      "Epoch 01387: val_loss did not improve\n",
      "2s - loss: 0.0092 - acc: 0.9960 - val_loss: 3.6274 - val_acc: 0.5861\n",
      "Epoch 1389/1500\n",
      "Epoch 01388: val_loss did not improve\n",
      "2s - loss: 0.0079 - acc: 0.9984 - val_loss: 3.7215 - val_acc: 0.5891\n",
      "Epoch 1390/1500\n",
      "Epoch 01389: val_loss did not improve\n",
      "2s - loss: 0.0086 - acc: 0.9969 - val_loss: 3.5786 - val_acc: 0.6042\n",
      "Epoch 1391/1500\n",
      "Epoch 01390: val_loss did not improve\n",
      "2s - loss: 0.0144 - acc: 0.9930 - val_loss: 3.5841 - val_acc: 0.5982\n",
      "Epoch 1392/1500\n",
      "Epoch 01391: val_loss did not improve\n",
      "2s - loss: 0.0019 - acc: 0.9992 - val_loss: 3.8502 - val_acc: 0.5770\n",
      "Epoch 1393/1500\n",
      "Epoch 01392: val_loss did not improve\n",
      "2s - loss: 0.0060 - acc: 0.9984 - val_loss: 3.7132 - val_acc: 0.5891\n",
      "Epoch 1394/1500\n",
      "Epoch 01393: val_loss did not improve\n",
      "2s - loss: 0.0111 - acc: 0.9968 - val_loss: 3.7350 - val_acc: 0.5710\n",
      "Epoch 1395/1500\n",
      "Epoch 01394: val_loss did not improve\n",
      "2s - loss: 0.0034 - acc: 0.9992 - val_loss: 3.4428 - val_acc: 0.6163\n",
      "Epoch 1396/1500\n",
      "Epoch 01395: val_loss did not improve\n",
      "2s - loss: 0.0065 - acc: 0.9976 - val_loss: 3.6875 - val_acc: 0.6073\n",
      "Epoch 1397/1500\n",
      "Epoch 01396: val_loss did not improve\n",
      "2s - loss: 0.0221 - acc: 0.9960 - val_loss: 3.6516 - val_acc: 0.5861\n",
      "Epoch 1398/1500\n",
      "Epoch 01397: val_loss did not improve\n",
      "2s - loss: 0.0205 - acc: 0.9952 - val_loss: 3.8996 - val_acc: 0.5619\n",
      "Epoch 1399/1500\n",
      "Epoch 01398: val_loss did not improve\n",
      "2s - loss: 0.0211 - acc: 0.9961 - val_loss: 3.5483 - val_acc: 0.6073\n",
      "Epoch 1400/1500\n",
      "Epoch 01399: val_loss did not improve\n",
      "2s - loss: 0.0033 - acc: 0.9984 - val_loss: 3.5866 - val_acc: 0.5891\n",
      "Epoch 1401/1500\n",
      "Epoch 01400: val_loss did not improve\n",
      "2s - loss: 0.0069 - acc: 0.9976 - val_loss: 3.4566 - val_acc: 0.6103\n",
      "Epoch 1402/1500\n",
      "Epoch 01401: val_loss did not improve\n",
      "2s - loss: 0.0039 - acc: 0.9992 - val_loss: 3.4750 - val_acc: 0.6073\n",
      "Epoch 1403/1500\n",
      "Epoch 01402: val_loss did not improve\n",
      "2s - loss: 0.0082 - acc: 0.9945 - val_loss: 3.7011 - val_acc: 0.5831\n",
      "Epoch 1404/1500\n",
      "Epoch 01403: val_loss did not improve\n",
      "2s - loss: 0.0018 - acc: 0.9984 - val_loss: 3.5569 - val_acc: 0.5801\n",
      "Epoch 1405/1500\n",
      "Epoch 01404: val_loss did not improve\n",
      "2s - loss: 0.0251 - acc: 0.9961 - val_loss: 3.6687 - val_acc: 0.6042\n",
      "Epoch 1406/1500\n",
      "Epoch 01405: val_loss did not improve\n",
      "2s - loss: 0.0073 - acc: 0.9969 - val_loss: 3.8800 - val_acc: 0.5801\n",
      "Epoch 1407/1500\n",
      "Epoch 01406: val_loss did not improve\n",
      "2s - loss: 0.0026 - acc: 0.9984 - val_loss: 3.6552 - val_acc: 0.6103\n",
      "Epoch 1408/1500\n",
      "Epoch 01407: val_loss did not improve\n",
      "2s - loss: 0.0266 - acc: 0.9961 - val_loss: 3.4932 - val_acc: 0.5952\n",
      "Epoch 1409/1500\n",
      "Epoch 01408: val_loss did not improve\n",
      "2s - loss: 0.0104 - acc: 0.9977 - val_loss: 3.4701 - val_acc: 0.5921\n",
      "Epoch 1410/1500\n",
      "Epoch 01409: val_loss did not improve\n",
      "2s - loss: 0.0058 - acc: 0.9968 - val_loss: 3.5188 - val_acc: 0.6224\n",
      "Epoch 1411/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01410: val_loss did not improve\n",
      "2s - loss: 0.0082 - acc: 0.9953 - val_loss: 3.5008 - val_acc: 0.5861\n",
      "Epoch 1412/1500\n",
      "Epoch 01411: val_loss did not improve\n",
      "2s - loss: 0.0103 - acc: 0.9976 - val_loss: 3.8233 - val_acc: 0.5740\n",
      "Epoch 1413/1500\n",
      "Epoch 01412: val_loss did not improve\n",
      "2s - loss: 0.0086 - acc: 0.9976 - val_loss: 3.7624 - val_acc: 0.5770\n",
      "Epoch 1414/1500\n",
      "Epoch 01413: val_loss did not improve\n",
      "2s - loss: 0.0185 - acc: 0.9946 - val_loss: 3.8337 - val_acc: 0.5861\n",
      "Epoch 1415/1500\n",
      "Epoch 01414: val_loss did not improve\n",
      "2s - loss: 0.0014 - acc: 1.0000 - val_loss: 3.6219 - val_acc: 0.5921\n",
      "Epoch 1416/1500\n",
      "Epoch 01415: val_loss did not improve\n",
      "2s - loss: 0.0057 - acc: 0.9984 - val_loss: 3.5636 - val_acc: 0.5831\n",
      "Epoch 1417/1500\n",
      "Epoch 01416: val_loss did not improve\n",
      "2s - loss: 0.0111 - acc: 0.9976 - val_loss: 3.6734 - val_acc: 0.5831\n",
      "Epoch 1418/1500\n",
      "Epoch 01417: val_loss did not improve\n",
      "2s - loss: 0.0021 - acc: 0.9992 - val_loss: 3.7211 - val_acc: 0.5921\n",
      "Epoch 1419/1500\n",
      "Epoch 01418: val_loss did not improve\n",
      "2s - loss: 0.0062 - acc: 0.9976 - val_loss: 3.6960 - val_acc: 0.5921\n",
      "Epoch 1420/1500\n",
      "Epoch 01419: val_loss did not improve\n",
      "2s - loss: 0.0023 - acc: 0.9992 - val_loss: 3.4877 - val_acc: 0.6133\n",
      "Epoch 1421/1500\n",
      "Epoch 01420: val_loss did not improve\n",
      "2s - loss: 0.0117 - acc: 0.9953 - val_loss: 3.8283 - val_acc: 0.5861\n",
      "Epoch 1422/1500\n",
      "Epoch 01421: val_loss did not improve\n",
      "2s - loss: 0.0043 - acc: 0.9984 - val_loss: 3.5386 - val_acc: 0.6224\n",
      "Epoch 1423/1500\n",
      "Epoch 01422: val_loss did not improve\n",
      "2s - loss: 0.0021 - acc: 0.9992 - val_loss: 3.3145 - val_acc: 0.6405\n",
      "Epoch 1424/1500\n",
      "Epoch 01423: val_loss did not improve\n",
      "2s - loss: 0.0030 - acc: 0.9992 - val_loss: 3.3689 - val_acc: 0.6193\n",
      "Epoch 1425/1500\n",
      "Epoch 01424: val_loss did not improve\n",
      "2s - loss: 0.0020 - acc: 0.9992 - val_loss: 3.8955 - val_acc: 0.5680\n",
      "Epoch 1426/1500\n",
      "Epoch 01425: val_loss did not improve\n",
      "2s - loss: 0.0188 - acc: 0.9977 - val_loss: 4.2034 - val_acc: 0.5468\n",
      "Epoch 1427/1500\n",
      "Epoch 01426: val_loss did not improve\n",
      "2s - loss: 0.0680 - acc: 0.9915 - val_loss: 3.5338 - val_acc: 0.6073\n",
      "Epoch 1428/1500\n",
      "Epoch 01427: val_loss did not improve\n",
      "2s - loss: 0.0034 - acc: 0.9976 - val_loss: 3.6413 - val_acc: 0.5921\n",
      "Epoch 1429/1500\n",
      "Epoch 01428: val_loss did not improve\n",
      "2s - loss: 0.0038 - acc: 0.9969 - val_loss: 3.5228 - val_acc: 0.5921\n",
      "Epoch 1430/1500\n",
      "Epoch 01429: val_loss did not improve\n",
      "2s - loss: 6.9098e-04 - acc: 1.0000 - val_loss: 3.7552 - val_acc: 0.5861\n",
      "Epoch 1431/1500\n",
      "Epoch 01430: val_loss did not improve\n",
      "2s - loss: 0.0024 - acc: 0.9992 - val_loss: 3.5826 - val_acc: 0.5982\n",
      "Epoch 1432/1500\n",
      "Epoch 01431: val_loss did not improve\n",
      "2s - loss: 0.0051 - acc: 0.9984 - val_loss: 3.7083 - val_acc: 0.5770\n",
      "Epoch 1433/1500\n",
      "Epoch 01432: val_loss did not improve\n",
      "2s - loss: 0.0011 - acc: 1.0000 - val_loss: 3.3577 - val_acc: 0.6224\n",
      "Epoch 1434/1500\n",
      "Epoch 01433: val_loss did not improve\n",
      "2s - loss: 0.0093 - acc: 0.9968 - val_loss: 3.6809 - val_acc: 0.6073\n",
      "Epoch 1435/1500\n",
      "Epoch 01434: val_loss did not improve\n",
      "2s - loss: 0.0012 - acc: 1.0000 - val_loss: 3.6441 - val_acc: 0.5921\n",
      "Epoch 1436/1500\n",
      "Epoch 01435: val_loss did not improve\n",
      "2s - loss: 0.0126 - acc: 0.9976 - val_loss: 3.3909 - val_acc: 0.6284\n",
      "Epoch 1437/1500\n",
      "Epoch 01436: val_loss did not improve\n",
      "2s - loss: 0.0098 - acc: 0.9961 - val_loss: 3.6270 - val_acc: 0.6103\n",
      "Epoch 1438/1500\n",
      "Epoch 01437: val_loss did not improve\n",
      "2s - loss: 0.0065 - acc: 0.9976 - val_loss: 3.4851 - val_acc: 0.6133\n",
      "Epoch 1439/1500\n",
      "Epoch 01438: val_loss did not improve\n",
      "2s - loss: 0.0089 - acc: 0.9953 - val_loss: 3.5955 - val_acc: 0.6103\n",
      "Epoch 1440/1500\n",
      "Epoch 01439: val_loss did not improve\n",
      "2s - loss: 0.0013 - acc: 0.9992 - val_loss: 3.3690 - val_acc: 0.6163\n",
      "Epoch 1441/1500\n",
      "Epoch 01440: val_loss did not improve\n",
      "2s - loss: 0.0079 - acc: 0.9976 - val_loss: 3.4423 - val_acc: 0.6133\n",
      "Epoch 1442/1500\n",
      "Epoch 01441: val_loss did not improve\n",
      "2s - loss: 0.0103 - acc: 0.9968 - val_loss: 3.7838 - val_acc: 0.5801\n",
      "Epoch 1443/1500\n",
      "Epoch 01442: val_loss did not improve\n",
      "2s - loss: 6.9397e-04 - acc: 1.0000 - val_loss: 3.7157 - val_acc: 0.5982\n",
      "Epoch 1444/1500\n",
      "Epoch 01443: val_loss did not improve\n",
      "2s - loss: 0.0110 - acc: 0.9961 - val_loss: 3.8833 - val_acc: 0.5770\n",
      "Epoch 1445/1500\n",
      "Epoch 01444: val_loss did not improve\n",
      "2s - loss: 0.0054 - acc: 0.9984 - val_loss: 3.6849 - val_acc: 0.5891\n",
      "Epoch 1446/1500\n",
      "Epoch 01445: val_loss did not improve\n",
      "2s - loss: 0.0054 - acc: 0.9984 - val_loss: 3.4494 - val_acc: 0.6344\n",
      "Epoch 1447/1500\n",
      "Epoch 01446: val_loss did not improve\n",
      "2s - loss: 0.0023 - acc: 0.9984 - val_loss: 3.7921 - val_acc: 0.6012\n",
      "Epoch 1448/1500\n",
      "Epoch 01447: val_loss did not improve\n",
      "2s - loss: 9.5528e-04 - acc: 1.0000 - val_loss: 3.4604 - val_acc: 0.6042\n",
      "Epoch 1449/1500\n",
      "Epoch 01448: val_loss did not improve\n",
      "2s - loss: 0.0142 - acc: 0.9968 - val_loss: 3.6624 - val_acc: 0.5861\n",
      "Epoch 1450/1500\n",
      "Epoch 01449: val_loss did not improve\n",
      "2s - loss: 5.1839e-04 - acc: 1.0000 - val_loss: 3.5666 - val_acc: 0.5861\n",
      "Epoch 1451/1500\n",
      "Epoch 01450: val_loss did not improve\n",
      "2s - loss: 0.0041 - acc: 0.9968 - val_loss: 3.3875 - val_acc: 0.6073\n",
      "Epoch 1452/1500\n",
      "Epoch 01451: val_loss did not improve\n",
      "2s - loss: 0.0103 - acc: 0.9984 - val_loss: 3.5747 - val_acc: 0.5952\n",
      "Epoch 1453/1500\n",
      "Epoch 01452: val_loss did not improve\n",
      "2s - loss: 0.0040 - acc: 0.9992 - val_loss: 3.5667 - val_acc: 0.6133\n",
      "Epoch 1454/1500\n",
      "Epoch 01453: val_loss did not improve\n",
      "2s - loss: 0.0017 - acc: 0.9992 - val_loss: 3.7767 - val_acc: 0.5619\n",
      "Epoch 1455/1500\n",
      "Epoch 01454: val_loss did not improve\n",
      "2s - loss: 0.0055 - acc: 0.9976 - val_loss: 3.8293 - val_acc: 0.5921\n",
      "Epoch 1456/1500\n",
      "Epoch 01455: val_loss did not improve\n",
      "2s - loss: 0.0063 - acc: 0.9984 - val_loss: 3.6011 - val_acc: 0.5861\n",
      "Epoch 1457/1500\n",
      "Epoch 01456: val_loss did not improve\n",
      "2s - loss: 0.0121 - acc: 0.9960 - val_loss: 3.4801 - val_acc: 0.5891\n",
      "Epoch 1458/1500\n",
      "Epoch 01457: val_loss did not improve\n",
      "2s - loss: 0.0029 - acc: 0.9977 - val_loss: 4.0596 - val_acc: 0.5619\n",
      "Epoch 1459/1500\n",
      "Epoch 01458: val_loss did not improve\n",
      "2s - loss: 0.0032 - acc: 0.9992 - val_loss: 3.6916 - val_acc: 0.5801\n",
      "Epoch 1460/1500\n",
      "Epoch 01459: val_loss did not improve\n",
      "2s - loss: 0.0037 - acc: 0.9984 - val_loss: 3.6648 - val_acc: 0.5650\n",
      "Epoch 1461/1500\n",
      "Epoch 01460: val_loss did not improve\n",
      "2s - loss: 0.0032 - acc: 0.9992 - val_loss: 3.3909 - val_acc: 0.6193\n",
      "Epoch 1462/1500\n",
      "Epoch 01461: val_loss did not improve\n",
      "2s - loss: 0.0079 - acc: 0.9976 - val_loss: 3.6210 - val_acc: 0.5982\n",
      "Epoch 1463/1500\n",
      "Epoch 01462: val_loss did not improve\n",
      "2s - loss: 0.0015 - acc: 1.0000 - val_loss: 3.8345 - val_acc: 0.5861\n",
      "Epoch 1464/1500\n",
      "Epoch 01463: val_loss did not improve\n",
      "2s - loss: 0.0061 - acc: 0.9976 - val_loss: 3.9697 - val_acc: 0.5891\n",
      "Epoch 1465/1500\n",
      "Epoch 01464: val_loss did not improve\n",
      "2s - loss: 0.0077 - acc: 0.9960 - val_loss: 3.7257 - val_acc: 0.5952\n",
      "Epoch 1466/1500\n",
      "Epoch 01465: val_loss did not improve\n",
      "2s - loss: 0.0053 - acc: 0.9984 - val_loss: 4.0967 - val_acc: 0.5559\n",
      "Epoch 1467/1500\n",
      "Epoch 01466: val_loss did not improve\n",
      "2s - loss: 0.0144 - acc: 0.9953 - val_loss: 3.4696 - val_acc: 0.6193\n",
      "Epoch 1468/1500\n",
      "Epoch 01467: val_loss did not improve\n",
      "2s - loss: 0.0061 - acc: 0.9968 - val_loss: 3.8554 - val_acc: 0.5770\n",
      "Epoch 1469/1500\n",
      "Epoch 01468: val_loss did not improve\n",
      "2s - loss: 0.0107 - acc: 0.9945 - val_loss: 3.8780 - val_acc: 0.5619\n",
      "Epoch 1470/1500\n",
      "Epoch 01469: val_loss did not improve\n",
      "2s - loss: 0.0032 - acc: 0.9976 - val_loss: 3.4023 - val_acc: 0.6133\n",
      "Epoch 1471/1500\n",
      "Epoch 01470: val_loss did not improve\n",
      "2s - loss: 0.0481 - acc: 0.9900 - val_loss: 3.6489 - val_acc: 0.6012\n",
      "Epoch 1472/1500\n",
      "Epoch 01471: val_loss did not improve\n",
      "2s - loss: 0.0096 - acc: 0.9976 - val_loss: 3.6590 - val_acc: 0.5891\n",
      "Epoch 1473/1500\n",
      "Epoch 01472: val_loss did not improve\n",
      "2s - loss: 0.0015 - acc: 0.9992 - val_loss: 3.7258 - val_acc: 0.6012\n",
      "Epoch 1474/1500\n",
      "Epoch 01473: val_loss did not improve\n",
      "2s - loss: 0.0133 - acc: 0.9952 - val_loss: 3.6559 - val_acc: 0.5982\n",
      "Epoch 1475/1500\n",
      "Epoch 01474: val_loss did not improve\n",
      "2s - loss: 0.0020 - acc: 1.0000 - val_loss: 3.4420 - val_acc: 0.6012\n",
      "Epoch 1476/1500\n",
      "Epoch 01475: val_loss did not improve\n",
      "2s - loss: 0.0144 - acc: 0.9937 - val_loss: 3.6281 - val_acc: 0.5982\n",
      "Epoch 1477/1500\n",
      "Epoch 01476: val_loss did not improve\n",
      "2s - loss: 0.0065 - acc: 0.9984 - val_loss: 3.8777 - val_acc: 0.5559\n",
      "Epoch 1478/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01477: val_loss did not improve\n",
      "2s - loss: 0.0011 - acc: 1.0000 - val_loss: 3.8002 - val_acc: 0.5529\n",
      "Epoch 1479/1500\n",
      "Epoch 01478: val_loss did not improve\n",
      "2s - loss: 0.0534 - acc: 0.9946 - val_loss: 3.9206 - val_acc: 0.5921\n",
      "Epoch 1480/1500\n",
      "Epoch 01479: val_loss did not improve\n",
      "2s - loss: 4.3795e-04 - acc: 1.0000 - val_loss: 3.7218 - val_acc: 0.5861\n",
      "Epoch 1481/1500\n",
      "Epoch 01480: val_loss did not improve\n",
      "2s - loss: 0.0013 - acc: 1.0000 - val_loss: 3.4621 - val_acc: 0.5952\n",
      "Epoch 1482/1500\n",
      "Epoch 01481: val_loss did not improve\n",
      "2s - loss: 0.0042 - acc: 0.9992 - val_loss: 3.5874 - val_acc: 0.6163\n",
      "Epoch 1483/1500\n",
      "Epoch 01482: val_loss did not improve\n",
      "2s - loss: 0.0198 - acc: 0.9969 - val_loss: 3.4645 - val_acc: 0.6133\n",
      "Epoch 1484/1500\n",
      "Epoch 01483: val_loss did not improve\n",
      "2s - loss: 0.0066 - acc: 0.9984 - val_loss: 3.4542 - val_acc: 0.6103\n",
      "Epoch 1485/1500\n",
      "Epoch 01484: val_loss did not improve\n",
      "2s - loss: 0.0109 - acc: 0.9976 - val_loss: 3.5883 - val_acc: 0.5770\n",
      "Epoch 1486/1500\n",
      "Epoch 01485: val_loss did not improve\n",
      "2s - loss: 7.3174e-04 - acc: 1.0000 - val_loss: 3.6807 - val_acc: 0.6012\n",
      "Epoch 1487/1500\n",
      "Epoch 01486: val_loss did not improve\n",
      "2s - loss: 0.0077 - acc: 0.9992 - val_loss: 3.5619 - val_acc: 0.5891\n",
      "Epoch 1488/1500\n",
      "Epoch 01487: val_loss did not improve\n",
      "2s - loss: 0.0079 - acc: 0.9968 - val_loss: 3.5576 - val_acc: 0.6012\n",
      "Epoch 1489/1500\n",
      "Epoch 01488: val_loss did not improve\n",
      "2s - loss: 0.0068 - acc: 0.9961 - val_loss: 3.8386 - val_acc: 0.5740\n",
      "Epoch 1490/1500\n",
      "Epoch 01489: val_loss did not improve\n",
      "2s - loss: 0.0127 - acc: 0.9968 - val_loss: 3.7493 - val_acc: 0.5801\n",
      "Epoch 1491/1500\n",
      "Epoch 01490: val_loss did not improve\n",
      "2s - loss: 0.0310 - acc: 0.9938 - val_loss: 3.1329 - val_acc: 0.6314\n",
      "Epoch 1492/1500\n",
      "Epoch 01491: val_loss did not improve\n",
      "2s - loss: 0.0036 - acc: 0.9977 - val_loss: 3.5758 - val_acc: 0.6042\n",
      "Epoch 1493/1500\n",
      "Epoch 01492: val_loss did not improve\n",
      "2s - loss: 0.0076 - acc: 0.9984 - val_loss: 3.1092 - val_acc: 0.6103\n",
      "Epoch 1494/1500\n",
      "Epoch 01493: val_loss did not improve\n",
      "2s - loss: 0.0012 - acc: 1.0000 - val_loss: 3.5504 - val_acc: 0.6012\n",
      "Epoch 1495/1500\n",
      "Epoch 01494: val_loss did not improve\n",
      "2s - loss: 9.1941e-04 - acc: 1.0000 - val_loss: 3.5030 - val_acc: 0.6284\n",
      "Epoch 1496/1500\n",
      "Epoch 01495: val_loss did not improve\n",
      "2s - loss: 0.0052 - acc: 0.9992 - val_loss: 3.7738 - val_acc: 0.5891\n",
      "Epoch 1497/1500\n",
      "Epoch 01496: val_loss did not improve\n",
      "2s - loss: 6.5853e-04 - acc: 1.0000 - val_loss: 3.6118 - val_acc: 0.6042\n",
      "Epoch 1498/1500\n",
      "Epoch 01497: val_loss did not improve\n",
      "2s - loss: 0.0144 - acc: 0.9953 - val_loss: 3.8654 - val_acc: 0.5921\n",
      "Epoch 1499/1500\n",
      "Epoch 01498: val_loss did not improve\n",
      "2s - loss: 0.0179 - acc: 0.9952 - val_loss: 3.7922 - val_acc: 0.5680\n",
      "Epoch 1500/1500\n",
      "Epoch 01499: val_loss did not improve\n",
      "2s - loss: 0.0076 - acc: 0.9961 - val_loss: 3.8909 - val_acc: 0.5861\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='piece_model.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "piece_hist = piece_model.fit_generator(generator=piece_train_iter, \n",
    "                          steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                          validation_data=piece_valid_iter, \n",
    "                          validation_steps=STEP_SIZE_VALID,\n",
    "                          epochs=1500, \n",
    "                          callbacks=[checkpointer], \n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 0.522388059701\n"
     ]
    }
   ],
   "source": [
    "#Reset test iterator\n",
    "STEP_SIZE_TEST = piece_test_iter.n/piece_test_iter.batch_size\n",
    "piece_test_iter.reset()\n",
    "# load the weights that yielded the best validation accuracy\n",
    "piece_model.load_weights('piece_model.weights.best.hdf5')\n",
    "# evaluate and print test accuracy\n",
    "score = piece_model.evaluate_generator(generator=piece_test_iter,steps=STEP_SIZE_TEST)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "piece_test_iter.reset()\n",
    "piece_pred = piece_model.predict_generator(piece_test_iter,steps=STEP_SIZE_TEST,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 0 1 4 2 3 0 0 1 0 2 2 3 0 0 5 0 2 3 3 0 0 2 3 3 5 0 0 0 0 3 0 0 4 2 2\n",
      " 3 4 0 0 0 0 0 3 5 0 1 1 0 2 4 1 1 4 1 2 4 1 0 1 1 0 2 1 1 5 4 1 1 3 5 4 1\n",
      " 5 1 5 4 1 5 2 4 3 0 5 3 0 3 2 5 2 2 5 5 5 2 3 2 5 2 4 3 0 0 0 2 3 0 3 0 2\n",
      " 2 2 5 2 5 4 3 3 2 2 0 2 5 2 3 0 5 2 4 2 5 3 0 0 2 2 2 2 3 2 3 3 3 3 3 3 3\n",
      " 3 0 3 3 2 0 3 5 3 5 2 2 3 6 0 3 3 3 3 3 5 5 3 0 0 0 0 2 3 3 5 2 3 2 3 3 3\n",
      " 3 2 2 3 3 5 3 4 0 2 1 4 5 2 5 4 0 4 4 4 0 4 5 0 2 0 4 1 1 5 3 3 2 1 1 1 2\n",
      " 0 4 3 0 2 5 2 5 5 3 0 2 5 6 2 5 5 5 5 5 5 3 5 5 5 5 0 3 5 5 5 3 5 3 0 3 5\n",
      " 3 1 5 2 5 6 1 2 5 3 0 5 3 3 6 3 5 4 0 5 0 5 0 4 0 5 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6]\n"
     ]
    }
   ],
   "source": [
    "predicted_class_indices=np.argmax(piece_pred,axis=1)\n",
    "print(predicted_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (piece_test_iter.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "truth =  [labels[k] for k in piece_test_iter.classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[labels[k] for k in piece_test_iter.classes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bishop/1538778538.3017461.jpg',\n",
       " 'bishop/1539025832.837544.jpg',\n",
       " 'bishop/1539025486.6533895.jpg',\n",
       " 'bishop/1538779519.5865016.jpg',\n",
       " 'bishop/1538778643.4925923.jpg',\n",
       " 'bishop/1539023363.830272.jpg',\n",
       " 'bishop/1539025801.510389.jpg',\n",
       " 'bishop/1538778410.6081142.jpg',\n",
       " 'bishop/1538778215.8878355.jpg',\n",
       " 'bishop/1538778752.467536.jpg',\n",
       " 'bishop/1539025373.0113628.jpg',\n",
       " 'bishop/1539023140.397658.jpg',\n",
       " 'bishop/1539025334.2429533.jpg',\n",
       " 'bishop/1538778214.3746974.jpg',\n",
       " 'bishop/1539023732.561326.jpg',\n",
       " 'bishop/1538777556.4695792.jpg',\n",
       " 'bishop/1539024760.3120384.jpg',\n",
       " 'bishop/1538778091.9695802.jpg',\n",
       " 'bishop/1539024593.521976.jpg',\n",
       " 'bishop/1538779155.2682924.jpg',\n",
       " 'bishop/1538778833.610855.jpg',\n",
       " 'bishop/1538777891.4931645.jpg',\n",
       " 'bishop/1539017656.6888525_5.jpg',\n",
       " 'bishop/1538778427.8668559.jpg',\n",
       " 'bishop/1538777675.2653856.jpg',\n",
       " 'bishop/1538778093.2397656.jpg',\n",
       " 'bishop/1539024725.794323.jpg',\n",
       " 'bishop/1539026035.275597.jpg',\n",
       " 'bishop/1539024424.9014952.jpg',\n",
       " 'bishop/1539024039.3749897.jpg',\n",
       " 'bishop/1538778832.1937056.jpg',\n",
       " 'bishop/1538778729.1405196.jpg',\n",
       " 'bishop/1539025434.58347.jpg',\n",
       " 'bishop/1538778878.3252861.jpg',\n",
       " 'bishop/1539025959.458598.jpg',\n",
       " 'bishop/1539025736.4874806.jpg',\n",
       " 'bishop/1539025415.635129.jpg',\n",
       " 'bishop/1538779144.9958382.jpg',\n",
       " 'bishop/1539017656.2202125_22.jpg',\n",
       " 'bishop/1538779417.7487714.jpg',\n",
       " 'bishop/1538777310.1624303.jpg',\n",
       " 'bishop/1538778958.324379.jpg',\n",
       " 'bishop/1538778656.6147914.jpg',\n",
       " 'bishop/1539025355.3753638.jpg',\n",
       " 'bishop/1538778537.1458335.jpg',\n",
       " 'bishop/1538778653.1963263.jpg',\n",
       " 'bishop/1539025474.8601475.jpg',\n",
       " 'king/1538776272.1332486.jpg',\n",
       " 'king/1539017657.8720484_58.jpg',\n",
       " 'king/1539017656.0015128_29.jpg',\n",
       " 'king/1538776522.496111.jpg',\n",
       " 'king/1538778011.0228102.jpg',\n",
       " 'king/1539023185.6079886.jpg',\n",
       " 'king/1539023823.1830983.jpg',\n",
       " 'king/1538778406.86247.jpg',\n",
       " 'king/1538775504.1042295.jpg',\n",
       " 'king/1539024597.23388.jpg',\n",
       " 'king/1539027947.6755114.jpg',\n",
       " 'king/1538779987.557536.jpg',\n",
       " 'king/1538775155.1271548.jpg',\n",
       " 'king/1538779354.1704876.jpg',\n",
       " 'king/1538774883.9670901.jpg',\n",
       " 'king/1539017656.5013957_31.jpg',\n",
       " 'king/1539022987.3141916.jpg',\n",
       " 'king/1538777095.0775242.jpg',\n",
       " 'king/1539017656.4857748_24.jpg',\n",
       " 'king/1539024744.5240357.jpg',\n",
       " 'king/1539026833.4767778.jpg',\n",
       " 'king/1538779020.8452945.jpg',\n",
       " 'king/1539017657.7939315_15.jpg',\n",
       " 'king/1538777707.301926.jpg',\n",
       " 'king/1538777418.4191957.jpg',\n",
       " 'king/1539023430.39102.jpg',\n",
       " 'king/1538779455.0068257.jpg',\n",
       " 'king/1539025742.555007.jpg',\n",
       " 'king/1538778972.6889744.jpg',\n",
       " 'king/1539023157.5381975.jpg',\n",
       " 'king/1538779136.6977031.jpg',\n",
       " 'king/1539017658.0594935_23.jpg',\n",
       " 'king/1538780110.995072.jpg',\n",
       " 'knight/1538779739.058273.jpg',\n",
       " 'knight/1539017658.809318_29.jpg',\n",
       " 'knight/1538778511.7367067.jpg',\n",
       " 'knight/1539017657.8251727_33.jpg',\n",
       " 'knight/1539028085.6649253.jpg',\n",
       " 'knight/1538778670.1169665.jpg',\n",
       " 'knight/1539026872.2657654.jpg',\n",
       " 'knight/1538779127.0457888.jpg',\n",
       " 'knight/1539017658.0438766_13.jpg',\n",
       " 'knight/1539017657.8407946_39.jpg',\n",
       " 'knight/1538779439.9036374.jpg',\n",
       " 'knight/1538779919.6389072.jpg',\n",
       " 'knight/1538778478.4419494.jpg',\n",
       " 'knight/1539017657.8251727_32.jpg',\n",
       " 'knight/1539023209.5838358.jpg',\n",
       " 'knight/1538778798.7536736.jpg',\n",
       " 'knight/1539023028.0835974.jpg',\n",
       " 'knight/1538778117.6826968.jpg',\n",
       " 'knight/1539017658.3406758_39.jpg',\n",
       " 'knight/1538779362.8107798.jpg',\n",
       " 'knight/1539017657.0682952_45.jpg',\n",
       " 'knight/1538779459.4036417.jpg',\n",
       " 'knight/1539017656.2045898_14.jpg',\n",
       " 'knight/1539028221.7775393.jpg',\n",
       " 'knight/1539017657.2756457_18.jpg',\n",
       " 'knight/1539023214.4817233.jpg',\n",
       " 'knight/1538775492.0805464.jpg',\n",
       " 'knight/1538779329.0645812.jpg',\n",
       " 'knight/1538778725.7980158.jpg',\n",
       " 'knight/1539017657.291264_26.jpg',\n",
       " 'knight/1539017657.2756457_13.jpg',\n",
       " 'knight/1538778212.992307.jpg',\n",
       " 'knight/1538777213.003978.jpg',\n",
       " 'knight/1539017656.7825797_62.jpg',\n",
       " 'knight/1539023817.175047.jpg',\n",
       " 'knight/1539017658.2938118_13.jpg',\n",
       " 'knight/1539017657.0643072_43.jpg',\n",
       " 'knight/1539023081.4048553.jpg',\n",
       " 'knight/1538778197.602519.jpg',\n",
       " 'knight/1539017656.048383_53.jpg',\n",
       " 'knight/1538777112.8554816.jpg',\n",
       " 'knight/1539023160.9380662.jpg',\n",
       " 'knight/1538779559.3820636.jpg',\n",
       " 'knight/1539017658.090735_39.jpg',\n",
       " 'knight/1538778628.9804418.jpg',\n",
       " 'knight/1538776219.5658782.jpg',\n",
       " 'knight/1539017657.5752366_26.jpg',\n",
       " 'knight/1538778356.0347438.jpg',\n",
       " 'knight/1539017656.6732304_1.jpg',\n",
       " 'knight/1539017658.3562984_41.jpg',\n",
       " 'knight/1539023190.5311208.jpg',\n",
       " 'knight/1539017657.5752366_28.jpg',\n",
       " 'knight/1538779701.3311424.jpg',\n",
       " 'knight/1539027337.492997.jpg',\n",
       " 'knight/1539017656.532639_55.jpg',\n",
       " 'knight/1539017658.5749974_28.jpg',\n",
       " 'knight/1538779157.0249271.jpg',\n",
       " 'knight/1539017658.3094337_22.jpg',\n",
       " 'knight/1539017657.7939315_13.jpg',\n",
       " 'knight/1539017657.0012786_23.jpg',\n",
       " 'knight/1539017658.5749974_27.jpg',\n",
       " 'pawn/1538779186.269667.jpg',\n",
       " 'pawn/1539025921.7744703.jpg',\n",
       " 'pawn/1539017659.0342584_5.jpg',\n",
       " 'pawn/1539023428.3806713.jpg',\n",
       " 'pawn/1539023228.1371589.jpg',\n",
       " 'pawn/1539024583.6953154.jpg',\n",
       " 'pawn/1539022975.1625128.jpg',\n",
       " 'pawn/1538776446.2195349.jpg',\n",
       " 'pawn/1539017659.9293435_51.jpg',\n",
       " 'pawn/1539025391.7579608.jpg',\n",
       " 'pawn/1539023017.1607347.jpg',\n",
       " 'pawn/1539024430.756946.jpg',\n",
       " 'pawn/1539026923.465744.jpg',\n",
       " 'pawn/1538778996.169403.jpg',\n",
       " 'pawn/1539017659.0342584_2.jpg',\n",
       " 'pawn/1539025607.6992056.jpg',\n",
       " 'pawn/1539017660.3198786_9.jpg',\n",
       " 'pawn/1539025757.220354.jpg',\n",
       " 'pawn/1539023766.4123085.jpg',\n",
       " 'pawn/1539023368.838083.jpg',\n",
       " 'pawn/1538779001.1267478.jpg',\n",
       " 'pawn/1539027155.227193.jpg',\n",
       " 'pawn/1539025313.0497591.jpg',\n",
       " 'pawn/1538778999.7679274.jpg',\n",
       " 'pawn/1538779184.9161654.jpg',\n",
       " 'pawn/1539017661.8009472_9.jpg',\n",
       " 'pawn/1539017659.273254_5.jpg',\n",
       " 'pawn/1539017659.320111_30.jpg',\n",
       " 'pawn/1539017660.5854392_17.jpg',\n",
       " 'pawn/1538779143.7233405.jpg',\n",
       " 'pawn/1539017660.148043_49.jpg',\n",
       " 'pawn/1539024541.9791014.jpg',\n",
       " 'pawn/1539017660.3511202_27.jpg',\n",
       " 'pawn/1539017661.6291142_49.jpg',\n",
       " 'pawn/1539017664.4256973_53.jpg',\n",
       " 'pawn/1539026875.391828.jpg',\n",
       " 'pawn/1539025362.0886774.jpg',\n",
       " 'pawn/1539017661.8321903_20.jpg',\n",
       " 'pawn/1539017660.804138_1.jpg',\n",
       " 'pawn/1538779112.965819.jpg',\n",
       " 'pawn/1539026980.8596466.jpg',\n",
       " 'pawn/1539026837.0018582.jpg',\n",
       " 'pawn/1538778988.6561909.jpg',\n",
       " 'pawn/1539023466.5992458.jpg',\n",
       " 'pawn/1539017662.058607_12.jpg',\n",
       " 'pawn/1539017660.9134872_58.jpg',\n",
       " 'pawn/1539017664.3632076_13.jpg',\n",
       " 'pawn/1539024357.4180336.jpg',\n",
       " 'pawn/1539025673.4654312.jpg',\n",
       " 'pawn/1539017662.0429847_1.jpg',\n",
       " 'pawn/1539026038.6849546.jpg',\n",
       " 'queen/1538776153.1161563.jpg',\n",
       " 'queen/1539017658.0751133_28.jpg',\n",
       " 'queen/1539023282.7923298.jpg',\n",
       " 'queen/1538774886.4350865.jpg',\n",
       " 'queen/1539026802.3034804.jpg',\n",
       " 'queen/1538779104.4953988.jpg',\n",
       " 'queen/1538776241.9984956.jpg',\n",
       " 'queen/1538777951.5345926.jpg',\n",
       " 'queen/1538775387.0960882.jpg',\n",
       " 'queen/1539017657.5596101_20.jpg',\n",
       " 'queen/1539027143.1900225.jpg',\n",
       " 'queen/1539017656.0171356_37.jpg',\n",
       " 'queen/1539023360.027172.jpg',\n",
       " 'queen/1538775023.0136087.jpg',\n",
       " 'queen/1539027242.9633646.jpg',\n",
       " 'queen/1539024330.4476821.jpg',\n",
       " 'queen/1538776666.2012632.jpg',\n",
       " 'queen/1538778645.0375922.jpg',\n",
       " 'queen/1539017658.809318_21.jpg',\n",
       " 'queen/1539025459.6575894.jpg',\n",
       " 'queen/1539025544.3600874.jpg',\n",
       " 'queen/1538778211.4124253.jpg',\n",
       " 'queen/1539017656.9544163_8.jpg',\n",
       " 'queen/1539028286.9873247.jpg',\n",
       " 'queen/1538777276.2401419.jpg',\n",
       " 'queen/1538774903.7820106.jpg',\n",
       " 'queen/1538775521.7555773.jpg',\n",
       " 'queen/1538777233.7800925.jpg',\n",
       " 'queen/1538779089.730211.jpg',\n",
       " 'queen/1539024135.86198.jpg',\n",
       " 'queen/1538779711.7096522.jpg',\n",
       " 'queen/1539017656.0171356_34.jpg',\n",
       " 'rook/1538779431.4099524.jpg',\n",
       " 'rook/1538779446.819697.jpg',\n",
       " 'rook/1539023040.9695048.jpg',\n",
       " 'rook/1539017656.7825797_63.jpg',\n",
       " 'rook/1539017656.1889713_1.jpg',\n",
       " 'rook/1538778901.7553732.jpg',\n",
       " 'rook/1538778196.1506379.jpg',\n",
       " 'rook/1538778508.6299925.jpg',\n",
       " 'rook/1539017657.1038074_61.jpg',\n",
       " 'rook/1538778101.779042.jpg',\n",
       " 'rook/1538780044.5343263.jpg',\n",
       " 'rook/1538778949.280067.jpg',\n",
       " 'rook/1539027229.5479693.jpg',\n",
       " 'rook/1539025545.9052472.jpg',\n",
       " 'rook/1539026987.1509364.jpg',\n",
       " 'rook/1539017656.7825797_56.jpg',\n",
       " 'rook/1539025399.1357424.jpg',\n",
       " 'rook/1538779366.148124.jpg',\n",
       " 'rook/1539017656.5482595_56.jpg',\n",
       " 'rook/1539017658.2781916_2.jpg',\n",
       " 'rook/1538779524.2512803.jpg',\n",
       " 'rook/1538778590.4654863.jpg',\n",
       " 'rook/1538779051.3667924.jpg',\n",
       " 'rook/1539017658.1376002_63.jpg',\n",
       " 'rook/1539017657.6064732_44.jpg',\n",
       " 'rook/1538779142.3172784.jpg',\n",
       " 'rook/1539017658.121979_59.jpg',\n",
       " 'rook/1538780084.217775.jpg',\n",
       " 'rook/1539025595.0919125.jpg',\n",
       " 'rook/1538778830.4086065.jpg',\n",
       " 'rook/1538776436.5497537.jpg',\n",
       " 'rook/1539017656.6732304_0.jpg',\n",
       " 'rook/1538778420.713808.jpg',\n",
       " 'rook/1538779718.4556568.jpg',\n",
       " 'rook/1539017658.5906172_32.jpg',\n",
       " 'rook/1538779147.5203454.jpg',\n",
       " 'rook/1538778808.3629324.jpg',\n",
       " 'rook/1539025256.5206127.jpg',\n",
       " 'rook/1538778848.9860363.jpg',\n",
       " 'rook/1539025785.8488226.jpg',\n",
       " 'rook/1538779688.6545618.jpg',\n",
       " 'rook/1538779355.8192723.jpg',\n",
       " 'rook/1539017657.8876572_60.jpg',\n",
       " 'rook/1539025702.8716216.jpg',\n",
       " 'rook/1538780007.7006266.jpg',\n",
       " 'rook/1539017658.387541_63.jpg',\n",
       " 'rook/1539017656.2983181_57.jpg',\n",
       " 'rook/1538778246.5786252.jpg',\n",
       " 'rook/1538778565.9025004.jpg',\n",
       " 'rook/1539026043.774472.jpg',\n",
       " 'rook/1538779183.5230417.jpg',\n",
       " 'rook/1539017657.3537493_60.jpg',\n",
       " 'rook/1539017656.4545326_0.jpg',\n",
       " 'rook/1539017657.6220949_52.jpg',\n",
       " 'rook/1539026846.958911.jpg',\n",
       " 'rook/1538779421.4983451.jpg',\n",
       " 'rook/1539027241.4846253.jpg',\n",
       " 'rook/1539017657.3537493_58.jpg',\n",
       " 'rook/1539017657.0325217_32.jpg',\n",
       " 'rook/1539017657.8720484_52.jpg',\n",
       " 'rook/1538780193.7644806.jpg',\n",
       " 'square/1538775507.261289.jpg',\n",
       " 'square/1538775508.9165573.jpg',\n",
       " 'square/1538775478.8303273.jpg',\n",
       " 'square/1538775464.8436766.jpg',\n",
       " 'square/1538775393.9093816.jpg',\n",
       " 'square/1538775477.4368722.jpg',\n",
       " 'square/1538775463.3285487.jpg',\n",
       " 'square/1538775534.8773243.jpg',\n",
       " 'square/1538775490.1613836.jpg',\n",
       " 'square/1538775411.657127.jpg',\n",
       " 'square/1538775556.1137612.jpg',\n",
       " 'square/1538775392.500712.jpg',\n",
       " 'square/1538775395.379885.jpg',\n",
       " 'square/1538775380.3348455.jpg',\n",
       " 'square/1538775554.7329156.jpg',\n",
       " 'square/1538775429.9237733.jpg',\n",
       " 'square/1538775557.4647563.jpg',\n",
       " 'square/1538775397.2511947.jpg',\n",
       " 'square/1538775414.3379526.jpg',\n",
       " 'square/1538775525.8732312.jpg',\n",
       " 'square/1538775589.5684185.jpg',\n",
       " 'square/1538775377.837528.jpg',\n",
       " 'square/1538775473.8751059.jpg',\n",
       " 'square/1538775541.8031077.jpg',\n",
       " 'square/1538775563.8003812.jpg',\n",
       " 'square/1538775413.002367.jpg',\n",
       " 'square/1538775546.3549168.jpg',\n",
       " 'square/1538775428.0259957.jpg',\n",
       " 'square/1538775496.149376.jpg',\n",
       " 'square/1538775553.2582464.jpg',\n",
       " 'square/1538775431.6329722.jpg',\n",
       " 'square/1538775518.2826645.jpg',\n",
       " 'square/1538775528.933519.jpg',\n",
       " 'square/1538775501.9954052.jpg',\n",
       " 'square/1538775593.2157.jpg',\n",
       " 'square/1538775575.8332133.jpg',\n",
       " 'square/1538775381.8908746.jpg',\n",
       " 'square/1538775482.290001.jpg',\n",
       " 'square/1538775527.3804672.jpg',\n",
       " 'square/1538775383.3700583.jpg',\n",
       " 'square/1538775497.691954.jpg',\n",
       " 'square/1538775433.0617445.jpg',\n",
       " 'square/1538775459.9201775.jpg',\n",
       " 'square/1538775578.4874399.jpg',\n",
       " 'square/1538775356.6463027.jpg',\n",
       " 'square/1538775585.983797.jpg',\n",
       " 'square/1538775472.3628545.jpg',\n",
       " 'square/1538775359.6263092.jpg',\n",
       " 'square/1538775583.9372883.jpg',\n",
       " 'square/1538775410.2587154.jpg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piece_test_iter.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=piece_test_iter.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Truth\": truth,\n",
    "                      \"Predictions\":predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bishop/1538778538.3017461.jpg</td>\n",
       "      <td>queen</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bishop/1539025832.837544.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bishop/1539025486.6533895.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bishop/1538779519.5865016.jpg</td>\n",
       "      <td>king</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bishop/1538778643.4925923.jpg</td>\n",
       "      <td>queen</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bishop/1539023363.830272.jpg</td>\n",
       "      <td>knight</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bishop/1539025801.510389.jpg</td>\n",
       "      <td>pawn</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bishop/1538778410.6081142.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bishop/1538778215.8878355.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bishop/1538778752.467536.jpg</td>\n",
       "      <td>king</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bishop/1539025373.0113628.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bishop/1539023140.397658.jpg</td>\n",
       "      <td>knight</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bishop/1539025334.2429533.jpg</td>\n",
       "      <td>knight</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bishop/1538778214.3746974.jpg</td>\n",
       "      <td>pawn</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bishop/1539023732.561326.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bishop/1538777556.4695792.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bishop/1539024760.3120384.jpg</td>\n",
       "      <td>rook</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bishop/1538778091.9695802.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bishop/1539024593.521976.jpg</td>\n",
       "      <td>knight</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bishop/1538779155.2682924.jpg</td>\n",
       "      <td>pawn</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bishop/1538778833.610855.jpg</td>\n",
       "      <td>pawn</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bishop/1538777891.4931645.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bishop/1539017656.6888525_5.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bishop/1538778427.8668559.jpg</td>\n",
       "      <td>knight</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bishop/1538777675.2653856.jpg</td>\n",
       "      <td>pawn</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bishop/1538778093.2397656.jpg</td>\n",
       "      <td>pawn</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bishop/1539024725.794323.jpg</td>\n",
       "      <td>rook</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bishop/1539026035.275597.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bishop/1539024424.9014952.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bishop/1539024039.3749897.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>square/1538775589.5684185.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>square/1538775377.837528.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>square/1538775473.8751059.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>square/1538775541.8031077.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>square/1538775563.8003812.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>square/1538775413.002367.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>square/1538775546.3549168.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>square/1538775428.0259957.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>square/1538775496.149376.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>square/1538775553.2582464.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>square/1538775431.6329722.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>square/1538775518.2826645.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>square/1538775528.933519.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>square/1538775501.9954052.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>square/1538775593.2157.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>square/1538775575.8332133.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>square/1538775381.8908746.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>square/1538775482.290001.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>square/1538775527.3804672.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>square/1538775383.3700583.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>square/1538775497.691954.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>square/1538775433.0617445.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>square/1538775459.9201775.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>square/1538775578.4874399.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>square/1538775356.6463027.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>square/1538775585.983797.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>square/1538775472.3628545.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>square/1538775359.6263092.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>square/1538775583.9372883.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>square/1538775410.2587154.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Filename Predictions   Truth\n",
       "0      bishop/1538778538.3017461.jpg       queen  bishop\n",
       "1       bishop/1539025832.837544.jpg      bishop  bishop\n",
       "2      bishop/1539025486.6533895.jpg      bishop  bishop\n",
       "3      bishop/1538779519.5865016.jpg        king  bishop\n",
       "4      bishop/1538778643.4925923.jpg       queen  bishop\n",
       "5       bishop/1539023363.830272.jpg      knight  bishop\n",
       "6       bishop/1539025801.510389.jpg        pawn  bishop\n",
       "7      bishop/1538778410.6081142.jpg      bishop  bishop\n",
       "8      bishop/1538778215.8878355.jpg      bishop  bishop\n",
       "9       bishop/1538778752.467536.jpg        king  bishop\n",
       "10     bishop/1539025373.0113628.jpg      bishop  bishop\n",
       "11      bishop/1539023140.397658.jpg      knight  bishop\n",
       "12     bishop/1539025334.2429533.jpg      knight  bishop\n",
       "13     bishop/1538778214.3746974.jpg        pawn  bishop\n",
       "14      bishop/1539023732.561326.jpg      bishop  bishop\n",
       "15     bishop/1538777556.4695792.jpg      bishop  bishop\n",
       "16     bishop/1539024760.3120384.jpg        rook  bishop\n",
       "17     bishop/1538778091.9695802.jpg      bishop  bishop\n",
       "18      bishop/1539024593.521976.jpg      knight  bishop\n",
       "19     bishop/1538779155.2682924.jpg        pawn  bishop\n",
       "20      bishop/1538778833.610855.jpg        pawn  bishop\n",
       "21     bishop/1538777891.4931645.jpg      bishop  bishop\n",
       "22   bishop/1539017656.6888525_5.jpg      bishop  bishop\n",
       "23     bishop/1538778427.8668559.jpg      knight  bishop\n",
       "24     bishop/1538777675.2653856.jpg        pawn  bishop\n",
       "25     bishop/1538778093.2397656.jpg        pawn  bishop\n",
       "26      bishop/1539024725.794323.jpg        rook  bishop\n",
       "27      bishop/1539026035.275597.jpg      bishop  bishop\n",
       "28     bishop/1539024424.9014952.jpg      bishop  bishop\n",
       "29     bishop/1539024039.3749897.jpg      bishop  bishop\n",
       "..                               ...         ...     ...\n",
       "305    square/1538775589.5684185.jpg      square  square\n",
       "306     square/1538775377.837528.jpg      square  square\n",
       "307    square/1538775473.8751059.jpg      square  square\n",
       "308    square/1538775541.8031077.jpg      square  square\n",
       "309    square/1538775563.8003812.jpg      square  square\n",
       "310     square/1538775413.002367.jpg      square  square\n",
       "311    square/1538775546.3549168.jpg      square  square\n",
       "312    square/1538775428.0259957.jpg      square  square\n",
       "313     square/1538775496.149376.jpg      square  square\n",
       "314    square/1538775553.2582464.jpg      square  square\n",
       "315    square/1538775431.6329722.jpg      square  square\n",
       "316    square/1538775518.2826645.jpg      square  square\n",
       "317     square/1538775528.933519.jpg      square  square\n",
       "318    square/1538775501.9954052.jpg      square  square\n",
       "319       square/1538775593.2157.jpg      square  square\n",
       "320    square/1538775575.8332133.jpg      square  square\n",
       "321    square/1538775381.8908746.jpg      square  square\n",
       "322     square/1538775482.290001.jpg      square  square\n",
       "323    square/1538775527.3804672.jpg      square  square\n",
       "324    square/1538775383.3700583.jpg      square  square\n",
       "325     square/1538775497.691954.jpg      square  square\n",
       "326    square/1538775433.0617445.jpg      square  square\n",
       "327    square/1538775459.9201775.jpg      square  square\n",
       "328    square/1538775578.4874399.jpg      square  square\n",
       "329    square/1538775356.6463027.jpg      square  square\n",
       "330     square/1538775585.983797.jpg      square  square\n",
       "331    square/1538775472.3628545.jpg      square  square\n",
       "332    square/1538775359.6263092.jpg      square  square\n",
       "333    square/1538775583.9372883.jpg      square  square\n",
       "334    square/1538775410.2587154.jpg      square  square\n",
       "\n",
       "[335 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.47      0.42        47\n",
      "          1       0.60      0.45      0.52        33\n",
      "          2       0.44      0.38      0.41        61\n",
      "          3       0.45      0.57      0.50        51\n",
      "          4       0.36      0.28      0.32        32\n",
      "          5       0.48      0.44      0.46        61\n",
      "          6       0.93      1.00      0.96        50\n",
      "\n",
      "avg / total       0.52      0.52      0.52       335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(piece_test_iter.classes,predicted_class_indices)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  2  7  9  4  3  0]\n",
      " [ 3 15  3  1  6  5  0]\n",
      " [11  0 23 12  4 11  0]\n",
      " [ 7  0  8 29  0  6  1]\n",
      " [ 6  6  5  2  9  4  0]\n",
      " [ 9  2  6 12  2 27  3]\n",
      " [ 0  0  0  0  0  0 50]]\n",
      "{0: 'bishop', 1: 'king', 2: 'knight', 3: 'pawn', 4: 'queen', 5: 'rook', 6: 'square'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cmatrix = confusion_matrix(piece_test_iter.classes,predicted_class_indices)\n",
    "print(cmatrix)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD8CAYAAABq6S8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcaEOSvkxhgT5v4fGxWoO71PnpcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f915a888cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.heatmap(cmatrix, annot=True, xticklabels=['bishop','king','pawn','knight','queen','rook','square'],yticklabels=['bishop','king','pawn','knight','queen','rook','square'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f915a888898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(piece_hist.history['acc'])\n",
    "plt.plot(piece_hist.history['val_acc'])\n",
    "plt.title('Piece Model accuracy no augmentation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8BVFUboJqvAVRVG6Cf8PSP6ZcQehJpEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9159858b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(piece_hist.history['loss'])\n",
    "plt.plot(piece_hist.history['val_loss'])\n",
    "plt.title('Piece Model Log Loss no augmentation')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.28927844239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss_result = log_loss(piece_test_iter.classes,piece_pred)\n",
    "print(log_loss_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
