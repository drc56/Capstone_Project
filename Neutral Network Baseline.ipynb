{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1227 images belonging to 7 classes.\n",
      "Found 335 images belonging to 7 classes.\n",
      "Found 331 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Image Data Generator w/ no augmentation\n",
    "#Scaling for pixels\n",
    "piece_train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255)\n",
    "piece_test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255)\n",
    "piece_valid_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255)\n",
    "\n",
    "\n",
    "#Flow data from directory\n",
    "\n",
    "piece_train_iter = piece_train_datagen.flow_from_directory(\n",
    "    directory = 'data/piece_data/train',\n",
    "    target_size = (135,135),\n",
    "    color_mode = 'grayscale',\n",
    "    class_mode = 'categorical',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "piece_test_iter = piece_test_datagen.flow_from_directory(\n",
    "    directory = 'data/piece_data/test',\n",
    "    target_size = (135,135),\n",
    "    color_mode = 'grayscale',\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "piece_valid_iter = piece_valid_datagen.flow_from_directory(\n",
    "    directory = 'data/piece_data/valid',\n",
    "    target_size = (135,135),\n",
    "    color_mode = 'grayscale',\n",
    "    class_mode = 'categorical',\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 135, 135, 16)      80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 67, 67, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 67, 67, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 67, 67, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 33, 33, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 33, 33, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 33, 33, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 11,063\n",
      "Trainable params: 10,967\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define NN architecture\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "piece_model = Sequential()\n",
    "piece_model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', \n",
    "                        input_shape=(135, 135, 1)))\n",
    "piece_model.add(MaxPooling2D(pool_size=2))\n",
    "piece_model.add(BatchNormalization())\n",
    "piece_model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "piece_model.add(MaxPooling2D(pool_size=2))\n",
    "piece_model.add(BatchNormalization())\n",
    "piece_model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "piece_model.add(MaxPooling2D(pool_size=2))\n",
    "piece_model.add(GlobalAveragePooling2D())\n",
    "piece_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "piece_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "rms_opt = keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=None, decay=0.0)\n",
    "piece_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "STEP_SIZE_TRAIN = piece_train_iter.n/piece_train_iter.batch_size\n",
    "STEP_SIZE_VALID = piece_valid_iter.n/piece_valid_iter.batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 00000: val_loss improved from inf to 1.93214, saving model to baseline_model.weights.best.hdf5\n",
      "3s - loss: 1.8489 - acc: 0.2541 - val_loss: 1.9321 - val_acc: 0.1843\n",
      "Epoch 2/100\n",
      "Epoch 00001: val_loss improved from 1.93214 to 1.92356, saving model to baseline_model.weights.best.hdf5\n",
      "1s - loss: 1.7321 - acc: 0.3194 - val_loss: 1.9236 - val_acc: 0.1934\n",
      "Epoch 3/100\n",
      "Epoch 00002: val_loss improved from 1.92356 to 1.91037, saving model to baseline_model.weights.best.hdf5\n",
      "1s - loss: 1.6642 - acc: 0.3409 - val_loss: 1.9104 - val_acc: 0.1480\n",
      "Epoch 4/100\n",
      "Epoch 00003: val_loss did not improve\n",
      "1s - loss: 1.6332 - acc: 0.3470 - val_loss: 1.9207 - val_acc: 0.1994\n",
      "Epoch 5/100\n",
      "Epoch 00004: val_loss did not improve\n",
      "1s - loss: 1.5918 - acc: 0.3691 - val_loss: 1.9608 - val_acc: 0.2326\n",
      "Epoch 6/100\n",
      "Epoch 00005: val_loss did not improve\n",
      "1s - loss: 1.5738 - acc: 0.3674 - val_loss: 1.9731 - val_acc: 0.1782\n",
      "Epoch 7/100\n",
      "Epoch 00006: val_loss did not improve\n",
      "1s - loss: 1.5472 - acc: 0.3960 - val_loss: 2.0201 - val_acc: 0.2356\n",
      "Epoch 8/100\n",
      "Epoch 00007: val_loss did not improve\n",
      "1s - loss: 1.5145 - acc: 0.4095 - val_loss: 2.0308 - val_acc: 0.1813\n",
      "Epoch 9/100\n",
      "Epoch 00008: val_loss did not improve\n",
      "1s - loss: 1.4872 - acc: 0.4124 - val_loss: 2.1539 - val_acc: 0.1843\n",
      "Epoch 10/100\n",
      "Epoch 00009: val_loss did not improve\n",
      "1s - loss: 1.4689 - acc: 0.4171 - val_loss: 2.1107 - val_acc: 0.2296\n",
      "Epoch 11/100\n",
      "Epoch 00010: val_loss did not improve\n",
      "1s - loss: 1.4599 - acc: 0.4423 - val_loss: 2.1766 - val_acc: 0.2145\n",
      "Epoch 12/100\n",
      "Epoch 00011: val_loss did not improve\n",
      "1s - loss: 1.4221 - acc: 0.4492 - val_loss: 2.1426 - val_acc: 0.2326\n",
      "Epoch 13/100\n",
      "Epoch 00012: val_loss did not improve\n",
      "1s - loss: 1.4063 - acc: 0.4475 - val_loss: 2.0140 - val_acc: 0.2387\n",
      "Epoch 14/100\n",
      "Epoch 00013: val_loss did not improve\n",
      "1s - loss: 1.3996 - acc: 0.4535 - val_loss: 2.0421 - val_acc: 0.2356\n",
      "Epoch 15/100\n",
      "Epoch 00014: val_loss improved from 1.91037 to 1.78614, saving model to baseline_model.weights.best.hdf5\n",
      "1s - loss: 1.3883 - acc: 0.4669 - val_loss: 1.7861 - val_acc: 0.3202\n",
      "Epoch 16/100\n",
      "Epoch 00015: val_loss did not improve\n",
      "1s - loss: 1.3705 - acc: 0.4735 - val_loss: 2.0432 - val_acc: 0.1813\n",
      "Epoch 17/100\n",
      "Epoch 00016: val_loss improved from 1.78614 to 1.74010, saving model to baseline_model.weights.best.hdf5\n",
      "1s - loss: 1.3295 - acc: 0.5108 - val_loss: 1.7401 - val_acc: 0.2961\n",
      "Epoch 18/100\n",
      "Epoch 00017: val_loss improved from 1.74010 to 1.73183, saving model to baseline_model.weights.best.hdf5\n",
      "1s - loss: 1.3222 - acc: 0.5018 - val_loss: 1.7318 - val_acc: 0.2991\n",
      "Epoch 19/100\n",
      "Epoch 00018: val_loss did not improve\n",
      "1s - loss: 1.2975 - acc: 0.5212 - val_loss: 2.1022 - val_acc: 0.2719\n",
      "Epoch 20/100\n",
      "Epoch 00019: val_loss improved from 1.73183 to 1.68650, saving model to baseline_model.weights.best.hdf5\n",
      "1s - loss: 1.2947 - acc: 0.5109 - val_loss: 1.6865 - val_acc: 0.3172\n",
      "Epoch 21/100\n",
      "Epoch 00020: val_loss did not improve\n",
      "1s - loss: 1.2711 - acc: 0.5219 - val_loss: 1.7202 - val_acc: 0.2931\n",
      "Epoch 22/100\n",
      "Epoch 00021: val_loss did not improve\n",
      "1s - loss: 1.2397 - acc: 0.5329 - val_loss: 1.7093 - val_acc: 0.2931\n",
      "Epoch 23/100\n",
      "Epoch 00022: val_loss improved from 1.68650 to 1.48955, saving model to baseline_model.weights.best.hdf5\n",
      "1s - loss: 1.2428 - acc: 0.5335 - val_loss: 1.4895 - val_acc: 0.4139\n",
      "Epoch 24/100\n",
      "Epoch 00023: val_loss did not improve\n",
      "1s - loss: 1.2084 - acc: 0.5739 - val_loss: 1.6069 - val_acc: 0.4079\n",
      "Epoch 25/100\n",
      "Epoch 00024: val_loss did not improve\n",
      "1s - loss: 1.2177 - acc: 0.5492 - val_loss: 1.7133 - val_acc: 0.4139\n",
      "Epoch 26/100\n",
      "Epoch 00025: val_loss did not improve\n",
      "1s - loss: 1.1946 - acc: 0.5629 - val_loss: 1.8638 - val_acc: 0.2719\n",
      "Epoch 27/100\n",
      "Epoch 00026: val_loss did not improve\n",
      "1s - loss: 1.1950 - acc: 0.5609 - val_loss: 1.4906 - val_acc: 0.4079\n",
      "Epoch 28/100\n",
      "Epoch 00027: val_loss improved from 1.48955 to 1.41159, saving model to baseline_model.weights.best.hdf5\n",
      "1s - loss: 1.1432 - acc: 0.5738 - val_loss: 1.4116 - val_acc: 0.4622\n",
      "Epoch 29/100\n",
      "Epoch 00028: val_loss did not improve\n",
      "1s - loss: 1.1673 - acc: 0.5479 - val_loss: 3.7498 - val_acc: 0.1994\n",
      "Epoch 30/100\n",
      "Epoch 00029: val_loss did not improve\n",
      "1s - loss: 1.1378 - acc: 0.5670 - val_loss: 2.1285 - val_acc: 0.2779\n",
      "Epoch 31/100\n",
      "Epoch 00030: val_loss improved from 1.41159 to 1.39343, saving model to baseline_model.weights.best.hdf5\n",
      "1s - loss: 1.1357 - acc: 0.5918 - val_loss: 1.3934 - val_acc: 0.4713\n",
      "Epoch 32/100\n",
      "Epoch 00031: val_loss did not improve\n",
      "1s - loss: 1.1178 - acc: 0.5956 - val_loss: 1.5822 - val_acc: 0.4441\n",
      "Epoch 33/100\n",
      "Epoch 00032: val_loss did not improve\n",
      "1s - loss: 1.0956 - acc: 0.6003 - val_loss: 2.1324 - val_acc: 0.3444\n",
      "Epoch 34/100\n",
      "Epoch 00033: val_loss did not improve\n",
      "1s - loss: 1.0977 - acc: 0.6059 - val_loss: 1.5079 - val_acc: 0.4169\n",
      "Epoch 35/100\n",
      "Epoch 00034: val_loss did not improve\n",
      "1s - loss: 1.0785 - acc: 0.5991 - val_loss: 1.9532 - val_acc: 0.3746\n",
      "Epoch 36/100\n",
      "Epoch 00035: val_loss improved from 1.39343 to 1.38210, saving model to baseline_model.weights.best.hdf5\n",
      "1s - loss: 1.0746 - acc: 0.6003 - val_loss: 1.3821 - val_acc: 0.4592\n",
      "Epoch 37/100\n",
      "Epoch 00036: val_loss did not improve\n",
      "1s - loss: 1.0482 - acc: 0.6078 - val_loss: 1.5224 - val_acc: 0.4169\n",
      "Epoch 38/100\n",
      "Epoch 00037: val_loss improved from 1.38210 to 1.36326, saving model to baseline_model.weights.best.hdf5\n",
      "1s - loss: 1.0530 - acc: 0.6175 - val_loss: 1.3633 - val_acc: 0.4924\n",
      "Epoch 39/100\n",
      "Epoch 00038: val_loss did not improve\n",
      "1s - loss: 1.0325 - acc: 0.6227 - val_loss: 1.4332 - val_acc: 0.4683\n",
      "Epoch 40/100\n",
      "Epoch 00039: val_loss did not improve\n",
      "1s - loss: 1.0337 - acc: 0.6421 - val_loss: 1.4318 - val_acc: 0.4864\n",
      "Epoch 41/100\n",
      "Epoch 00040: val_loss did not improve\n",
      "1s - loss: 1.0053 - acc: 0.6403 - val_loss: 3.6134 - val_acc: 0.2508\n",
      "Epoch 42/100\n",
      "Epoch 00041: val_loss improved from 1.36326 to 1.17252, saving model to baseline_model.weights.best.hdf5\n",
      "1s - loss: 1.0052 - acc: 0.6324 - val_loss: 1.1725 - val_acc: 0.5166\n",
      "Epoch 43/100\n",
      "Epoch 00042: val_loss did not improve\n",
      "1s - loss: 0.9840 - acc: 0.6453 - val_loss: 1.5236 - val_acc: 0.4471\n",
      "Epoch 44/100\n",
      "Epoch 00043: val_loss did not improve\n",
      "1s - loss: 0.9660 - acc: 0.6498 - val_loss: 2.3671 - val_acc: 0.2991\n",
      "Epoch 45/100\n",
      "Epoch 00044: val_loss did not improve\n",
      "1s - loss: 0.9777 - acc: 0.6341 - val_loss: 1.4250 - val_acc: 0.4894\n",
      "Epoch 46/100\n",
      "Epoch 00045: val_loss did not improve\n",
      "1s - loss: 0.9676 - acc: 0.6371 - val_loss: 1.3708 - val_acc: 0.4713\n",
      "Epoch 47/100\n",
      "Epoch 00046: val_loss did not improve\n",
      "1s - loss: 0.9737 - acc: 0.6375 - val_loss: 1.2903 - val_acc: 0.4955\n",
      "Epoch 48/100\n",
      "Epoch 00047: val_loss did not improve\n",
      "1s - loss: 0.9468 - acc: 0.6695 - val_loss: 1.5645 - val_acc: 0.4350\n",
      "Epoch 49/100\n",
      "Epoch 00048: val_loss did not improve\n",
      "1s - loss: 0.9298 - acc: 0.6567 - val_loss: 1.2704 - val_acc: 0.5136\n",
      "Epoch 50/100\n",
      "Epoch 00049: val_loss did not improve\n",
      "1s - loss: 0.9279 - acc: 0.6629 - val_loss: 1.1740 - val_acc: 0.5468\n",
      "Epoch 51/100\n",
      "Epoch 00050: val_loss did not improve\n",
      "1s - loss: 0.9072 - acc: 0.6722 - val_loss: 1.2206 - val_acc: 0.5529\n",
      "Epoch 52/100\n",
      "Epoch 00051: val_loss did not improve\n",
      "1s - loss: 0.8995 - acc: 0.6685 - val_loss: 1.3752 - val_acc: 0.5257\n",
      "Epoch 53/100\n",
      "Epoch 00052: val_loss did not improve\n",
      "1s - loss: 0.8915 - acc: 0.6820 - val_loss: 1.6766 - val_acc: 0.3776\n",
      "Epoch 54/100\n",
      "Epoch 00053: val_loss did not improve\n",
      "1s - loss: 0.9166 - acc: 0.6630 - val_loss: 1.5117 - val_acc: 0.4260\n",
      "Epoch 55/100\n",
      "Epoch 00054: val_loss did not improve\n",
      "1s - loss: 0.9037 - acc: 0.6692 - val_loss: 1.3823 - val_acc: 0.4502\n",
      "Epoch 56/100\n",
      "Epoch 00055: val_loss did not improve\n",
      "1s - loss: 0.8760 - acc: 0.6670 - val_loss: 1.2383 - val_acc: 0.5438\n",
      "Epoch 57/100\n",
      "Epoch 00056: val_loss did not improve\n",
      "1s - loss: 0.8849 - acc: 0.6759 - val_loss: 2.5788 - val_acc: 0.4018\n",
      "Epoch 58/100\n",
      "Epoch 00057: val_loss did not improve\n",
      "1s - loss: 0.8850 - acc: 0.6695 - val_loss: 1.6331 - val_acc: 0.4713\n",
      "Epoch 59/100\n",
      "Epoch 00058: val_loss did not improve\n",
      "1s - loss: 0.8643 - acc: 0.7004 - val_loss: 1.3214 - val_acc: 0.5196\n",
      "Epoch 60/100\n",
      "Epoch 00059: val_loss did not improve\n",
      "1s - loss: 0.8700 - acc: 0.6903 - val_loss: 1.9350 - val_acc: 0.3837\n",
      "Epoch 61/100\n",
      "Epoch 00060: val_loss did not improve\n",
      "1s - loss: 0.8544 - acc: 0.6916 - val_loss: 1.3210 - val_acc: 0.5227\n",
      "Epoch 62/100\n",
      "Epoch 00061: val_loss did not improve\n",
      "1s - loss: 0.8458 - acc: 0.6998 - val_loss: 1.3792 - val_acc: 0.5408\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00062: val_loss did not improve\n",
      "1s - loss: 0.8529 - acc: 0.6861 - val_loss: 1.2661 - val_acc: 0.5468\n",
      "Epoch 64/100\n",
      "Epoch 00063: val_loss did not improve\n",
      "1s - loss: 0.8183 - acc: 0.6912 - val_loss: 1.4817 - val_acc: 0.4894\n",
      "Epoch 65/100\n",
      "Epoch 00064: val_loss did not improve\n",
      "1s - loss: 0.8506 - acc: 0.6903 - val_loss: 1.3025 - val_acc: 0.5438\n",
      "Epoch 66/100\n",
      "Epoch 00065: val_loss did not improve\n",
      "1s - loss: 0.8140 - acc: 0.7008 - val_loss: 2.4885 - val_acc: 0.3625\n",
      "Epoch 67/100\n",
      "Epoch 00066: val_loss did not improve\n",
      "1s - loss: 0.8226 - acc: 0.6944 - val_loss: 1.9648 - val_acc: 0.4562\n",
      "Epoch 68/100\n",
      "Epoch 00067: val_loss did not improve\n",
      "1s - loss: 0.8024 - acc: 0.7134 - val_loss: 1.4092 - val_acc: 0.4894\n",
      "Epoch 69/100\n",
      "Epoch 00068: val_loss did not improve\n",
      "1s - loss: 0.7943 - acc: 0.7158 - val_loss: 1.6772 - val_acc: 0.4773\n",
      "Epoch 70/100\n",
      "Epoch 00069: val_loss did not improve\n",
      "1s - loss: 0.8021 - acc: 0.7082 - val_loss: 2.9725 - val_acc: 0.2931\n",
      "Epoch 71/100\n",
      "Epoch 00070: val_loss did not improve\n",
      "1s - loss: 0.7805 - acc: 0.7061 - val_loss: 1.3247 - val_acc: 0.5196\n",
      "Epoch 72/100\n",
      "Epoch 00071: val_loss did not improve\n",
      "1s - loss: 0.7958 - acc: 0.7052 - val_loss: 1.4480 - val_acc: 0.4532\n",
      "Epoch 73/100\n",
      "Epoch 00072: val_loss did not improve\n",
      "1s - loss: 0.7726 - acc: 0.7132 - val_loss: 1.6498 - val_acc: 0.5317\n",
      "Epoch 74/100\n",
      "Epoch 00073: val_loss did not improve\n",
      "1s - loss: 0.7822 - acc: 0.7164 - val_loss: 2.1356 - val_acc: 0.3837\n",
      "Epoch 75/100\n",
      "Epoch 00074: val_loss did not improve\n",
      "1s - loss: 0.7796 - acc: 0.7026 - val_loss: 1.5583 - val_acc: 0.5045\n",
      "Epoch 76/100\n",
      "Epoch 00075: val_loss did not improve\n",
      "1s - loss: 0.7743 - acc: 0.7144 - val_loss: 1.5085 - val_acc: 0.5106\n",
      "Epoch 77/100\n",
      "Epoch 00076: val_loss did not improve\n",
      "1s - loss: 0.7565 - acc: 0.7254 - val_loss: 1.2503 - val_acc: 0.5347\n",
      "Epoch 78/100\n",
      "Epoch 00077: val_loss did not improve\n",
      "1s - loss: 0.7433 - acc: 0.7367 - val_loss: 1.2618 - val_acc: 0.5468\n",
      "Epoch 79/100\n",
      "Epoch 00078: val_loss did not improve\n",
      "1s - loss: 0.7453 - acc: 0.7388 - val_loss: 2.0387 - val_acc: 0.4350\n",
      "Epoch 80/100\n",
      "Epoch 00079: val_loss did not improve\n",
      "1s - loss: 0.7506 - acc: 0.7280 - val_loss: 4.1463 - val_acc: 0.3172\n",
      "Epoch 81/100\n",
      "Epoch 00080: val_loss improved from 1.17252 to 1.07715, saving model to baseline_model.weights.best.hdf5\n",
      "1s - loss: 0.7174 - acc: 0.7509 - val_loss: 1.0772 - val_acc: 0.6042\n",
      "Epoch 82/100\n",
      "Epoch 00081: val_loss did not improve\n",
      "1s - loss: 0.7465 - acc: 0.7358 - val_loss: 1.4646 - val_acc: 0.5740\n",
      "Epoch 83/100\n",
      "Epoch 00082: val_loss did not improve\n",
      "1s - loss: 0.7030 - acc: 0.7503 - val_loss: 2.0621 - val_acc: 0.4411\n",
      "Epoch 84/100\n",
      "Epoch 00083: val_loss did not improve\n",
      "1s - loss: 0.7350 - acc: 0.7389 - val_loss: 1.2531 - val_acc: 0.5680\n",
      "Epoch 85/100\n",
      "Epoch 00084: val_loss did not improve\n",
      "1s - loss: 0.7063 - acc: 0.7535 - val_loss: 5.4478 - val_acc: 0.2719\n",
      "Epoch 86/100\n",
      "Epoch 00085: val_loss did not improve\n",
      "1s - loss: 0.7204 - acc: 0.7477 - val_loss: 1.1652 - val_acc: 0.6012\n",
      "Epoch 87/100\n",
      "Epoch 00086: val_loss did not improve\n",
      "1s - loss: 0.7120 - acc: 0.7417 - val_loss: 1.4416 - val_acc: 0.5227\n",
      "Epoch 88/100\n",
      "Epoch 00087: val_loss did not improve\n",
      "1s - loss: 0.6916 - acc: 0.7616 - val_loss: 2.7030 - val_acc: 0.3807\n",
      "Epoch 89/100\n",
      "Epoch 00088: val_loss did not improve\n",
      "1s - loss: 0.6998 - acc: 0.7606 - val_loss: 1.4242 - val_acc: 0.5076\n",
      "Epoch 90/100\n",
      "Epoch 00089: val_loss did not improve\n",
      "1s - loss: 0.7017 - acc: 0.7409 - val_loss: 3.1540 - val_acc: 0.4109\n",
      "Epoch 91/100\n",
      "Epoch 00090: val_loss did not improve\n",
      "1s - loss: 0.6883 - acc: 0.7661 - val_loss: 5.3342 - val_acc: 0.2870\n",
      "Epoch 92/100\n",
      "Epoch 00091: val_loss did not improve\n",
      "1s - loss: 0.6870 - acc: 0.7495 - val_loss: 1.6768 - val_acc: 0.4592\n",
      "Epoch 93/100\n",
      "Epoch 00092: val_loss did not improve\n",
      "1s - loss: 0.6778 - acc: 0.7529 - val_loss: 1.1957 - val_acc: 0.5861\n",
      "Epoch 94/100\n",
      "Epoch 00093: val_loss did not improve\n",
      "1s - loss: 0.6750 - acc: 0.7593 - val_loss: 1.3341 - val_acc: 0.4804\n",
      "Epoch 95/100\n",
      "Epoch 00094: val_loss did not improve\n",
      "1s - loss: 0.6800 - acc: 0.7671 - val_loss: 1.2831 - val_acc: 0.5347\n",
      "Epoch 96/100\n",
      "Epoch 00095: val_loss did not improve\n",
      "1s - loss: 0.6316 - acc: 0.7871 - val_loss: 1.2622 - val_acc: 0.5740\n",
      "Epoch 97/100\n",
      "Epoch 00096: val_loss did not improve\n",
      "1s - loss: 0.6691 - acc: 0.7606 - val_loss: 1.5025 - val_acc: 0.5076\n",
      "Epoch 98/100\n",
      "Epoch 00097: val_loss did not improve\n",
      "1s - loss: 0.6466 - acc: 0.7791 - val_loss: 4.1647 - val_acc: 0.2387\n",
      "Epoch 99/100\n",
      "Epoch 00098: val_loss did not improve\n",
      "1s - loss: 0.6361 - acc: 0.7908 - val_loss: 1.2115 - val_acc: 0.5227\n",
      "Epoch 100/100\n",
      "Epoch 00099: val_loss did not improve\n",
      "1s - loss: 0.6471 - acc: 0.7678 - val_loss: 1.8341 - val_acc: 0.4260\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='baseline_model.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "piece_hist = piece_model.fit_generator(generator=piece_train_iter, \n",
    "                          steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                          validation_data=piece_valid_iter, \n",
    "                          validation_steps=STEP_SIZE_VALID,\n",
    "                          epochs=100, \n",
    "                          callbacks=[checkpointer], \n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 0.594029853593\n"
     ]
    }
   ],
   "source": [
    "#Reset test iterator\n",
    "STEP_SIZE_TEST = piece_test_iter.n/piece_test_iter.batch_size\n",
    "piece_test_iter.reset()\n",
    "# load the weights that yielded the best validation accuracy\n",
    "piece_model.load_weights('baseline_model.weights.best.hdf5')\n",
    "# evaluate and print test accuracy\n",
    "score = piece_model.evaluate_generator(generator=piece_test_iter,steps=STEP_SIZE_TEST)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [========================>.....] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "piece_test_iter.reset()\n",
    "piece_pred = piece_model.predict_generator(piece_test_iter,steps=STEP_SIZE_TEST,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 2 0 2 5 0 2 5 0 0 0 0 0 0 0 2 0 0 0 0 1 0 0 0 2 0 0 0 0 0 0 0 0 0 5\n",
      " 0 0 2 0 5 0 0 5 0 0 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 0 5 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 5 1 1 5 2 0 5 5 2 5 2 0 2 0 5 2 5 0 5 2 2 0 0 2 0 2 1 2 2 2 1 0 0 0 2\n",
      " 5 0 2 2 2 0 5 3 2 0 0 5 0 0 5 2 1 3 2 2 2 5 2 0 2 1 0 2 2 4 3 3 5 3 2 0 3\n",
      " 3 5 0 3 3 0 3 5 3 5 3 2 0 3 5 2 3 3 5 5 2 5 3 5 5 3 5 5 3 0 3 0 3 3 5 3 3\n",
      " 5 0 2 5 2 0 3 1 2 0 1 4 1 5 5 1 4 4 1 1 4 1 1 2 2 0 0 1 0 5 5 0 0 1 1 0 1\n",
      " 2 4 5 5 2 5 2 5 5 5 2 2 5 3 2 1 5 2 5 5 2 2 3 5 2 5 0 0 5 5 5 3 5 1 2 2 5\n",
      " 2 5 2 2 5 3 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 0 5 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 3\n",
      " 6 6]\n"
     ]
    }
   ],
   "source": [
    "predicted_class_indices=np.argmax(piece_pred,axis=1)\n",
    "print(predicted_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (piece_test_iter.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "truth =  [labels[k] for k in piece_test_iter.classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'bishop',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'king',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'knight',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'pawn',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'rook',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square',\n",
       " 'square']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[labels[k] for k in piece_test_iter.classes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bishop/1538778538.3017461.jpg',\n",
       " 'bishop/1539025832.837544.jpg',\n",
       " 'bishop/1539025486.6533895.jpg',\n",
       " 'bishop/1538779519.5865016.jpg',\n",
       " 'bishop/1538778643.4925923.jpg',\n",
       " 'bishop/1539023363.830272.jpg',\n",
       " 'bishop/1539025801.510389.jpg',\n",
       " 'bishop/1538778410.6081142.jpg',\n",
       " 'bishop/1538778215.8878355.jpg',\n",
       " 'bishop/1538778752.467536.jpg',\n",
       " 'bishop/1539025373.0113628.jpg',\n",
       " 'bishop/1539023140.397658.jpg',\n",
       " 'bishop/1539025334.2429533.jpg',\n",
       " 'bishop/1538778214.3746974.jpg',\n",
       " 'bishop/1539023732.561326.jpg',\n",
       " 'bishop/1538777556.4695792.jpg',\n",
       " 'bishop/1539024760.3120384.jpg',\n",
       " 'bishop/1538778091.9695802.jpg',\n",
       " 'bishop/1539024593.521976.jpg',\n",
       " 'bishop/1538779155.2682924.jpg',\n",
       " 'bishop/1538778833.610855.jpg',\n",
       " 'bishop/1538777891.4931645.jpg',\n",
       " 'bishop/1539017656.6888525_5.jpg',\n",
       " 'bishop/1538778427.8668559.jpg',\n",
       " 'bishop/1538777675.2653856.jpg',\n",
       " 'bishop/1538778093.2397656.jpg',\n",
       " 'bishop/1539024725.794323.jpg',\n",
       " 'bishop/1539026035.275597.jpg',\n",
       " 'bishop/1539024424.9014952.jpg',\n",
       " 'bishop/1539024039.3749897.jpg',\n",
       " 'bishop/1538778832.1937056.jpg',\n",
       " 'bishop/1538778729.1405196.jpg',\n",
       " 'bishop/1539025434.58347.jpg',\n",
       " 'bishop/1538778878.3252861.jpg',\n",
       " 'bishop/1539025959.458598.jpg',\n",
       " 'bishop/1539025736.4874806.jpg',\n",
       " 'bishop/1539025415.635129.jpg',\n",
       " 'bishop/1538779144.9958382.jpg',\n",
       " 'bishop/1539017656.2202125_22.jpg',\n",
       " 'bishop/1538779417.7487714.jpg',\n",
       " 'bishop/1538777310.1624303.jpg',\n",
       " 'bishop/1538778958.324379.jpg',\n",
       " 'bishop/1538778656.6147914.jpg',\n",
       " 'bishop/1539025355.3753638.jpg',\n",
       " 'bishop/1538778537.1458335.jpg',\n",
       " 'bishop/1538778653.1963263.jpg',\n",
       " 'bishop/1539025474.8601475.jpg',\n",
       " 'king/1538776272.1332486.jpg',\n",
       " 'king/1539017657.8720484_58.jpg',\n",
       " 'king/1539017656.0015128_29.jpg',\n",
       " 'king/1538776522.496111.jpg',\n",
       " 'king/1538778011.0228102.jpg',\n",
       " 'king/1539023185.6079886.jpg',\n",
       " 'king/1539023823.1830983.jpg',\n",
       " 'king/1538778406.86247.jpg',\n",
       " 'king/1538775504.1042295.jpg',\n",
       " 'king/1539024597.23388.jpg',\n",
       " 'king/1539027947.6755114.jpg',\n",
       " 'king/1538779987.557536.jpg',\n",
       " 'king/1538775155.1271548.jpg',\n",
       " 'king/1538779354.1704876.jpg',\n",
       " 'king/1538774883.9670901.jpg',\n",
       " 'king/1539017656.5013957_31.jpg',\n",
       " 'king/1539022987.3141916.jpg',\n",
       " 'king/1538777095.0775242.jpg',\n",
       " 'king/1539017656.4857748_24.jpg',\n",
       " 'king/1539024744.5240357.jpg',\n",
       " 'king/1539026833.4767778.jpg',\n",
       " 'king/1538779020.8452945.jpg',\n",
       " 'king/1539017657.7939315_15.jpg',\n",
       " 'king/1538777707.301926.jpg',\n",
       " 'king/1538777418.4191957.jpg',\n",
       " 'king/1539023430.39102.jpg',\n",
       " 'king/1538779455.0068257.jpg',\n",
       " 'king/1539025742.555007.jpg',\n",
       " 'king/1538778972.6889744.jpg',\n",
       " 'king/1539023157.5381975.jpg',\n",
       " 'king/1538779136.6977031.jpg',\n",
       " 'king/1539017658.0594935_23.jpg',\n",
       " 'king/1538780110.995072.jpg',\n",
       " 'knight/1538779739.058273.jpg',\n",
       " 'knight/1539017658.809318_29.jpg',\n",
       " 'knight/1538778511.7367067.jpg',\n",
       " 'knight/1539017657.8251727_33.jpg',\n",
       " 'knight/1539028085.6649253.jpg',\n",
       " 'knight/1538778670.1169665.jpg',\n",
       " 'knight/1539026872.2657654.jpg',\n",
       " 'knight/1538779127.0457888.jpg',\n",
       " 'knight/1539017658.0438766_13.jpg',\n",
       " 'knight/1539017657.8407946_39.jpg',\n",
       " 'knight/1538779439.9036374.jpg',\n",
       " 'knight/1538779919.6389072.jpg',\n",
       " 'knight/1538778478.4419494.jpg',\n",
       " 'knight/1539017657.8251727_32.jpg',\n",
       " 'knight/1539023209.5838358.jpg',\n",
       " 'knight/1538778798.7536736.jpg',\n",
       " 'knight/1539023028.0835974.jpg',\n",
       " 'knight/1538778117.6826968.jpg',\n",
       " 'knight/1539017658.3406758_39.jpg',\n",
       " 'knight/1538779362.8107798.jpg',\n",
       " 'knight/1539017657.0682952_45.jpg',\n",
       " 'knight/1538779459.4036417.jpg',\n",
       " 'knight/1539017656.2045898_14.jpg',\n",
       " 'knight/1539028221.7775393.jpg',\n",
       " 'knight/1539017657.2756457_18.jpg',\n",
       " 'knight/1539023214.4817233.jpg',\n",
       " 'knight/1538775492.0805464.jpg',\n",
       " 'knight/1538779329.0645812.jpg',\n",
       " 'knight/1538778725.7980158.jpg',\n",
       " 'knight/1539017657.291264_26.jpg',\n",
       " 'knight/1539017657.2756457_13.jpg',\n",
       " 'knight/1538778212.992307.jpg',\n",
       " 'knight/1538777213.003978.jpg',\n",
       " 'knight/1539017656.7825797_62.jpg',\n",
       " 'knight/1539023817.175047.jpg',\n",
       " 'knight/1539017658.2938118_13.jpg',\n",
       " 'knight/1539017657.0643072_43.jpg',\n",
       " 'knight/1539023081.4048553.jpg',\n",
       " 'knight/1538778197.602519.jpg',\n",
       " 'knight/1539017656.048383_53.jpg',\n",
       " 'knight/1538777112.8554816.jpg',\n",
       " 'knight/1539023160.9380662.jpg',\n",
       " 'knight/1538779559.3820636.jpg',\n",
       " 'knight/1539017658.090735_39.jpg',\n",
       " 'knight/1538778628.9804418.jpg',\n",
       " 'knight/1538776219.5658782.jpg',\n",
       " 'knight/1539017657.5752366_26.jpg',\n",
       " 'knight/1538778356.0347438.jpg',\n",
       " 'knight/1539017656.6732304_1.jpg',\n",
       " 'knight/1539017658.3562984_41.jpg',\n",
       " 'knight/1539023190.5311208.jpg',\n",
       " 'knight/1539017657.5752366_28.jpg',\n",
       " 'knight/1538779701.3311424.jpg',\n",
       " 'knight/1539027337.492997.jpg',\n",
       " 'knight/1539017656.532639_55.jpg',\n",
       " 'knight/1539017658.5749974_28.jpg',\n",
       " 'knight/1538779157.0249271.jpg',\n",
       " 'knight/1539017658.3094337_22.jpg',\n",
       " 'knight/1539017657.7939315_13.jpg',\n",
       " 'knight/1539017657.0012786_23.jpg',\n",
       " 'knight/1539017658.5749974_27.jpg',\n",
       " 'pawn/1538779186.269667.jpg',\n",
       " 'pawn/1539025921.7744703.jpg',\n",
       " 'pawn/1539017659.0342584_5.jpg',\n",
       " 'pawn/1539023428.3806713.jpg',\n",
       " 'pawn/1539023228.1371589.jpg',\n",
       " 'pawn/1539024583.6953154.jpg',\n",
       " 'pawn/1539022975.1625128.jpg',\n",
       " 'pawn/1538776446.2195349.jpg',\n",
       " 'pawn/1539017659.9293435_51.jpg',\n",
       " 'pawn/1539025391.7579608.jpg',\n",
       " 'pawn/1539023017.1607347.jpg',\n",
       " 'pawn/1539024430.756946.jpg',\n",
       " 'pawn/1539026923.465744.jpg',\n",
       " 'pawn/1538778996.169403.jpg',\n",
       " 'pawn/1539017659.0342584_2.jpg',\n",
       " 'pawn/1539025607.6992056.jpg',\n",
       " 'pawn/1539017660.3198786_9.jpg',\n",
       " 'pawn/1539025757.220354.jpg',\n",
       " 'pawn/1539023766.4123085.jpg',\n",
       " 'pawn/1539023368.838083.jpg',\n",
       " 'pawn/1538779001.1267478.jpg',\n",
       " 'pawn/1539027155.227193.jpg',\n",
       " 'pawn/1539025313.0497591.jpg',\n",
       " 'pawn/1538778999.7679274.jpg',\n",
       " 'pawn/1538779184.9161654.jpg',\n",
       " 'pawn/1539017661.8009472_9.jpg',\n",
       " 'pawn/1539017659.273254_5.jpg',\n",
       " 'pawn/1539017659.320111_30.jpg',\n",
       " 'pawn/1539017660.5854392_17.jpg',\n",
       " 'pawn/1538779143.7233405.jpg',\n",
       " 'pawn/1539017660.148043_49.jpg',\n",
       " 'pawn/1539024541.9791014.jpg',\n",
       " 'pawn/1539017660.3511202_27.jpg',\n",
       " 'pawn/1539017661.6291142_49.jpg',\n",
       " 'pawn/1539017664.4256973_53.jpg',\n",
       " 'pawn/1539026875.391828.jpg',\n",
       " 'pawn/1539025362.0886774.jpg',\n",
       " 'pawn/1539017661.8321903_20.jpg',\n",
       " 'pawn/1539017660.804138_1.jpg',\n",
       " 'pawn/1538779112.965819.jpg',\n",
       " 'pawn/1539026980.8596466.jpg',\n",
       " 'pawn/1539026837.0018582.jpg',\n",
       " 'pawn/1538778988.6561909.jpg',\n",
       " 'pawn/1539023466.5992458.jpg',\n",
       " 'pawn/1539017662.058607_12.jpg',\n",
       " 'pawn/1539017660.9134872_58.jpg',\n",
       " 'pawn/1539017664.3632076_13.jpg',\n",
       " 'pawn/1539024357.4180336.jpg',\n",
       " 'pawn/1539025673.4654312.jpg',\n",
       " 'pawn/1539017662.0429847_1.jpg',\n",
       " 'pawn/1539026038.6849546.jpg',\n",
       " 'queen/1538776153.1161563.jpg',\n",
       " 'queen/1539017658.0751133_28.jpg',\n",
       " 'queen/1539023282.7923298.jpg',\n",
       " 'queen/1538774886.4350865.jpg',\n",
       " 'queen/1539026802.3034804.jpg',\n",
       " 'queen/1538779104.4953988.jpg',\n",
       " 'queen/1538776241.9984956.jpg',\n",
       " 'queen/1538777951.5345926.jpg',\n",
       " 'queen/1538775387.0960882.jpg',\n",
       " 'queen/1539017657.5596101_20.jpg',\n",
       " 'queen/1539027143.1900225.jpg',\n",
       " 'queen/1539017656.0171356_37.jpg',\n",
       " 'queen/1539023360.027172.jpg',\n",
       " 'queen/1538775023.0136087.jpg',\n",
       " 'queen/1539027242.9633646.jpg',\n",
       " 'queen/1539024330.4476821.jpg',\n",
       " 'queen/1538776666.2012632.jpg',\n",
       " 'queen/1538778645.0375922.jpg',\n",
       " 'queen/1539017658.809318_21.jpg',\n",
       " 'queen/1539025459.6575894.jpg',\n",
       " 'queen/1539025544.3600874.jpg',\n",
       " 'queen/1538778211.4124253.jpg',\n",
       " 'queen/1539017656.9544163_8.jpg',\n",
       " 'queen/1539028286.9873247.jpg',\n",
       " 'queen/1538777276.2401419.jpg',\n",
       " 'queen/1538774903.7820106.jpg',\n",
       " 'queen/1538775521.7555773.jpg',\n",
       " 'queen/1538777233.7800925.jpg',\n",
       " 'queen/1538779089.730211.jpg',\n",
       " 'queen/1539024135.86198.jpg',\n",
       " 'queen/1538779711.7096522.jpg',\n",
       " 'queen/1539017656.0171356_34.jpg',\n",
       " 'rook/1538779431.4099524.jpg',\n",
       " 'rook/1538779446.819697.jpg',\n",
       " 'rook/1539023040.9695048.jpg',\n",
       " 'rook/1539017656.7825797_63.jpg',\n",
       " 'rook/1539017656.1889713_1.jpg',\n",
       " 'rook/1538778901.7553732.jpg',\n",
       " 'rook/1538778196.1506379.jpg',\n",
       " 'rook/1538778508.6299925.jpg',\n",
       " 'rook/1539017657.1038074_61.jpg',\n",
       " 'rook/1538778101.779042.jpg',\n",
       " 'rook/1538780044.5343263.jpg',\n",
       " 'rook/1538778949.280067.jpg',\n",
       " 'rook/1539027229.5479693.jpg',\n",
       " 'rook/1539025545.9052472.jpg',\n",
       " 'rook/1539026987.1509364.jpg',\n",
       " 'rook/1539017656.7825797_56.jpg',\n",
       " 'rook/1539025399.1357424.jpg',\n",
       " 'rook/1538779366.148124.jpg',\n",
       " 'rook/1539017656.5482595_56.jpg',\n",
       " 'rook/1539017658.2781916_2.jpg',\n",
       " 'rook/1538779524.2512803.jpg',\n",
       " 'rook/1538778590.4654863.jpg',\n",
       " 'rook/1538779051.3667924.jpg',\n",
       " 'rook/1539017658.1376002_63.jpg',\n",
       " 'rook/1539017657.6064732_44.jpg',\n",
       " 'rook/1538779142.3172784.jpg',\n",
       " 'rook/1539017658.121979_59.jpg',\n",
       " 'rook/1538780084.217775.jpg',\n",
       " 'rook/1539025595.0919125.jpg',\n",
       " 'rook/1538778830.4086065.jpg',\n",
       " 'rook/1538776436.5497537.jpg',\n",
       " 'rook/1539017656.6732304_0.jpg',\n",
       " 'rook/1538778420.713808.jpg',\n",
       " 'rook/1538779718.4556568.jpg',\n",
       " 'rook/1539017658.5906172_32.jpg',\n",
       " 'rook/1538779147.5203454.jpg',\n",
       " 'rook/1538778808.3629324.jpg',\n",
       " 'rook/1539025256.5206127.jpg',\n",
       " 'rook/1538778848.9860363.jpg',\n",
       " 'rook/1539025785.8488226.jpg',\n",
       " 'rook/1538779688.6545618.jpg',\n",
       " 'rook/1538779355.8192723.jpg',\n",
       " 'rook/1539017657.8876572_60.jpg',\n",
       " 'rook/1539025702.8716216.jpg',\n",
       " 'rook/1538780007.7006266.jpg',\n",
       " 'rook/1539017658.387541_63.jpg',\n",
       " 'rook/1539017656.2983181_57.jpg',\n",
       " 'rook/1538778246.5786252.jpg',\n",
       " 'rook/1538778565.9025004.jpg',\n",
       " 'rook/1539026043.774472.jpg',\n",
       " 'rook/1538779183.5230417.jpg',\n",
       " 'rook/1539017657.3537493_60.jpg',\n",
       " 'rook/1539017656.4545326_0.jpg',\n",
       " 'rook/1539017657.6220949_52.jpg',\n",
       " 'rook/1539026846.958911.jpg',\n",
       " 'rook/1538779421.4983451.jpg',\n",
       " 'rook/1539027241.4846253.jpg',\n",
       " 'rook/1539017657.3537493_58.jpg',\n",
       " 'rook/1539017657.0325217_32.jpg',\n",
       " 'rook/1539017657.8720484_52.jpg',\n",
       " 'rook/1538780193.7644806.jpg',\n",
       " 'square/1538775507.261289.jpg',\n",
       " 'square/1538775508.9165573.jpg',\n",
       " 'square/1538775478.8303273.jpg',\n",
       " 'square/1538775464.8436766.jpg',\n",
       " 'square/1538775393.9093816.jpg',\n",
       " 'square/1538775477.4368722.jpg',\n",
       " 'square/1538775463.3285487.jpg',\n",
       " 'square/1538775534.8773243.jpg',\n",
       " 'square/1538775490.1613836.jpg',\n",
       " 'square/1538775411.657127.jpg',\n",
       " 'square/1538775556.1137612.jpg',\n",
       " 'square/1538775392.500712.jpg',\n",
       " 'square/1538775395.379885.jpg',\n",
       " 'square/1538775380.3348455.jpg',\n",
       " 'square/1538775554.7329156.jpg',\n",
       " 'square/1538775429.9237733.jpg',\n",
       " 'square/1538775557.4647563.jpg',\n",
       " 'square/1538775397.2511947.jpg',\n",
       " 'square/1538775414.3379526.jpg',\n",
       " 'square/1538775525.8732312.jpg',\n",
       " 'square/1538775589.5684185.jpg',\n",
       " 'square/1538775377.837528.jpg',\n",
       " 'square/1538775473.8751059.jpg',\n",
       " 'square/1538775541.8031077.jpg',\n",
       " 'square/1538775563.8003812.jpg',\n",
       " 'square/1538775413.002367.jpg',\n",
       " 'square/1538775546.3549168.jpg',\n",
       " 'square/1538775428.0259957.jpg',\n",
       " 'square/1538775496.149376.jpg',\n",
       " 'square/1538775553.2582464.jpg',\n",
       " 'square/1538775431.6329722.jpg',\n",
       " 'square/1538775518.2826645.jpg',\n",
       " 'square/1538775528.933519.jpg',\n",
       " 'square/1538775501.9954052.jpg',\n",
       " 'square/1538775593.2157.jpg',\n",
       " 'square/1538775575.8332133.jpg',\n",
       " 'square/1538775381.8908746.jpg',\n",
       " 'square/1538775482.290001.jpg',\n",
       " 'square/1538775527.3804672.jpg',\n",
       " 'square/1538775383.3700583.jpg',\n",
       " 'square/1538775497.691954.jpg',\n",
       " 'square/1538775433.0617445.jpg',\n",
       " 'square/1538775459.9201775.jpg',\n",
       " 'square/1538775578.4874399.jpg',\n",
       " 'square/1538775356.6463027.jpg',\n",
       " 'square/1538775585.983797.jpg',\n",
       " 'square/1538775472.3628545.jpg',\n",
       " 'square/1538775359.6263092.jpg',\n",
       " 'square/1538775583.9372883.jpg',\n",
       " 'square/1538775410.2587154.jpg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piece_test_iter.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=piece_test_iter.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Truth\": truth,\n",
    "                      \"Predictions\":predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bishop/1538778538.3017461.jpg</td>\n",
       "      <td>knight</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bishop/1539025832.837544.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bishop/1539025486.6533895.jpg</td>\n",
       "      <td>knight</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bishop/1538779519.5865016.jpg</td>\n",
       "      <td>knight</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bishop/1538778643.4925923.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bishop/1539023363.830272.jpg</td>\n",
       "      <td>knight</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bishop/1539025801.510389.jpg</td>\n",
       "      <td>rook</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bishop/1538778410.6081142.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bishop/1538778215.8878355.jpg</td>\n",
       "      <td>knight</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bishop/1538778752.467536.jpg</td>\n",
       "      <td>rook</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bishop/1539025373.0113628.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bishop/1539023140.397658.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bishop/1539025334.2429533.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bishop/1538778214.3746974.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bishop/1539023732.561326.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bishop/1538777556.4695792.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bishop/1539024760.3120384.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bishop/1538778091.9695802.jpg</td>\n",
       "      <td>knight</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bishop/1539024593.521976.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bishop/1538779155.2682924.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bishop/1538778833.610855.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bishop/1538777891.4931645.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bishop/1539017656.6888525_5.jpg</td>\n",
       "      <td>king</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bishop/1538778427.8668559.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bishop/1538777675.2653856.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bishop/1538778093.2397656.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bishop/1539024725.794323.jpg</td>\n",
       "      <td>knight</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bishop/1539026035.275597.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bishop/1539024424.9014952.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bishop/1539024039.3749897.jpg</td>\n",
       "      <td>bishop</td>\n",
       "      <td>bishop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>square/1538775589.5684185.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>square/1538775377.837528.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>square/1538775473.8751059.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>square/1538775541.8031077.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>square/1538775563.8003812.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>square/1538775413.002367.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>square/1538775546.3549168.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>square/1538775428.0259957.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>square/1538775496.149376.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>square/1538775553.2582464.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>square/1538775431.6329722.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>square/1538775518.2826645.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>square/1538775528.933519.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>square/1538775501.9954052.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>square/1538775593.2157.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>square/1538775575.8332133.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>square/1538775381.8908746.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>square/1538775482.290001.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>square/1538775527.3804672.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>square/1538775383.3700583.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>square/1538775497.691954.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>square/1538775433.0617445.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>square/1538775459.9201775.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>square/1538775578.4874399.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>square/1538775356.6463027.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>square/1538775585.983797.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>square/1538775472.3628545.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>square/1538775359.6263092.jpg</td>\n",
       "      <td>pawn</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>square/1538775583.9372883.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>square/1538775410.2587154.jpg</td>\n",
       "      <td>square</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Filename Predictions   Truth\n",
       "0      bishop/1538778538.3017461.jpg      knight  bishop\n",
       "1       bishop/1539025832.837544.jpg      bishop  bishop\n",
       "2      bishop/1539025486.6533895.jpg      knight  bishop\n",
       "3      bishop/1538779519.5865016.jpg      knight  bishop\n",
       "4      bishop/1538778643.4925923.jpg      bishop  bishop\n",
       "5       bishop/1539023363.830272.jpg      knight  bishop\n",
       "6       bishop/1539025801.510389.jpg        rook  bishop\n",
       "7      bishop/1538778410.6081142.jpg      bishop  bishop\n",
       "8      bishop/1538778215.8878355.jpg      knight  bishop\n",
       "9       bishop/1538778752.467536.jpg        rook  bishop\n",
       "10     bishop/1539025373.0113628.jpg      bishop  bishop\n",
       "11      bishop/1539023140.397658.jpg      bishop  bishop\n",
       "12     bishop/1539025334.2429533.jpg      bishop  bishop\n",
       "13     bishop/1538778214.3746974.jpg      bishop  bishop\n",
       "14      bishop/1539023732.561326.jpg      bishop  bishop\n",
       "15     bishop/1538777556.4695792.jpg      bishop  bishop\n",
       "16     bishop/1539024760.3120384.jpg      bishop  bishop\n",
       "17     bishop/1538778091.9695802.jpg      knight  bishop\n",
       "18      bishop/1539024593.521976.jpg      bishop  bishop\n",
       "19     bishop/1538779155.2682924.jpg      bishop  bishop\n",
       "20      bishop/1538778833.610855.jpg      bishop  bishop\n",
       "21     bishop/1538777891.4931645.jpg      bishop  bishop\n",
       "22   bishop/1539017656.6888525_5.jpg        king  bishop\n",
       "23     bishop/1538778427.8668559.jpg      bishop  bishop\n",
       "24     bishop/1538777675.2653856.jpg      bishop  bishop\n",
       "25     bishop/1538778093.2397656.jpg      bishop  bishop\n",
       "26      bishop/1539024725.794323.jpg      knight  bishop\n",
       "27      bishop/1539026035.275597.jpg      bishop  bishop\n",
       "28     bishop/1539024424.9014952.jpg      bishop  bishop\n",
       "29     bishop/1539024039.3749897.jpg      bishop  bishop\n",
       "..                               ...         ...     ...\n",
       "305    square/1538775589.5684185.jpg      square  square\n",
       "306     square/1538775377.837528.jpg      square  square\n",
       "307    square/1538775473.8751059.jpg      square  square\n",
       "308    square/1538775541.8031077.jpg      square  square\n",
       "309    square/1538775563.8003812.jpg      square  square\n",
       "310     square/1538775413.002367.jpg      square  square\n",
       "311    square/1538775546.3549168.jpg      square  square\n",
       "312    square/1538775428.0259957.jpg      square  square\n",
       "313     square/1538775496.149376.jpg      square  square\n",
       "314    square/1538775553.2582464.jpg      square  square\n",
       "315    square/1538775431.6329722.jpg      square  square\n",
       "316    square/1538775518.2826645.jpg      square  square\n",
       "317     square/1538775528.933519.jpg      square  square\n",
       "318    square/1538775501.9954052.jpg      square  square\n",
       "319       square/1538775593.2157.jpg      square  square\n",
       "320    square/1538775575.8332133.jpg      square  square\n",
       "321    square/1538775381.8908746.jpg      square  square\n",
       "322     square/1538775482.290001.jpg      square  square\n",
       "323    square/1538775527.3804672.jpg      square  square\n",
       "324    square/1538775383.3700583.jpg      square  square\n",
       "325     square/1538775497.691954.jpg      square  square\n",
       "326    square/1538775433.0617445.jpg      square  square\n",
       "327    square/1538775459.9201775.jpg      square  square\n",
       "328    square/1538775578.4874399.jpg      square  square\n",
       "329    square/1538775356.6463027.jpg      square  square\n",
       "330     square/1538775585.983797.jpg      square  square\n",
       "331    square/1538775472.3628545.jpg      square  square\n",
       "332    square/1538775359.6263092.jpg        pawn  square\n",
       "333    square/1538775583.9372883.jpg      square  square\n",
       "334    square/1538775410.2587154.jpg      square  square\n",
       "\n",
       "[335 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
